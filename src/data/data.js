export const blogListProfiles = [{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"]},{"title":"观‘技术人不要看中文’有感","date":"2022-04-29","tags":["essay"]},{"title":"字节码-无关性的基石","date":"2022-05-04","tags":["Java","byte","code"]},{"title":"functional programming","date":"2022-05-05","tags":["编程风格","lambda","纯函数"]},{"title":"reactive programming","date":"2022-05-11","tags":["reactive","编程风格"]},{"title":"123.买卖股票的最佳时机Ⅲ","date":"2022-05-03","tags":["leetcode"]},{"title":"42.接雨水","date":"2022-05-03","tags":["leetcode"]},{"title":"DDD领域驱动设计","date":"2023-04-05","tags":["设计思想"]},{"title":"http协议","date":"2023-04-13","tags":["http","网络"]},{"title":"Nginx必知必会","date":"2022-11-16","tags":["nginx","运维","devops"]},{"title":"spring security(servlet)","date":"2023-02-22","tags":["spring-security"]},{"title":"单元测试","date":"2023-04-16","tags":["测试"]},{"title":"并发探索","date":"2023-04-12","tags":["Java","并发"]},{"title":"泛型实现","date":"2023-04-13","tags":["泛型","编程语言原理"]},{"title":"使用redis实现分布式锁","date":"2022-04-29","tags":["redis","分布式锁"]},{"title":"编程相关小技巧","date":"2022-04-29","tags":["技巧"]},{"title":"rabbitmq与AMQP","date":"2022-05-01","tags":["消息队列","中间件","rabbitmq"]},{"title":"rabbitmq中的消息发布与消费","date":"2022-05-02","tags":["rabbitmq"]},{"title":"rabbitmq中的队列和exchange","date":"2022-05-02","tags":["rabbitmq","中间件","消息队列"]}];
export const blogsMap = [{"title":"what is spring webflux","payload":{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"}},{"title":"观‘技术人不要看中文’有感","payload":{"title":"观‘技术人不要看中文’有感","date":"2022-04-29","tags":["essay"],"categories":"随笔","content":"\r\n\r\n今日B站给推送一个视频，标题叫‘[50岁程序员：技术人不准看中文！](https://www.bilibili.com/video/BV1Sr4y1J7K9?spm_id_from=333.999.0.0)’ 。短短25秒大致意思就是中文互联网下所获取学习到的相关技术已经比其原本所具备的能力打了折扣。评论最高赞的三个评论我贴在下方。![反对方论点](../resources/img/journal_review1.png)  ![支持方论点](../resources/img/journal_review2.png)\r\n\r\n就我个人来说，技术人不准看中文大致上是准确。诚然，中文互联网上是可以找到大量优质的技术文章，它们或者短小精悍，或者详尽有趣，看完也能大有收获。但是呢，这里有一个问题，我怎么才能找到这些文章呢？对于一个小白来说代价有点大。遇到问题，借助百度，搜到的答案要么同质化程度太高，要么水平低下，要么早已过时。(google好一些，但或多或少还是会遇到这种情况，怎么解决还有待探索)。一些技术论坛，rss的情况好一些，可以时不时的找到一些高质量文章，有时在评论区也能有所收获，但也都是随缘，毕竟这些生产高质量文章的大佬一是更新日期不固定，二是实时的关注点也会有所差异。当然我们也可以去看书，这里有两类，一类是由英文翻译而来的技术书，一类是中文作者原创的技术书。中文原创的技术书一般都是实战型，就着某个框架，某门技术给你现造个应用出来，这么做其实好的，编程这个东西就得实践，看一百本书都比不上做一个完整项目的收获大。但是这么做也是有问题的，一本几百页的书并且是在以项目为基础的前提下所能包含的相关技术的内涵是有限的，而且这些书一般也会绑定某个版本做项目，当我们要换个版本做应用，并且版本的变化相对较大时，我们还是得去看官方的文档，这些文档鲜少会提供中文。至于由英文翻译而来的技术书呢，则良莠不齐，有些甚至都可以看出是机翻。\r\n\r\n所以对于反对者所说的看英文文档效率低的问题我是不认同的，相对与在中文互联网中四处闲逛还是收获甚小所造成的开销，翻译层的开销是可以忽略的。至于后半段真假参半的话术，还扯上脊梁问题，那就令人反感了。这里为什么说真假参半呢，因为这里是有指导意义的，读应当读英文，那些大佬有空也可以做一些优秀的中文输出反馈到中文社区，从而形成中文互联网的良性循环。虽然在这个流量变现，而不是付费变现的时代，期待这成为现实有些困难，但万一呢 :wink: "}},{"title":"字节码-无关性的基石","payload":{"title":"字节码-无关性的基石","date":"2022-05-04","tags":["Java","byte","code"],"categories":"Java","content":"\r\n\r\n字节码技术是虚拟机实现平台无关性，语言无关性的基石，得益于此，Java语言才能在嵌入式，web服务端等领域大展拳脚并受到长期欢迎。围绕字节码技术，发展出一批拥有不同特性的运行于Java虚拟机之上的编程语言，如groovy，Scala，kotlin等。虚拟机只与class文件绑定，它不关心class文件来自何处，是来自本地的磁盘文件，还是来自于网络，是由.java文件编译而来，还是由.groovy文件编译而来，只要是有效的class文件，虚拟机便能够运行。\r\n\r\n一个class文件由连续的8-bit、16-bit和32-bit的无符号数的流构成，并且以大端模式存储。class文件的格式可以以一种C-like结构体的方式描述，结构体由`items`和`tables`构成。tables由零个或者任意的items构成。class文件的格式结构体描述如下，其中u1，u2，u4为`items`,_info结尾的项为`tables`\r\n\r\n    ClassFile{\r\n        u4              magic;\r\n        u2              minor_version;\r\n        u2              major_version;\r\n        u2              constant_pool_count;\r\n        cp_info         constant_pool[constant_pool_count-1];\r\n        u2              access_flags;\r\n        u2              this_class;\r\n        u2              super_class;\r\n        u2              interfaces_count;\r\n        u2              interfaces[interfaces_count];\r\n        u2              fields_count;\r\n        field_info      fields[fields_count];\r\n        u2              methods_count;\r\n        method_info     methods[methods_count];\r\n        u2              attributes_count;\r\n        attribute_info  attributes[attributes_count];\r\n    }\r\n\r\n> magic\r\n\r\n魔数，固定为OxCAFEBABE,标志为一个class文件。\r\n\r\n> minor_version,major_version\r\n\r\n它们共同决定了一个class文件的版本，不同的Java SE所能支持的class文件版本是不同的，比如Java8支持主版本45-52，Java18支持主版本45-62。主版本号 >= 56时，此版本号限制为0或者65535，之前的主版本则随意。Java虚拟机的实现如果遵循JavaSE的某版本(>=12)，那么就必须支持该版本的preview feature，并且默认关闭支持，但是提供途径可以开启支持。一个class文件的版本若为(45 - N+44).65535的形式，则其是依赖JavaSEN的preview feature的class文件。一个遵循JavaSEN的虚拟机实现，只有在开启preview feature支持时，才能加载(45 - N+44).65535的class文件，普通的则不受影响。\r\n\r\n> constant_pool_count\r\n\r\n常量池条目的数量加一。\r\n\r\n> constant_pool[]\r\n\r\n常量池是一张可包含各种字符串常量，类名，接口名，字段名以及其他表示class文件中条目的常量的表，表中entry的格式由其第一个字节`tag`指示。常量表的索引从1到constant_pool_count - 1。\r\n\r\n> access_flags\r\n\r\naccess_flags是一个掩码标记，用来指示一个类或者接口的访问权限以及各种属性。\r\n\r\n|Flag name|Value|Interpretation|\r\n|:-|:-:|:-|\r\n|ACC_PUBLIC|0x0001|Declared public; may be accessed from outside its package.|\r\n|ACC_FINAL|0x0010|Declared final; no subclasses allowed|\r\n|ACC_SUPER|0x0020|Treat superclass methods specially when invoked by the invokespecial instruction|\r\n|ACC_INTERFACE|0x0200|Is an interface, not a class|\r\n|ACC_ABSTRACT|0x0400|Declared abstract; must not be instantiated|\r\n|ACC_SYNTHETIC|0x1000|Declared synthetic; not present in the source code.|\r\n|ACC_ANNATATION|0x2000|Declared as an annotation interface.|\r\n|ACC_ENUM|0x4000|Declared as an enum class.|\r\n|ACC_MODULE|0x8000|Is a module, not a class or interface.|\r\n\r\nACC_SUPER用来指示当遇到invokespecial指令将表示的两种语义时，应该选择哪种进行解释。Java8之后，无论class文件是否设置该值，虚拟机都认为设置了。ACC_SYNTHETIC指示该类或者接口是由编译器动态生成的，而不是本身就存在于源码中的。\r\n\r\n> this_class\r\n\r\n该值是常量池表的一个有效索引，索引指向的条目必须是一个代表该类或者接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> super_class\r\n\r\n该值或为0或为指向常量池的一个有效索引，若为0，则超类为Object，否则指向常量池中一个代表超类结构的`CONSTANT_Class_info`类型。\r\n\r\n> interfaces_count\r\n\r\n代表该类或者接口有几个直接父接口。\r\n\r\n> interfaces[]\r\n\r\n一个指向常量池的有效索引的数组，每个索引指向的条目必须是代表父接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> fields_count\r\n\r\n指示该类或接口的类变量和实例变量的总数目。\r\n\r\n> fields[]\r\n\r\n字段表的每个条目必须是`field_info`结构，用来表示一个字段的完整描述。\r\n\r\n> methods_count\r\n\r\n指示该类或者接口有多少方法。\r\n\r\n> methods[]\r\n\r\n方法表的每个条目必须是`method_info`结构，用来表示一个方法的完整描述。如果结构中没有设置`ACC_NATIVE`或者`ACC_ABSTRACT`，那么方法的虚拟机指令实现也会被提供。\r\n\r\n> attributes_count\r\n\r\n指示该类属性的总数目。\r\n\r\n> attributes[]\r\n\r\n属性表的每个条目必须是`attribute_info`结构，用来表示一个属性的完整描述。属性表条目可以用来表示class文件的属性，也可以用来表示一个方法的属性。`attribute_info`的结构如下：\r\n\r\n    attribute_info {\r\n        u2 attribute_name_index; \r\n        u4 attribute_length; \r\n        u1 info[attribute_length];\r\n    }\r\n\r\n常量池表是class文件的资源仓库，与class文件中的其他item有着各种各样的联系。常量池表的第0号索引被空出来，用来在表示不引用任何常量池item的特殊含义。常量池中主要有两类常量：字面量和符号引用，字面量接近Java语言层面的常量概念，符号引用则属于编译原理方面的概念，主要包括package、Fully Qualified Name、Descriptor、Method Handle、Method Type、Invoke Dynamic、Dynamically-Computed Call Site、Dynamically-Computed Constant。\r\n\r\n类或者接口的名称在class文件中总是被表示为全限定类名的utf8编码形式，放在常量池的`CONSTANT_Utf8_info`结构中。而方法，字段，本地变量，形参则为非全限定类名的Unicode编码方式。\r\n\r\n类中的字段和方法的类型被一个叫descriptor的字符串来表示，其在常量池中是一个`CONSTANT_Utf8_info`结构。字段描述符被表示为FieldDescriptor:FieldType。Object类型的字段的描述符为Ljava/lang/Object,double[][][]类型的字段的描述符为[[[D，array类型不能超过255个维度。方法描述符被表示为：MethodDescriptor:( {ParameterDescriptor} ) ReturnDescriptor，比如Object m(int i, double d, Thread t) {...}的描述符为(IDLjava/lang/Thread;)Ljava/lang/Object;。\r\n\r\n常量池的每一项都是一个表，截至jdk18，共有17类表结构，这些表结构的第一项都是一个u1的tag，表示其是哪种类型的表结构。具体如下所示：\r\n|Constant Kind|Tag|\r\n|:-|:-|\r\n|CONSTANT_Class|7|\r\n|CONSTANT_Fieldref|9|\r\n|CONSTANT_Methodref|10|\r\n|CONSTANT_InterfaceMethodref|11|\r\n|CONSTANT_String|8|\r\n|CONSTANT_Integer|3|\r\n|CONSTANT_Float|4|\r\n|CONSTANT_Long|5|\r\n|CONSTANT_Double|6|\r\n|CONSTANT_NameAndType|12|\r\n|CONSTANT_Utf8|1|\r\n|CONSTANT_MethodHandle|15|\r\n|CONSTANT_MethodType|16|\r\n|CONSTANT_Dynamic|17|\r\n|CONSTANT_InvokeDynamic|18|\r\n|CONSTANT_Module|19|\r\n|CONSTANT_Package|20|\r\n\r\n所有类型的条目都遵循以下格式：\r\n\r\n    cp_info { \r\n        u1 tag;\r\n        u1 info[]; \r\n    }\r\n\r\n- CONSTANT_Class_info\r\n\r\n        CONSTANT_Class_info {\r\n            // 7  \r\n            u1 tag;\r\n\r\n            // 指向常量池表的某一项，该项为CONSTANT_Utf8_info结构\r\n            // 存储类的全限定类名\r\n            u2 name_index;  \r\n        }\r\n\r\n- CONSTANT_Fieldref_info\r\n\r\n        CONSTANT_Fieldref_info { \r\n            // 9\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构可表示一个类或者接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和字段描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_Methodref_info\r\n\r\n        CONSTANT_Methodref_info { \r\n            // 10\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个类\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_InterfaceMethodref_info\r\n\r\n        CONSTANT_InterfaceMethodref_info { \r\n            // 11\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_String_info\r\n\r\n        CONSTANT_String_info { \r\n            // 8\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info结构\r\n            // 该结构表示字符串对象的Unicode编码\r\n            u2 string_index; \r\n        }\r\n\r\n- CONSTANT_Integer_info\r\n\r\n        CONSTANT_Integer_info {\r\n            // 3 \r\n            u1 tag; \r\n\r\n            // 表示int值\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Float_info\r\n\r\n        CONSTANT_Float_info { \r\n            // 4 \r\n            u1 tag; \r\n\r\n            // 表示为IEEE754的单浮点数编码\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Long_info\r\n  \r\n        CONSTANT_Long_info { \r\n            // 5\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_Double_info\r\n  \r\n        CONSTANT_Double_info { \r\n            // 6\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_NameAndType_info\r\n\r\n        CONSTANT_NameAndType_info { \r\n            // 12\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法的名称\r\n            u2 name_index; \r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法描述符\r\n            u2 descriptor_index;\r\n        }\r\n\r\n- CONSTANT_Utf8_info\r\n\r\n        CONSTANT_Utf8_info { \r\n            // 1\r\n            u1 tag;\r\n\r\n            // byte数组的长度\r\n            u2 length; \r\n\r\n            // UTF-8编码\r\n            u1 bytes[length]; \r\n        }\r\n\r\n- CONSTANT_MethodHandle_info\r\n\r\n        CONSTANT_MethodHandle_info { \r\n            // 15\r\n            u1 tag;\r\n\r\n            // 表示方法句柄的类型，该类型会影响字节码的行为\r\n            // 1.REF_getField 2.REF_getStatic 3.REF_putField\r\n            // 4.REF_putStatic 5.REF_invokeVirtual 6.REF_invokeStatic\r\n            // 7.REF_invokeSpecial 8.REF_newInvokeSpecial 9.REF_invokeInterface\r\n            u1 reference_kind; \r\n\r\n            // 根据reference_kind的值，指向常量池中的某CONSTANT_Fieldref_info\r\n\r\n            // CONSTANT_Methodref_info或者CONSTANT_InterfaceMethodref_info结构\r\n            u2 reference_index;\r\n        }\r\n\r\n- CONSTANT_MethodType_info\r\n\r\n        CONSTANT_MethodType_info { \r\n            // 16\r\n            u1 tag;\r\n\r\n            // 指向常量池中的某表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n        }\r\n\r\n- CONSTANT_Dynamic_info （表示一个动态调用计算出的常量）\r\n\r\n        CONSTANT_Dynamic_info { \r\n            // 17\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示字段描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_InvokeDynamic_info （表示一个动态计算出的方法调用）\r\n  \r\n        CONSTANT_InvokeDynamic_info { \r\n            // 18\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示方法描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_Module_info\r\n\r\n        CONSTANT_Module_info { \r\n            // 19\r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示模块名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n\r\n- CONSTANT_Package_info\r\n\r\n        CONSTANT_Package_info {\r\n            // 20 \r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示包名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n    \r\nclass文件中fields数组中的条目都遵循`field_info`结构，数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n    field_info {\r\n        // 掩码标记，指示访问权限以及属性\r\n        // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED\r\n        // ACC_STATIC、ACC_FINAL、ACC_VOLATILE\r\n        // ACC_TRANSIENT、ACC_SYNTHETIC、ACC_ENUM\r\n        u2 access_flags; \r\n\r\n        // 指向常量池中一个表示字段名的CONSTANT_Utf8_info结构\r\n        u2 name_index;\r\n\r\n        // 指向常量池中一个表示字段描述符的CONSTANT_Utf8_info结构\r\n        u2 descriptor_index; \r\n\r\n        // 字段额外属性数组的大小\r\n        u2 attributes_count;\r\n\r\n        // attribute_info结构的数组\r\n        attribute_info attributes[attributes_count]; \r\n    }\r\n\r\nclass文件中methods数组中的条目都遵循`method_info`结构，每个条目表示一个方法，一个实例初始化方法，或者一个类初始化方法。数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n        method_info { \r\n            // 掩码标记，指示访问权限以及属性\r\n            // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED、ACC_STATIC\r\n            // ACC_FINAL、ACC_SYNCHRONIZED、ACC_BRIDGE、ACC_VARARGS\r\n            // ACC_NATIVE、ACC_ABSTRACT、ACC_STRICT、ACC_SYNTHETIC\r\n            u2 access_flags; \r\n\r\n            // 指向常量池中一个表示方法，<init>方法或者<clinit>方法的CONSTANT_Utf8_info结构\r\n            u2 name_index;\r\n\r\n            // 指向常量池中一个表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n\r\n            // 方法额外属性数组的大小\r\n            attributes_count;\r\n\r\n            // attribute_info结构的数组\r\n            attribute_info attributes[attributes_count]; \r\n        }\r\n\r\nattributes被用在class文件，field_info，method_info，Code_attribute，record_component_info结构中。field_info结构如下：\r\n\r\n        attribute_info {\r\n            // 指向常量池中一个表示属性名的CONSTANT_Utf8_info结构\r\n            u2 attribute_name_index; \r\n\r\n            // 表示附加属性的字节长度\r\n            u4 attribute_length;\r\n\r\n            // 附加属性\r\n            u1 info[attribute_length];\r\n        }\r\n\r\n附加属性相关的东西就说来话长了，有时间在写吧。"}},{"title":"functional programming","payload":{"title":"functional programming","date":"2022-05-05","tags":["编程风格","lambda","纯函数"],"categories":"theory","content":"\r\n\r\n> 函数式编程是一种编程范式，区别于面向对象编程和面向过程编程的命令风格，其风格是声明式的，是满足若干要素的构建软件的方式。\r\n\r\n函数式编程由纯函数的组合构成，以避免共享状态、可变数据以及副作用。理解函数式编程的第一步就是要理解什么是纯函数。\r\n\r\n所谓纯函数就是那种对于给定输入总是得出固定输出且不产生任何副作用的函数。纯函数是函数的一种类型，一个函数的目的可以是值映射，一系列步骤的组合或者是同系统中的其他模块通信。纯函数总是和值映射相关，一个参数，一个固定输出。比如Math.max(11,13)无论被调用多少次，什么时候调用，其结果都是13。而且因为该函数不存在将值存盘或者输出到标准输出上的行为，理论上来说，只要Math.max(11,13)出现的地方，都可以用13去代替。即所谓的引用透明性(referential transparency)。Math.random(),System.currentTime()不是纯函数，因为它们不满足一个输入对应一个输出的原则。\r\n\r\n纯函数用副本实现不可变性的。区别于全拷贝，它将数据分成一个个很小的块，只对变化的块进行复制，很象git管理库和提交的方式。基于不可变性，纯函数也不会修改任何外部状态。\r\n\r\n纯函数不修改外部状态避免了共享状态，也意味着不会产生任何副作用。在共享状态下，并发/并行过程 + 可变状态 = 不确定性，一个不确定的系统结果是无法预测的，可能会产生各种奇奇怪怪的bug，纯函数可以帮助我们避免这种bug。\r\n\r\n函数组合就是将两个以上的函数以某种顺序组合成一个函数的过程，一个函数就像是一个管道，我们的数据就在这一系列的管道中流过。基于这种风格，我们可以减少中间变量的使用。\r\n\r\n函数式编程倾向于重用一组通用的函数式实用程序来处理数据。面向对象的编程倾向于将方法和数据放在对象中。那些并置的方法只能对它们设计用于操作的数据类型进行操作，并且通常只能对包含在该特定对象实例中的数据进行操作。在函数式编程中，任何类型的数据都是平等的。相同的 map()实用程序可以映射对象、字符串、数字或任何其他数据类型，因为它将函数作为参数来适当地处理给定的数据类型。函数式编程使用高阶函数实现了它的通用实用技巧。\r\n\r\n更加具体清晰的functional programming说明可以参考Eric Elliott的文章[Master the JavaScript Interview: What is Functional Programming?](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0),以及Russ Olsen的演讲[Functional Programming in 40 Minutes](https://www.youtube.com/watch?v=0if71HOyVjY)。\r\n"}},{"title":"reactive programming","payload":{"title":"reactive programming","date":"2022-05-11","tags":["reactive","编程风格"],"categories":"theory","content":"\r\n\r\n"}},{"title":"123.买卖股票的最佳时机Ⅲ","payload":{"title":"123.买卖股票的最佳时机Ⅲ","date":"2022-05-03","tags":["leetcode"],"categories":"leetcode","content":"\r\n\r\n> 题目描述\r\n\r\n给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你最多可以完成两笔交易。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\r\n\r\n> 例1\r\n\r\n    输入：prices = [3,3,5,0,0,3,1,4]\r\n    输出：6\r\n    解释：在第 4 天（股票价格 = 0）的时候买入，在第 6 天（股票价格 = 3）的时候卖出，这笔交易所能获得利润 = 3-0 = 3 。\r\n    随后，在第 7 天（股票价格 = 1）的时候买入，在第 8 天 （股票价格 = 4）的时候 卖出，这笔交易所能获得利润 = 4-1 = 3 。\r\n> 例2\r\n\r\n    输入：prices = [1,2,3,4,5]\r\n    输出：4\r\n    解释：在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。   \r\n    注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出.因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。\r\n> 例3\r\n\r\n    输入：prices = [7,6,4,3,1] \r\n    输出：0 \r\n    解释：在这个情况下, 没有交易完成, 所以最大利润为 0。\r\n\r\n思路：我们可做的交易数为0，1，2，也就是说最多可以做两笔交易。那么我们可以以第i天为界，计算出[0 - i]最大收益数和[i - n]最大收益数之和，得到的结果就是我们想要的答案。<div align=\"center\"><img src=\"../resources/img/leetcode_123_1.jpg\"></div>\r\n\r\n附上代码\r\n\r\n    //123.买卖股票的最佳时机 III\r\n    public int maxProfit(int[] prices) {\r\n        int ans = 0;\r\n        int len = prices.length;\r\n        //前i + 1天所能得到的最大收益\r\n        int[] beforeProfits = new int[len];\r\n        int min = prices[0],max = prices[0];\r\n        for (int i = 1; i < len; i++) {\r\n            min = Math.min(min,prices[i]);\r\n            max = Math.max(max,prices[i]);\r\n            beforeProfits[i] = Math.max(beforeProfits[i - 1],prices[i] - min);\r\n        }\r\n        min = prices[len - 1];\r\n        max = prices[len - 1];\r\n        //后n - i天所能得到的最大收益\r\n        int[] afterProfits = new int[len];\r\n        for (int i = len - 2; i >= 0; i--) {\r\n            min = Math.min(min,prices[i]);\r\n            max = Math.max(max,prices[i]);\r\n            afterProfits[i] = Math.max(afterProfits[i + 1],max - prices[i]);\r\n        }\r\n        for (int i = 0; i < len; i++) {\r\n            ans = Math.max(ans,beforeProfits[i] + afterProfits[i]);\r\n        }\r\n        return ans;\r\n    }\r\n\r\n"}},{"title":"42.接雨水","payload":{"title":"42.接雨水","date":"2022-05-03","tags":["leetcode"],"categories":"leetcode","content":"\r\n\r\n> 题目描述\r\n\r\n给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\r\n\r\n> 例1\r\n\r\n    输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]\r\n    输出：6\r\n\r\n> 例2\r\n\r\n    输入：height = [4,2,0,3,2,5]\r\n    输出：9\r\n\r\n> 思路\r\n\r\n- 首先找出所有的制高点，所谓制高点就是广义极大值点\r\n- （关键）以每个制高点为左边界，找到其右边界。具体做法是沿着制高点数组向右找第一个大于等于的制高点作为右边界，如果找到头也没找到，则把其中最大的作为右边界\r\n- 从最左制高点开始将其作为左边界，将上一步找到的其右边界作为右边界，找到它们当中的较低点作为水平面值，从此点开始向左或者向右将深度加到结果中去，直到遇到某处的高度大于水平面值为止。之后将右边界作为左边界循环此步，直到边界抵达最右制高点。\r\n\r\n> 附上代码\r\n\r\n    public int trap(int[] height) {\r\n        int ans = 0;\r\n        int len = height.length;\r\n        if(len == 1){\r\n            return ans;\r\n        }\r\n        //制高点list\r\n        List<Integer> list = new ArrayList<>();\r\n        //将所有制高点的数组下标按顺序放入list中\r\n        if(height[0] >= height[1]){\r\n            list.add(0);\r\n        }\r\n        for (int i = 1; i < len - 1; i++) {\r\n            if(height[i] >= height[i - 1] && height[i] >= height[i + 1]){\r\n                list.add(i);\r\n            }\r\n        }\r\n        if(height[len - 1] >= height[len - 2]){\r\n            list.add(len - 1);\r\n        }\r\n        int size = list.size();\r\n        //所有制高点的右边界的list下标\r\n        int[] rightFirstHigher = new int[size];\r\n        rightFirstHigher[size - 1] = size;\r\n        //关键步骤，从右向左找到所有制高点的右边界的list下标\r\n        for (int i = size - 2; i >= 0; i--) {\r\n            //next期望找到第一个大于等于当前制高点的下标，nextI为未找到next前小于当前制高点的最高点的下标\r\n            int h = height[list.get(i)],next = i + 1,nextI = i + 1;\r\n            while (next < size && height[list.get(next)] < h){\r\n                if(height[list.get(next)] > height[list.get(nextI)]){\r\n                    nextI = next;\r\n                }\r\n                next = rightFirstHigher[next];\r\n            }\r\n            //没找到，右边界为nextI，否则为next\r\n            rightFirstHigher[i] = next == size ? nextI : next;\r\n        }\r\n        //统计各区间的水量\r\n        for (int i = 0; i < size - 1; i=rightFirstHigher[i]) {\r\n            int left = list.get(i),right = list.get(rightFirstHigher[i]);\r\n            int min = Math.min(height[left],height[right]);\r\n            if(height[left] < height[right]){\r\n                for (int j = left + 1; j < right; j++) {\r\n                    //保证不大于水平面高度\r\n                    if(height[j] > min){\r\n                        break;\r\n                    }\r\n                    ans += min - height[j];\r\n                }\r\n            }else {\r\n                for (int j = right - 1; j > left; j--) {\r\n                    if(height[j] > min){\r\n                        break;\r\n                    }\r\n                    ans += min - height[j];\r\n                }\r\n            }\r\n        }\r\n        return ans;\r\n    }\r\n\r\n时空间复杂度感人:joy:\r\n"}},{"title":"DDD领域驱动设计","payload":{"title":"DDD领域驱动设计","categories":"软技能","tags":["设计思想"],"date":"2023-04-05","content":"\n\n领域驱动设计，一个理解是领域模型驱动设计模型。领域模型表达的是与业务相关的事实，设计模型描述的是所要构建的系统。\n\n\nquestion：DDD是否与scrum冲突？\n\n\n按照美团技术团队的理解，他们将解决复杂和大规模软件的武器大致分为了三类：抽象、分治和知识。\n\n- 分治：把问题空间分割为规模更小且易于处理的若干子问题。分割后的问题需要足够小，以便一个人单枪匹马就能够解决他们；其次，必须考虑如何将分割后的各个部分分装配为整体。分割得越合理越易于理解，在装配成整体时，所需跟踪的细节也就越少。即更容易设计各部分的协作方式。评判什么是分治得好，即高内聚低耦合。\n- 抽象：使用抽象能够精简问题空间，而且问题越小越容易理解。\n- 知识：DDD可以认为是知识的一种。DDD提供知识手段，让我们知道如何抽象出限界上下文以及如何去分治。\n\n领域驱动设计与微服务架构是天然耦合的。架构设计活动可以被精简为三个层面：\n\n- 业务架构-根据业务需求设计业务模块及其关系\n- 系统架构-设计系统和子系统的模块\n- 技术架构-决定采用的技术及其框架\n\nDDD的核心诉求就是讲业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。而微服务追求业务层面的复用，设计出来的系统架构和业务一致；在技术架构上则系统模块之间充分耦合，可以自由地选择合适的技术架构，去中心化地治理技术和数据。\n\n\n美团技术团队的领域模型设计一般实践分为5个步骤：\n\n1. 根据需求划分出初步的领域和限界上下文，以及上下文之间的关系；\n2. 进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象；\n3. 对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根；\n4. 为聚合根设计仓储，并思考实体和值对象的创建方式；\n5. 在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。\n\n领域\n\n\n现实世界中，领域包含问题域和解系统。在DDD中，解系统可以映射为一个个限界上下文，限界上下文就是软件对于问题域的一个特定的、有限的解决方案。\n\n\n一个给定的业务领域会包含多个限界上下文，想与一个限界上下文沟通，则需要通过显示边界进行通信。系统通过确定的限界上下文来进行解耦，而每一个上下文内部紧密组织，职责明确，具有较高的内聚性。\n\n\n一个很形象的隐喻：细胞质所以能够存在，是因为细胞膜限定了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜。\n\n\n如何划分限界上下文\n\n\n在美团技术团队的实践中，具体做法是考虑产品所讲的通用语言，从中提取一些术语称之为概念对象，寻找对象之间的联系；或者从需求中提取一些动词，观察动词之间的关系；将紧耦合的各自圈在一起，观察他们内在的联系，从而形成对应的限界上下文。形成之后，尝试用语言来描述限界上下文的职责，看它是否清晰、准确、简洁和完整。简言之，限界上下文应该从需求出发，按领域划分。\n\n\n上下文映射图\n\n\n在进行上下文划分之后，下一步要做的就是梳理上下文之间的关系。\n\n\n> 康威定律\n\n\n任何组织在设计一套系统时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。\n\n\n所以团队结构应该和限界上下文保持一致。\n\n\n> 限界上下文之间的映射关系\n\n- 合作关系：两个上下文紧密合作的关系，一荣俱荣，一损俱损\n- 共享内核：两个上下文依赖部分共享的模型\n- 客户方-供应方开发：上下文之间有组织的上下游依赖\n- 遵奉者：下游上下文只能盲目依赖上游上下文\n- 防腐层：一个上下文通过一些适配和转换与另一个上下文交互\n- 开放主机服务：定义一种协议来让其他上下文对本上下文进行访问\n- 发布语言：通常和OHS一起使用，用于定义开放主机协议\n- 大泥路：混杂在一起的上下文关系，边界不清晰\n- 另谋他路：两个完全没有任何联系的上下文\n\n战术建模—细分上下文\n\n\n> 实体\n\n\n当一个对象由其标识(而不是属性)区分时，这种对象称为实体。比如公安系统的身份信息录入，每个人都是独一无二的，且具有唯一标识的，可以被认为是实体。\n\n\n> 值对象\n\n\n当一个对象用于对事务进行描述而没有唯一标识时，它被称作值对象。\n\n\n> 聚合根\n\n\n聚合是一组相关对象的集合，作为一个整体被外界访问，聚合根是这个聚合的根节点。聚合由根实体，值对象和实体组成。\n\n\n> 领域服务\n\n\n一些重要的领域行为或操作，可以归类为领域服务。它既不是实体，也不是值对象的范畴。\n\n\n> 领域事件\n\n\n领域事件是对领域内发生的活动进行的建模。\n\n"}},{"title":"http协议","payload":{"title":"http协议","categories":"网络","tags":["http","网络"],"date":"2023-04-13","content":"\n\n参考：\n\n\n[https://www.shouxicto.com/article/4093.html](https://www.shouxicto.com/article/4093.html)\n\n\n### HTTP/1.1\n\n- 长连接\n\nHTTP/1.0中，默认使用的是短连接，就是每次请求都要重新建立一次连接。HTTP/1.1默认使用长连接Connection : keep-alive。\n\n- 管道\n\npipeline指客户端拥有连续发送请求的能力，但是客户端没有分辨响应的能力，即存在响应队头阻塞的问题。\n\n\n### HTTP/2\n\n\n相比较HTTP/1.1,HTTP/2做了如下改进\n\n- 二进制分帧层(核心)\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d8dd31b1-bcf7-4d65-85e7-e0ce09894cb5/HTTP2.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=8f00999b3cec5679ac91f3986a9840d3bc1cc1b8b854165c61e2180542984a17&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n二进制分帧层是指位于套接字接口和应用可见的高级HTTP API之间一个经过优化的新编码机制。在二进制分帧层上，HTTP/2.0会将所有传输信息分割为更小的消息和帧，并对它们采用二进制格式的编码，其中HTTP/1.x的首部信息会被封装到Headers帧，request body则封装到Data帧中。\n\n- 头部压缩\n\n每个HTTP传输都承载一组标头来说明传输的资源及其属性。在HTTP/1.x中，此元数据始终以纯文本的形式传输，通常高达500-800字节，如果使用HTTP Cookie，有事会达到上千字节。\n\n\nHTTP/2使用HPACK压缩格式压缩请求和响应标头元数据，这种格式由两种技术支持：\n\n1. 使用静态霍夫曼代码对传输的标头字段进行编码，从而缩小各个传输的大小。\n2. 客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表，即建立一个共享的压缩上下文，此表随后会用作参考，对之前传输的值进行有效编码。\n\nHTTP/2.0在客户端和服务端使用“首部表”跟踪和储存之前发送的键值对，对于相同的数据，不再通过每次请求和响应发送;通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型,等等)只需发送一次。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/08d37a32-fd07-4378-ada5-13e95f915cd9/HTTP2%E9%A6%96%E9%83%A8%E8%A1%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=c8558b68e929372351da213a574caebfb0cf92a1154bd3343ed7df0ecd95b207&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 多路复用\n\n在HTTP/1.x中数据是基于文本的有序传输，不能并行传输并且接收端又不知道数据包的顺序。HTTP/2中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将HTTP消息分解为互不依赖的帧，然后交错发送，在另一端再将其组装起来。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/280a438c-7404-4601-8c4d-d9fa8598ceb7/HTTP2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=71da3ab359f59857bfef9171ee99cc22befe35fbe837bc343abdb15222c774ad&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 服务器推送\n\nHTTP/2可以对一个请求发送多个响应，即除了最初请求的响应外，服务器还可以向客户端推送额外资源，而无需客户端明确地请求。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/20b147a9-3bb2-4f50-adc8-05a9038989b8/HTTP2%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=dfa0e1f0276e29ef519e8e8fc918f36883c90d00aa6b55bd510eefda6de4f95e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n### HTTP/2的缺点\n\n\nHTTP2的缺点一是建立连接的时间长，二是队头阻塞的问题依旧存在。而HTTP2的这两个缺点，都是因为HTTP2是基于TCP的应用层协议，tcp的三次握手消耗1.5RTT，加上TLS加密握手，则需要消耗3RTT，HTTP2虽然解决了http消息队头阻塞问题，但是并没有解决TCP队头阻塞问题。HTTP2废弃了管道化的方式，而引入帧、消息和数据流的概念，客户端和服务端可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来，解决了HTTP1.1队头阻塞的问题（一个响应返回发生延迟，其后续的响应都会被延迟，直到队头的响应送达）。TCP传输中会将数据拆分成一个一个小的有序的数据包，如果其中一个数据包没有按序到达，接收端就会保持连接等待数据包返回，这是就会阻塞后续的请求，造成TCP队头阻塞。\n\n\nHTTP/1.1 管道化持久连接也是使得同一个TCP连接可以被多个HTTP使用，但是HTTP/1.1中规定一个域名可以有6个TCP连接，而HTTP/2中，同一个域名只使用一个TCP连接，一旦HTTP/2中TCP队头阻塞所造成的影响会更大，因为HTTP/2的多路复用技术使得多个请求其实是基于同一个TCP连接的，如果某一个请求造成了TCP队头阻塞，那么多个请求都会受到影响。\n\n\n### HTTP/3\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/83871cf5-cec0-4f54-b13e-37d46815f9e0/HTTP3.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=e1120e9737dd47ae49ffe6a112b6f5ea6d3487dc3c03541826487d0a3316f10a&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 实现了类似 TCP 的流量控制、传输可靠性的功能。虽然 UDP 不提供可靠性的传输，但 QUIC 在 UDP 的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些 TCP 中存在的特性。\n- 集成了 TLS 加密功能。目前 QUIC 使用的是 TLS1.3，相较于早期版本 TLS1.3 有更多的优点，其中最重要的一点是减少了握手所花费的 RTT 个数。\n- 实现了 HTTP/2 中的多路复用功能。和 TCP 不同，QUIC 实现了在同一物理连接上可以有多个独立的逻辑数据流。实现了数据流的单独传输，就解决了 TCP 中队头阻塞的问题。\n"}},{"title":"Nginx必知必会","payload":{"title":"Nginx必知必会","categories":"nginx","tags":["nginx","运维","devops"],"date":"2022-11-16","content":"\n\n[在centos下安装Nginx](b43b9a0b-0311-412a-a38d-0720a9a8df76)\n\n1. 在/etc/yum.repo.d下新建文件nginx.repo定义Nginx软件仓库细节\n\n\t```shell\n\t[nginx]\n\tname=nginx repo\n\t#OS example centos,OSRELEASE example 7.x\n\tbaseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/\n\tgpgcheck=0\n\tenabled=1\n\t```\n\n2. 执行nginx下载，配置nginx自启动，配置防火墙\n\n\t```shell\n\tyum -y install nginx\n\tsystemctl enable nginx\n\tsystemctl start nginx\n\tfirewalld-cmd --permanent --zone=public --add-port=80/tcp\n\tfirewall-cmd --reload\n\t```\n\n\n[nginx关键文件，文件夹以及命令](7de1a27a-f767-40b5-83e3-4605e4d1eafe)\n\n- 文件(夹)\n\n| /etc/nginx/               | nginx配置文件默认的文件夹根地址                                        |\n| - |  |\n| /etc/nginx/nginx.conf     | nginx默认的配置文件入口，设置了工作进程，管道，日志，加载动态模块的配置。该文件中还包含指向其他配置文件的引用 |\n| /etc/nginx/conf.d/        | 该文件夹下包含默认的HTTP服务配置文件                                      |\n| /etc/nginx/stream.conf.d/ | 该文件夹下包含stream配置文件                                         |\n| /var/log/nginx/           | 默认的日志文件夹，包含access.log和error.log                           |\n\n- 命令\n\n| nginx -h        | nginx help菜单                                         |\n|  | - |\n| nginx -v        | 版本                                                   |\n| nginx -V        | 版本，构建信息，配置参数                                         |\n| nginx -t        | 测试nginx配置                                            |\n| nginx -T        | 测试nginx配置并且打印有效配置                                    |\n| nginx -s signal | 给nginx主进程发送命令，signal example：stop quit reload reopen |\n\n\n[优雅地重启nginx](7a802821-4a1c-47be-845e-1d280bd19658)\n\n\nnginx -s reload\n\n\n[nginx负载均衡](802bf27b-a1b2-4df0-b30a-405c9d425ff8)\n\n- HTTP负载均衡\n\n\t```shell\n\tupstream backend {#upstream模块控制nginx的负载均衡\n\t\n\t\t#在两个HTTP server间做负载均衡，weight越大权重越大\n\t\tserver 10.10.12.45:80 weight=1;\n\t\tserver app.example.com:80 weight=2;\n\t\n\t\t#一个后备，当上面两个服务挂掉时启用\n\t\tserver spare.example.com:80 backup;\n\t}\n\tserver {\n\t\tlocation / {\n\t\t\tproxy_pass http://backend;\n\t\t}\n\t}\n\t```\n\n- TCP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream mysql_read {\n\t\t\tserver read1.example.com:3306 weight=5;\n\t\t\tserver read2.example.com:3306;\n\t\t\tserver 10.10.12.34:3306 backup;\n\t\t}\n\t\tserver {\n\t\t\tlisten 3306;\n\t\t\tproxy_pass mysql_read;\n\t\t}\n\t}\n\t```\n\n\n\t这个配置不会被放在conf.d文件夹下，应当创建一个stream.conf.d文件夹，在nginx.conf中加入以下配置。\n\n\n\t```shell\n\tstream{\n\t\t\tinclude /etc/nginx/stream.conf.d/*.conf;\n\t}\n\t```\n\n- UDP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream ntp {\n\t\t\tserver ntp1.example.com:123 weight=2;\n\t\t\tserver ntp2.example.com:123;\n\t\t}\n\t\tserver {\n\t\t\tlisten 123 udp;\n\t\t\tproxy_pass ntp;\n\t\t}\n\t}\n\t```\n\n\nnginx默认采用的是Round-robin轮询调度算法，nginx支持多种负载均衡方法如：最少连接，最少耗时，一致性hash，IP hash，随机调度等。可以在upstream block中进行配置：\n\n\n```shell\nupstream backend {\n\tleast_conn;\n\tserver backend.example.com;\n\tserver backend1.example.com;\n}\n```\n\n\n| Round robin       | 默认方式，按顺序分配请求给服务集群。可以通过配置weight使其成为weighted round robin                                                             |\n| -- |  |\n| Least connections | 将请求分配给打开连接数最少的服务器，可以通过weight给每个服务器设置权重                                                                             |\n| Least time        | 只在nginx plus中可用                                                                                                    |\n| Generic hash      | [https://zh.m.wikipedia.org/zh-hans/一致哈希](https://zh.m.wikipedia.org/zh-hans/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C) |\n| Random            | 随机算法，考虑weight                                                                                                      |\n| IP hash           | IP地址作为hash参数，考虑weight                                                                                              |\n\n\n[nginx流量管理](daebaa2d-2f3c-4d3c-a6e4-dc0b0bb49bae)\n\n\n### A/B Testing\n\n\n将客户端导流到不同的应用版本\n\n\n```shell\nsplit_clients \"${remote_addr}AAA\" $variant {\n\t\t20.0% \"backendv2\";\n\t\t* \"backendv1\";\n}\n```\n\n\n### GeoIP Module\n\n- 下载nginx GeoIP模块包\n\n```shell\n#下载nginx-module-geoip\nyum install nginx-module-geoip\nmkdir /etc/nginx/geoip\ncd /etc/nginx/geoip\nwget \"http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz\"\ngunzip GeoIP.dat.gz\nwget \"http://geolite.maxmind.com/\\download/geoip/database/GeoLiteCity.dat.gz\"\ngunzip GeoLiteCity.dat.gz\n```\n\n- 然后在配置文件中进行配置\n\n```shell\n#load_module指令只在主context中有效\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n#geoip_country,geoip_city只在http context中有效\nhttp {\n\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n}\n```\n\n\n有了这个module就可以将地理信息传递给后端的应用，或者借助它来进行流量路由，例如可以基于国别进行控制\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\t#来自美国的IP，变量country_access被置为0，其他被置为1\n\t\tmap $geoip_country_code $country_access{\n\t\t\t\t\"US\" 0;\n\t\t\t\tdefault 1;\n\t\t}\n\t\t#在server block中进行配置\n\t\tserver{\n\t\t\t\t#非美国的IP禁止访问\n\t\t\t\tif($country_access = '1'){\n\t\t\t\t\t\treturn 403;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n如果客户端在nginx之前途经其他的代理，可以配置找到其原始IP\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\t\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n\n\t\t#CIDR 指示nginx利用X-Forwarded-For头去查询客户端地址\n\t\tgeoip_proxy 10.0.16.0/26;\n\n\t\t#递归查找\n\t\tgeoip_proxy_recursive on;\n}\n```\n\n\n### 按照一定的规则限制连接数，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\tlimit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;\n\t\tlimit_conn_status 429;\n\t\tserver{\n\t\t\t\tlimit_conn limitbyaddr 40;\n\t\t}\n}\nlimit_conn_status和limit_conn指令在http、server、location context中有效\nlimit_conn_zone则只在http context中有效\n```\n\n\n预定义的key即规则要按照实际情况进行设置。比如请求来自NAT网络，那么根据IP地址限制连接数就是不合理的。limit_conn_zone后的字符串可以是任意数量的nginx可用变量，可以在应用层的级别去识别一个用户，比如说通过session cookie。默认的http状态码是503，但是其实服务是可用的，只是被限制了访问，所以429是更好的选择来暗示是客户端的问题\n\n\n### 按照一定的规则限制流量，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\t#速率被限制为3r/s，可以以秒或者分钟的粒度进行限流\n\t\tlimit_req_zone $binary_remote_addr zone=limitbyaddr:10m rate=3r/s;\n\t\tlimit_req_status 429;\n\t\tserver{\n\t\t\t\tlimit_req zone=limitbyaddr;\n\t\t\t\tlocation / {\n\t\t\t\t\t\t#二阶段限速，burst允许速率提升到其值而不拒绝请求\n\t\t\t\t\t\t#第二个参数有delay和nodelay选项\n\t\t\t\t\t\t#nodelay选项会立即消费brust的请求\n\t\t\t\t\t\t#但是在floor(brust/rate)时间后才会继续接受来自该客户端的请求\n\t\t\t\t\t\t#delay选项则会先消费delay数的请求，之后的延迟消费\n\t\t\t\t\t\tlimit_req zone=limitbyaddr burst=12 delay=9;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n_超出限制的访问请求会被记录到error.log中。_\n\n\n### 限制带宽\n\n\n通过配置限制每个客户端的下载带宽\n\n\n```shell\nlocation /download/ {\n\t\t#在下载10m的资源后会被限速1m/s\n\t\tlimit_rate_after 10m;\n\t\tlimit_rate 1m;\n}\n```\n\n\n[nginx内容缓存](f3dcfc09-4c20-426c-895e-f313c1003d64)\n\n\n[nginx动态配置的能力](0afd3e8d-3820-4ea7-8716-1ef02dd5a14c)\n\n\n[nginx认证](180d99e4-2155-4b93-ad35-0b3439dcb6df)\n\n\n### HTTP Basic认证\n\n\n生成一个包含用户名和密码的文件\n\n\n```shell\n#comment\n#password可以是加密或者hash后的字符串，加密使用C函数crypt()\n#具体操作方式是下载OpenSSL，执行openssl passwd password\n#password可以通过多种方式进行混淆，但是通常是不安全的，因为可以进行暴力破解\nname1:password1\nname2:password2:comment\nname3:password3\n```\n\n\n在配置文件中配置指令使得认证生效\n\n\n```shell\nlocation / {\n\t\t#未认证通过的请求显示Private site\n\t\tauth_basic \"Private site\";\n\t\tauth_basic_user_file conf.d/passwd;\n}\nauth_basic可以在http、server、location中进行配置\n```\n\n\n### 认证子请求，即对请求进行授权认证\n\n\n可以使用http_auth_request_module在将实际请求转发给相应服务前先由认证服务进行身份鉴别\n\n\n```shell\nlocation /private/ {\n\t\tauth_request /auth;\n\t\t#从auth服务中带出的一些变量\n\t\tauth_request_set $auth_status $upstream_status;\n}\n\nlocation = /auth {\n\t\tinternal;\n\t\tproxy_pass http://auth-server;\n\t\t#不需要body的场景\n\t\tproxy_pass_request_body off;\n\t\tproxy_set_header Content-Length \"\";\n\t\tproxy_set_header X-Original_URI $request_uri;\n}\n```\n\n\n[nginx安全控制](85eaab33-5d9d-4895-950c-cb71775c9c46)\n\n\n### 基于IP地址的访问控制\n\n\n```shell\nlocation /admin/ {\n\t\t#允许10.0.0.0/20域下除了10.0.0.1的访问\n\t\tdeny 10.0.0.1;\n\t\tallow 10.0.0.0/20;\n\t\t#允许2001:0db8::/32子网下所有IPV6地址的访问\n\t\tallow 2001:0db8::/32;\n\t\t#拒绝其他IP的请求\n\t\tdeny all;\n}\n\nallow、deny指令在http，server，location以及基于TCP/UDP的stream，server context中都是有效的\n```\n\n\n### 允许跨域资源共享(CORS)\n\n\n```shell\n#http 方法映射\nmap $request_method $cors_method {\n\t\tOPTIONS 11;\n\t\tGET 1;\n\t\tPOST 1;\n\t\tdefault 0;\n}\nserver {\n\t\tlocation / {\n\t\t\t\tif($cors_method ~ '1'){\n\t\t\t\t\t\t#允许跨域的方法\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\n\t\t\t\t\t\t#允许跨域的域名规则\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Origin' '*.example.com';\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Headers' \n\t\t\t\t\t\t\t'DNT,Keep-Alive,User-Agent,X-Request-With,\n\t\t\t\t\t\t\tIf-Modified-Since,Cache-Control,Content-Type';\n\t\t\t\t}\n\t\t\t\t#OPTION方法发送预检请求，获取服务的CORS规则\n\t\t\t\tif($cors_method = '11'){\n\t\t\t\t\t\t#在客户端缓存20天\n\t\t\t\t\t\tadd_header 'Access-Control-Max-Age' 1728000;\n\t\t\t\t\t\t#请求体为空\n\t\t\t\t\t\tadd_header 'Content-Type' 'text/plain; charset=UTF-8';\n\t\t\t\t\t\tadd_header 'Content-Length' 0;\n\t\t\t\t\t\treturn 204;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n### 客户端侧的加密\n\n\n```shell\n#利用一个SSL module对流量进行加密，比如ngx_http_ssl_module或者ngx_stream_ssl_module\n\nhttp { # All directives used below are also valid in stream\n\t\tserver {\n\t\t\t\t#设置一个SSL/TLS服务侦听在8443端口\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#服务证书，即发给客户端的公钥\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#用于加解密的密钥，实际上是服务端用的私钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.key;\n\t\t}\n}\n```\n\n\n### 加强客户端侧加密\n\n\n证书和证书秘钥既可以通过文件路径的方式进行配置，也可以通过变量参数的方式进行配置，客户端所能提供的最强等级标准和服务器所能接受的标准将是最终协议的结果。\n\n\n```shell\nhttp { #所有的指令在stream中也可以使用\n\t\tserver {\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#允许的ssl协议以及cipher\n\t\t\t\tssl_protocols TLSv1.2 TLSv1.3;\n\t\t\t\t#密码被设置为最高标准，拒绝aNULL,MD5\n\t\t\t\tssl_ciphers HIGH:!aNULL:!MD5;\n\t\t\t\t\n\t\t\t\t#RSA证书文件\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#RSA秘钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.pem;\n\n\t\t\t\t#变量中设置的证书使用椭圆曲线数字签名算法（ECC）\n\t\t\t\tssl_certificate $ecdsa_cert;\n\t\t\t\t#变量中设置的ECC形式的秘钥\n\t\t\t\tssl_certificate_key data:$ecdsa_key_path;\n\t\t\t\t\n\t\t\t\t#允许nginx缓存协议10分钟，内存配置为10m\n\t\t\t\tssl_session_cache shared:SSL:10m;\n\t\t\t\tssl_session_timeout 10m;\n\t\t}\n}\n\n#在相同强度下，ECC比RSA快\n```\n\n\n### 上游加密\n\n\n对nginx和上游服务之间的流量进行加密并且进行特定协议协商\n\n\n```shell\nlocation / {\n\t\tproxy_pass https://upstream.example.com;\n\t\tproxy_ssl_verify on;\n\t\t#确保nginx验证上游服务的证书有效深度最多为2\n\t\tproxy_ssl_verify_depth 2;\n\t\t#只接受TLSv1.2，默认所有版本\n\t\tproxy_ssl_protocols TLSv1.2;\n}\n```\n\n\n### 保护一个location block\n\n\n```shell\nlocation /resources {\n\t\t#安全秘钥\n\t\tsecure_link_secret mySecret;\n\t\tif($secure_link = \"\") {\n\t\t\t\treturn 403;\n\t\t}\n\t\trewrite ^ /secured/$secure_link;\n}\nlocation /secured/ {\n\t\tinternal;\n\t\troot /var/www;\n}\n```\n\n\n👆配置了一个内部block和一个公开block。如果请求的URI中包含一个md5 hash字符串并且能够被secure_link_secret指令提供的秘钥认证，则请求地址会被重写，并且交给内部block处理，否则请求会被拒绝，收到403的回复。\n\n\n### 使用秘钥生成一个安全链接\n\n\n上个单元中的合法URI长什么样子呢，举个例子，我们访问域名为www.example.com的服务器上的/var/www/secured/index.html资源，那么就需要根据index.html这个资源生成md5的十六进制编码，具体操作如下：\n\n\n```shell\necho -n 'index.htmlmySecret' | openssl md5 -hex\n(stdin)= a53bee08a4bf0bbea978ddf736363a12\n```\n\n\n然后这个生成的md5十六进制摘要会被拼接到URI中\n\n\n```shell\nwww.example.com/resources/a53bee08a4bf0bbea978ddf736363a12/index.html\n```\n\n\n这就是一个合法的URI。\n\n\n### 使用一个过期日期保护一个location block\n\n\n只有合法且在有效期内的链接才能够访问资源\n\n\n```shell\nlocation /resources {\n\t\troot /var/www;\n\t\t#第一个参数持有md5 hash，第二个参数是Unix epoch格式的link过期时间\n\t\t#arg_md5是一个http参数\n\t\tsecure_link $arg_md5,$arg_expires;\n\t\t#用于生成md5编码的字符串格式\n\t\tsecure_link_md5 \"$secure_link_expires$uri$remote_addrmySecret\";\n\t\t#如果是个无效的URI\n\t\tif($secure_link = \"\"){return 403;}\n\t\t#如果是个有效的URI但是已经过期了\n\t\tif($secure_link = \"0\"){return 410;}\n}\n```\n\n\n### 生成一个带过期时间的链接\n\n\n在unix系统中生成unix时间戳可以使用date指令\n\n\n```shell\n$ date -d \"2030-12-31 00:00\" +%s --utc\n1924905600\n```\n\n\n接下来要做的就是将在secure_link_md5指令中配置的字符串参数进行拼接，再上一个单元中拼接成的字符串则为1924905600/resources/index.html127.0.0.1 mySecret .在这里的MD5 hash同16进制摘要的MD5 hash有一些不同，它是二进制格式的，并且是将+转换为-，/转换为_，去掉=的base64编码。在unix系统中的一个例子如下：\n\n\n```shell\n$ echo -n '1924905600/resources/index.html127.0.0.1 mySecret' \\\n\t| openssl md5 -binary \\\n\t| openssl base64 \\\n\t| tr +/ -_ \\\n\t| tr -d =\nsqysOw5kMvQBL3j9ODCyoQ\n```\n\n\n现在可以在URI中拼接生成的MD5参数\n\n\n```shell\n/resources/index.html?md5=sqysOw5kMvQBL3j9ODCyoQ&expires=1924905600 \n```\n\n\n### 将一个http请求重定向为一个https请求\n\n\n```shell\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\treturn 301 https://$host$request_url;\n}\nor\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\t#只有在http_x_forwarded_proto请求头为http时，才重定向\n\t\tif($http_x_forwarded_proto = 'http'){\n\t\t\t\treturn 301 https://$host$request_url;\n\t\t}\n}\n```\n\n\n### HTTP严格传输安全（HSTS）\n\n\n通过设置Strict-Transport-Security请求头让浏览器总是进行重定向将HTTP请求转换为HTTPS请求\n\n\n```shell\n#max-age=1 year\nadd_header Strict-Transport-Security max-age=31536000;\n```\n\n\n### 满足任意数量的保障安全方式\n\n\n```shell\nlocation / {\n\t\t#参数any or all\n\t\tsatisfy any;\n\t\t\n\t\t#允许192.168.1.0/24网络访问\n\t\tallow 192.168.1.0/24;\n\t\tdeny all;\n\t\t\n\t\t#basic认证访问\n\t\tauth_basic \"closed site\";\n\t\tauth_basic_user_file conf/htpasswd;\n}\n```\n\n"}},{"title":"spring security(servlet)","payload":{"title":"spring security(servlet)","categories":"Java","tags":["spring-security"],"date":"2023-02-22","content":"\n\n以下内容均是基于spring security 5.7.4版本，并且是基于webmvc。\n\n\n由于spring gateway的web依赖是webflux，webflux是spring基于响应式编程实践创建的web框架，如果要将spring security集成进spring gateway中，则需要对webflux以及projectreactor有一点了解。projectreactor参考[https://projectreactor.io/](https://projectreactor.io/)。webflux参考[https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html#spring-webflux](https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html#spring-webflux)。\n\n\nspring security是一个拥有认证，授权，提供网络保护的Java安全框架\n\n\n**架构篇**\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/acb6293f-2142-4c49-bf8f-ee6ff2597bbc/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=b5bfed3f9075809ff04944668725c99658c6bab268a7eafff496f581f7aaa254&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nspring securtiy的servlet是基于Filter的servlet。当客户端向应用发送请求时，servlet容器会创建一个包含有一系列过滤器和一个servlet的FilterChain Bean，这个bean会去处理基于请求URI生成的HttpServletRequest对象。\n\n\nFilterChain中的Filter的作用主要有两个，其一是防止下游的Filter或者Servlet被调用，那么这个Filter一般会返回一个HttpServletResponse。其二是修改被下游的Filter或者是Servlet使用的HttpServletRequest或HttpServletResponse。\n\n\nFilterChain用例\n\n\n```javascript\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) {\n\t// do something before the rest of the application\n    chain.doFilter(request, response); // invoke the rest of the application\n    // do something after the rest of the application\n}\n```\n\n\n**DelegatingFilterProxy**\n\n\nspring提供一个叫做DelegatingFilterProxy的Filter实现，这个类运用代理模式将servlet容器中的Filter和spring容器中的bean关联起来。基于DelegatingFilterProxy的机制，可以实现不同安全框架的融合。DelegatingFilterProxy的另一个好处是可以实现Filter bean的懒加载。\n\n\nDelegatingFilterProxy的伪码如下所示：\n\n\n```javascript\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) {\n\t// Lazily get Filter that was registered as a Spring Bean\n\tFilter delegate = getFilterBean(someBeanName);\n\t// delegate work to the Spring Bean\n\tdelegate.doFilter(request, response);\n}\n```\n\n\n**FilterChainProxy**\n\n\nspring security提供一个叫做FilterChainProxy的类，该类是一个特殊的Filter允许通过SecurityFilterChain代理一系列的Filter。既然FilterChainProxy是一个Filter的bean，它通常会被包在DelegatingFilterProxy中。\n\n\nSecurityFilterChain\n\n\n一个SecurityFilterChain中包含一系列的Filter，FilterChainProxy可以根据某个请求走哪一个过滤链。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/80db0144-3520-436b-9d58-1d64a781c435/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=717a76002bfaa76312c2e37ccd4a1d9e76181a49a34116a54b2b81820c9e2e37&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n**Security Filters**\n\n\nFilters的顺序对于程序的执行很重要。\n\n\nspring security filter的综合顺序如下\n\n- [`ForceEagerSessionCreationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/session-management.html#session-mgmt-force-session-creation)\n- ChannelProcessingFilter\n- WebAsyncManagerIntegrationFilter\n- SecurityContextPersistenceFilter\n- HeaderWriterFilter\n- CorsFilter\n- CsrfFilter\n- LogoutFilter\n- OAuth2AuthorizationRequestRedirectFilter\n- Saml2WebSsoAuthenticationRequestFilter\n- X509AuthenticationFilter\n- AbstractPreAuthenticatedProcessingFilter\n- CasAuthenticationFilter\n- OAuth2LoginAuthenticationFilter\n- Saml2WebSsoAuthenticationFilter\n- [`UsernamePasswordAuthenticationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/passwords/form.html#servlet-authentication-usernamepasswordauthenticationfilter)\n- OpenIDAuthenticationFilter\n- DefaultLoginPageGeneratingFilter\n- DefaultLogoutPageGeneratingFilter\n- ConcurrentSessionFilter\n- [`DigestAuthenticationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/passwords/digest.html#servlet-authentication-digest)\n- BearerTokenAuthenticationFilter\n- [`BasicAuthenticationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/passwords/basic.html#servlet-authentication-basic)\n- RequestCacheAwareFilter\n- SecurityContextHolderAwareRequestFilter\n- JaasApiIntegrationFilter\n- RememberMeAuthenticationFilter\n- AnonymousAuthenticationFilter\n- OAuth2AuthorizationCodeGrantFilter\n- SessionManagementFilter\n- [`ExceptionTranslationFilter`](https://docs.spring.io/spring-security/reference/servlet/architecture.html#servlet-exceptiontranslationfilter)\n- [`FilterSecurityInterceptor`](https://docs.spring.io/spring-security/reference/servlet/authorization/authorize-requests.html#servlet-authorization-filtersecurityinterceptor)\n- SwitchUserFilter\n\n处理**Security Exceptions**\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/06c70dbd-e31d-48d8-90e5-0244c3e1da06/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=c1e1bb041178890b54837ec948e2062dbb27247674c909730ca52887f0b79cf3&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nspring security的异常由ExceptionTranslationFilter处理，它本身也是一个Filter，它负责将AccessDeniedException和AuthenticationException转化为HTTP 响应。\n\n1. 首先, the ExceptionTranslationFilter调用 `FilterChain.doFilter(request, response)`\n去执行应用接下来的部分。\n2. 如果一个用户还没有认证过或者是一个AuthenticationException，就会启动认证流程。以下步骤会被执行，SecurityContextHolder会被清空。HttpServletRequest会被保存在RequestCache中，用来在认证通过之后进行请求重放。AuthenticationEntryPoint会被用来在认证失败后，进行特殊的认证流程。\n3. 如果上面的流程没有通过，就是一个AccessDeniedException。AccessDeniedHandler会对这种情况进行处理。\n\nExceptionTranslationFilter的伪码如下：\n\n\n```javascript\ntry {\n\tfilterChain.doFilter(request, response); \n} catch (AccessDeniedException | AuthenticationException ex) {\n\tif (!authenticated || ex instanceof AuthenticationException) {\n\t\tstartAuthentication(); \n\t} else {\n\t\taccessDenied(); \n\t}\n}\n```\n\n\n# **spring security的认证**\n\n\n### 与认证相关的一些概念和类\n\n\nSecurityContextHolder - spring security储存当前认证用户细节的地方\n\n\nSecurityContext - 可以从SecurityContextHolder 中获取，包含当前认证用户的Authenticaiton\n\n\nAuthenticaiton - 可以是作为AuthenticationManager输入用来提供一个用户进行认证的凭证，也可以是从SecurityContext 中获取的当前用户。\n\n\nGrantedAuthority - 在Authenticaiton 中授予给Principal的权限。\n\n\nAuthenticationManager - 定义了spring security Filter执行authentication的API。\n\n\nProviderManager - AuthenticationManager 的一般实现类。\n\n\nAuthenticationProvider - 被ProviderManager 用来执行特定的认证。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/14b7014e-7a40-4b85-8927-a884f19ae923/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=6be1ccb275d4c65cc14b6644c5a9be694425a0532eb6b307f07182941b073ce4&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nspring security认证的核心是SecurityContextHolder 。spring security并不关心SecurityContextHolder 怎么产生的，只要它有一个值，它就会被当作是当前的认证用户。\n\n\n最简单的指示一个认证用户的方式是直接设置SecurityContextHolder 。\n\n\n```javascript\n//1.创建一个空SecurityContext \nSecurityContext context = SecurityContextHolder.createEmptyContext(); \n//2.创建一个新的Authentication 对象\nAuthentication authentication =\n    new TestingAuthenticationToken(\"username\", \"password\", \"ROLE_USER\"); \ncontext.setAuthentication(authentication);\n\nSecurityContextHolder.setContext(context);\n```\n\n\n从SecurityContextHolder 中获取当前认证用户的方式\n\n\n```javascript\nSecurityContext context = SecurityContextHolder.getContext();\nAuthentication authentication = context.getAuthentication();\nString username = authentication.getName();\nObject principal = authentication.getPrincipal();\nCollection<? extends GrantedAuthority> authorities = authentication.getAuthorities();\n```\n\n\n**AbstractAuthenticationProcessingFilter**\n\n\nAbstractAuthenticationProcessingFilter是用于认证用户凭证的一个基本Filter，其大致的流程图如下：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/37772f05-68cc-446f-8747-a4d8b32d7d02/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=ee689335ddfb9c60027b8fd10598bc8e584bd5b404af4fda883b90d641bec67e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n1. 当用户提交他们的凭证时，AbstractAuthenticationProcessingFilter会从HttpServletRequest中构造出一个用于认证的Authentication对象。Authentication的类型取决于AbstractAuthenticationProcessingFilter的子类。比如UsernamePasswordAuthenticationFilter会创建UsernamePasswordAuthenticationToken。\n2. Authentication被传递给AuthenticationManager来进行认证。\n3. 如果认证失败，SecurityContextHolder被清空。RememberMeServices.loginFail被调用，如果remember me没有被设置，那么上面的函数便不会被调用。AuthenticationFailureHandler被掉用。\n4. 如果认证成功。\n- `SessionAuthenticationStrategy` 处理新的登录。\n- [Authentication](https://docs.spring.io/spring-security/reference/servlet/authentication/architecture.html#servlet-authentication-authentication) 被设置到 [SecurityContextHolder](https://docs.spring.io/spring-security/reference/servlet/authentication/architecture.html#servlet-authentication-securitycontextholder)。之后 `SecurityContextPersistenceFilter` 将 `SecurityContext` 保存到 `HttpSession`.\n- `RememberMeServices.loginSuccess` 被调用，如果remember me没有被设置，那么上面的函数便不会被调用。\n- `ApplicationEventPublisher` 发布一个 `InteractiveAuthenticationSuccessEvent。`\n- `AuthenticationSuccessHandler` 被调用。\n\n### 用户名密码登录\n\n\n用户名密码登录分为Form,Basic,Digest登录三种形式，spring security中的Form登录的账号名密码提交流程如下图所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/581243ef-bed4-4d3b-8850-49d134a77542/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=95ff2f5d11603fc1ebab7a57e881e12eaf42a19f75c230dd0121ba517f500560&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n一旦用户名密码被提交，UsernamePasswordAuthenticationFilter就开始执行它的认证工作，UsernamePasswordAuthenticationFilter继承自AbstractAuthenticationProcessingFilter,它的流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ea389297-5be0-404e-b7d8-494afdc20b90/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=2e69b676db9b71f12260b7eca232c3ec8c470dee96e7259a5391450055dd9bf3&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nFrom登录可以自定义配置，Java代码如下所示：\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t.formLogin(form -> form \n\t\t\t.loginPage(\"/login\") //你能控制的部分\n\t\t\t.permitAll()\n\t\t);\n\t// ...\n}\n```\n\n\nBasic HTTP Authentication是服务器向未认证客户端请求认证信息的一种登陆方式，在Spring中的流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7ae42cc3-dcbe-4d05-8f0b-68dd932cc60f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=9b5d13db6c679042701ccb4f2c44c665d8e4b6f381f8dab55aa2fe4cea6a17b6&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n同样的，拿到账号名密码之后会执行类似的认证流程：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fb58b283-dfd4-4411-9f58-29a36ff52c3a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=149a82ccbf624a5a1c4677ac7900fbe57f9c215a0cc6f61b4b630aaaf29d05ab&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nBasic登录的配置如下：\n\n\n```javascript\n@Bean\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t// ...\n\t\t.httpBasic(withDefaults());\n\treturn http.build();\n}\n```\n\n\nrabbitmq 管理端web登陆方式就是Form登录和Basic登录的结合。\n\n\nDigest登录略。\n\n\n**Persisting Authentication**\n\n\nspring security中与认证信息持久化相关的一个类是SecurityContextRepository，可以通过如下的方式进行配置：\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t// ...\n\t\t.securityContext((securityContext) -> securityContext\n\t\t\t.securityContextRepository(new RequestAttributeSecurityContextRepository())//**SecurityContextRepository的一个实现类**\n\t\t);\n\treturn http.build();\n}\n```\n\n\nSecurityContextPersistenceFilter负责将SecurityContext持久化，其流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7da295e8-dd44-4b91-aa70-e20694fdd1a2/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=b98f403dea02febcb4437fa8628db324cf49cec35398f21b798a04f7b84ccf4f&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nSecurityContextHolderFilter负责加载SecurityContext信息，其流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7d1355e0-9d67-4f2d-8268-598a54faac6f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=4ebf7b5f107a5672a7243666ce5204204f775d90c969d774c78a25e6c953044e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nSecurityContextHolderFilter不会显式的保存SecurityContext信息，需要在配置中明确信息的保存。\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t// ...\n\t\t.securityContext((securityContext) -> securityContext\n\t\t\t.requireExplicitSave(true)\n\t\t);\n\treturn http.build();\n}\n```\n\n\n### Logout\n\n\n一般来说，logout会自动配置。默认的URL - /logout将会执行用户登出操作：\n\n- 使session无效\n- 清除任何配置的RememberMe认证\n- 清除SecurityContextHolder\n- 重定向到/login?logout\n\n使用者可以自定义登出逻辑\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n    http\n        .logout(logout -> logout                                                \n            .logoutUrl(\"/my/logout\")  //自定义logout url                                       \n            .logoutSuccessUrl(\"/my/index\")  //登出成功重定向地址                               \n            .logoutSuccessHandler(logoutSuccessHandler)  //登出成功处理器，如果配了这个，logoutSuccessUrl将被忽略               \n            .invalidateHttpSession(true)                                     \n            .addLogoutHandler(logoutHandler)                                    \n            .deleteCookies(cookieNamesToClear)                                  \n        )\n        ...\n}\n```\n\n\n# **Authorization**\n\n\n### **Authorization Architecture**\n\n\n在授权中，核心对象是Authority。在认证完成之后，所有Authentication的实现类都会储存一个GrantedAuthority对象的列表，一个GrantedAuthority表示系统内某主体的一个权限。GrantedAuthority会在接下来AuthorizationManager的授权流程中被使用。\n\n\nGrantedAuthority是一个只提供一个方法的接口\n\n\n```javascript\nString getAuthority();\n```\n\n\nAuthorizationManager调用该方法获取一个表示该GrantedAuthority的字符串，通过该字符串作出授权决策。\n\n\n前置调用处理\n\n\nspring security提供两个Manager对收到的web请求的作前置权限控制。分别是AccessDecisionManager以及AccessDecisionManager。一般情况下官方推荐使用AuthorizationManager来代替AccessDecisionManager。AuthorizationManager被AuthorizationFilter调用，负责最终的访问控制。AuthorizationManager包含两个主要方法：\n\n\n```javascript\n//主体方法，负责做权限决策，如果授权成功返回一个positive AuthorizationDecision。否则则是negative的\nAuthorizationDecision check(Supplier<Authentication> authentication, Object secureObject);\n\n//调用check()，如果check()返回negative AuthorizationDecision,则抛出AccessDeniedException.\ndefault AuthorizationDecision verify(Supplier<Authentication> authentication, Object secureObject)\n        throws AccessDeniedException {\n    // ...\n}\n```\n\n\n### spring security的访问控制模型\n\n\nspring security基于RBAC（role based access control）实现其访问控制功能，RBAC的概念请参考[https://icyfenix.cn/architect-perspective/general-architecture/system-security/authorization.html#rbac](https://icyfenix.cn/architect-perspective/general-architecture/system-security/authorization.html#rbac)。\n\n\nspring security中的role可以是一种继承的结构。可以在配置文件中配置HierarchyVoter bean来进行设置。\n\n\n```javascript\n//ROLE_ADMIN ⇒ ROLE_STAFF ⇒ ROLE_USER ⇒ ROLE_GUEST, > 代表包含\n@Bean\nAccessDecisionVoter hierarchyVoter() {\n    RoleHierarchy hierarchy = new RoleHierarchyImpl();\n    hierarchy.setHierarchy(\"ROLE_ADMIN > ROLE_STAFF\\n\" +\n            \"ROLE_STAFF > ROLE_USER\\n\" +\n            \"ROLE_USER > ROLE_GUEST\");\n    return new RoleHierarchyVoter(hierarchy);\n}\n```\n\n\n**使用AuthorizationFilter对HttpServletRequests进行授权**\n\n\nAuthorizationFilter被插入FilterChainProxy中作为Security Filters的一份子。在configuration类中进行AuthorizationFilter配置。\n\n\n```javascript\n@Bean\nSecurityFilterChain web(HttpSecurity http) throws AuthenticationException {\n    http\n        .authorizeHttpRequests((authorize) -> authorize //可以配置一个bean\n            .anyRequest().authenticated();\n        )\n        // ...\n\n    return http.build();\n}\n```\n\n\n使用AuthorizationFilter的流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/90f57f18-5dd9-4ff0-a3e1-8b63c1ea17ee/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=fe408d6bcea809916481f87e02097a665cb999e09659bfa57c9b61a4fa54cbae&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n可以按照一定的优先顺序配置授权规则\n\n\n```javascript\n@Bean\nSecurityFilterChain web(HttpSecurity http) throws Exception {\n\thttp\n\t\t// ...\n\t\t.authorizeHttpRequests(authorize -> authorize                                  \n\t\t\t.mvcMatchers(\"/resources/**\", \"/signup\", \"/about\").permitAll()  //任何user都可以访问的路径       \n\t\t\t.mvcMatchers(\"/admin/**\").hasRole(\"ADMIN\")  //只有admin角色可以访问的路径                         \n\t\t\t.mvcMatchers(\"/db/**\").access((authentication, request) ->\n\t\t\t    Optional.of(hasRole(\"ADMIN\").check(authentication, request))\n\t\t\t        .filter((decision) -> !decision.isGranted())\n\t\t\t        .orElseGet(() -> hasRole(\"DBA\").check(authentication, request)); //同时拥有admin和dba可以访问的路径\n\t\t\t)   \n\t\t\t.anyRequest().denyAll() //其他未在上面配置的路径拒绝                                                \n\t\t);\n\n\treturn http.build();\n}\n```\n\n\n更多配置方式参考[https://docs.spring.io/spring-security/reference/servlet/authorization/authorize-http-requests.html](https://docs.spring.io/spring-security/reference/servlet/authorization/authorize-http-requests.html)。\n\n\nspring security支持SpEL,感兴趣可以参考[https://docs.spring.io/spring-security/reference/servlet/authorization/expression-based.html](https://docs.spring.io/spring-security/reference/servlet/authorization/expression-based.html)\n\n"}},{"title":"单元测试","payload":{"title":"单元测试","categories":"Java","tags":["测试"],"date":"2023-04-16","content":"\n"}},{"title":"并发探索","payload":{"title":"并发探索","categories":"Java","tags":["Java","并发"],"date":"2023-04-12","content":"\n\n[embed](https://miro.com/app/board/uXjVPaWzcGg=/?share_link_id=77380253885)\n\n\n[embed](https://miro.com/app/board/uXjVPZryvFY=/?share_link_id=495517938632)\n\n"}},{"title":"泛型实现","payload":{"title":"泛型实现","categories":"底层原理","tags":["泛型","编程语言原理"],"date":"2023-04-13","content":"\n\n参考，其实就是不成形的笔记\n\n\n[https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/](https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/)\n\n\n## 类型系统（Type system）\n\n\n### 类型内存布局（Type Memory Layout）\n\n\n在二进制的世界里，存储在内存中的数据在操作系统中看到的是一串比特序列，而在拥有类型之后这串比特序列才有一定的意义。\n\n\n### 类型检查\n\n- 强弱类型：\n\n强弱类型并没有标准的定义，但是普遍认为强弱类型的核心区别在于，语言能否在某一个时刻能检查出来类型导出的错误，而不是抛出运行时错误（Unchecked RuntimeError）。强类型的编程语言可以在类型不匹配时发生错误（编译与运行时都可能发生），而弱类型的语言在类型不匹配时会做隐式的类型转换或无视类型进行操作，这会导致无法预料的运行时错误。这二者区分出来的核心现象就是，弱类型语言往往无法信赖变量的值，需要写很多额外的代码做额外的类型验证操作。\n\n- 静动检查：\n\n动态与静态的区别在于类型检查发生的阶段，动态是在运行时阶段，静态是在编译阶段。但实际上一些编程语言是混合的类型检查，比如在C#中开发者可以通过关键字来标识此数据类型检查是动态还是静态的。不少静态类型检查的编程语言也有动态的类型检查，比如Java中既有编译阶段的静态类型检查，又有运行时的动态类型检查（如父类与子类的互相转换）。\n\n- 类型推导：\n\n一些编程语言虽然不需要开发者显示定义数据类型，但编译器能够做类型推导，帮助开发者定义数据类型，如Scala与Kotlin。\n\n\nJavaScript是一个弱类型的动态类型检查语言，C是一个弱类型的静态类型检查语言。\n\n\n### 实现泛型\n\n\n通常意义下的泛型也叫参数多态，指的是声明与定义函数、复合类型、变量时不指定其具体的类型，而把这部分类型作为参数使用，使得该定义对各种具体类型都适用。参数化多态使得语言更具表达力，同时保持了完全的静态类型安全。这被称为泛化函数、泛化数据类型、泛型变量，形成了泛型编程的基础。\n\n\n> 多态理论\n\n\n\t编程语言理论(PLT)中多态(Polymorphism)包含三个主要方面：特设多态(Ad-hoc)，参数多态(Parametric)和子类型(Subtyping)。\n\n\n\tAd-hoc：也叫重载(Overloading)，允许具有相同名称的函数对不同类型执行不同的操作。例如，`+`运算符即可以将两个整数相加，也可以连接两个字符串。\n\n\n\tSubtyping：也叫包容性多态(Inclusion)，是指通过基类指针和引用使用派生类的能力。\n\n\n子类型多态也称为运行时多态性，因为编译器在编译时不定位函数的地址，而是在运行时动态调用函数。派发分为三种：\n\n- 静态派发(Static dispatch/early binding)：当程序在编译时可以找到执行的函数。C++默认使用的是直接派发，加上`virtual`修饰符可以改成虚函数表(Vtable)派发。直接派发是最快的，原因是调用指令少，还可通过编译器进行内联等方式的优化。这种派发缺点是不灵活，无法实现一些面向对象所需的技术如多态性。\n- 动态派发(dynamic dispatch/run-time dispatch/virtual method call/late binding): 当程序在运行时可以找到执行的函数。Java默认使用的是虚函数表(Vtable)派发，通过`final`修饰符可改成直接派发。虚函数表派发是有动态性的，一个类里会用表来存储类成员函数的指针，子类重写(Override)父类的函数会替代父类的函数，子类添加的函数会被加到这个表里。当程序运行时派发时会从这个表中找到对应的函数，这样就可以实现动态派发。面向对象的编程语言正是靠此机制实现了多态性(Polymorphic)。\n- 消息机制(message passing)：通过消息传递来调用被执行的函数。这种机制是在运行时可以改变函数的行为，甚至函数可以未实现，也不会引发运行时错误。Objective-C中就是通过消息传递来调用被执行的函数，甚至可以在程序运行过程中实现热更新代码。\n\n静态派发的速度是最快的，但并不灵活。而动态派发虽然比较慢，但却可以实现面向对象多态的功能。消息机制是最灵活的方式，但性能也最差。\n\n\n[embed](https://miro.com/app/board/uXjVPabTn6A=/?share_link_id=402499999270)\n\n\n### 类型擦除\n\n\n对Java来说统一的数据类型就是Object，在编译阶段做完类型检查后就将类型信息通过转换成Object进行擦除，这样只需要生成一份泛型函数的副本即可。类型擦除保证了泛型函数生成的字节码和非泛型函数的是相同的，也符合Java对兼容性的要求。不过类型擦除也给Java的泛型带来了很多的限制。\n\n\n### 虚函数表(Vtable)\n\n\nJava通过类型擦除结合虚方法表来实现泛型的效果：运行时同样的数据类型Object，却能调用原始类型的方法。\n\n\n### 字典\n\n\n编译器在编译泛型函数时只生成了一份函数副本，通过新增一个字典参数来供调用方传递类型参数(Type Parameters)，这种实现方式称为字典传递(Dictionary passing)。\n\n\n### 单态化\n\n\n单态化的思路是自动生成多个类型的泛型函数版本，看起来就是一个模版代码生成的过程，但是也需要考虑很多种情况。比如：\n\n- 生成所有类型的函数版本：这种最简单，但是会拖慢编译时间，也会让最终的二进制文件变得很庞大。\n- 生成调用类型的函数版本：这种需要编译器分阶段或多次编译，比如需要遍历寻找调用点来确定最终的类型列表，对于不同包的同名函数的处理等。\n- 是否支持独立编译：如果调用泛型函数的类型与泛型函数不在同一个包内，是否能支持泛型函数独立的编译。\n\n模板\n\n\nC++通过模板实现泛型类、方法和函数，这导致编译器为每个唯一的类型参数集编译了代码的单独副本。这种方法的一个关键优势是没有运行时性能开销，尽管它以增加二进制文件大小和编译时间为代价。\n\n\n蜡印\n\n\n蜡印其实就是模版，也是一种代码生成技术。但Go除了使用字典传递实现装箱外，还采用了`GC Shape Stenciling`的技术。这种看起来很高级的名词简单来说是为了解决蜡印或模版的问题，因为在蜡印的过程中，编译器会为每一个实例化的类型参数生成一套独立的代码。\n\n"}},{"title":"使用redis实现分布式锁","payload":{"title":"使用redis实现分布式锁","date":"2022-04-29","tags":["redis","分布式锁"],"categories":"中间件","content":"\r\n\r\n## 使用redis实现分布式锁\r\n\r\n>同一操作系统下的线程竞态访问某一临界资源，我们可以使用锁来帮助我们达成目的，一些编程语言\r\n都会提供内置的锁库。但是当我们的执行线程并不运行在同一操作系统之下，单一实例下的锁机制就\r\n失效了，这种情况下，我们需要分布式锁机制来帮助我们协调管理线程之间的竞争。\r\n\r\n我们可以在redis的帮助下实现分布式锁机制。只需要一条简单的命令我们便能做到它。\r\n\r\n    set resource_name unique_value NX;\r\n在我们进入临界区之前，先尝试着向redis中插入一条数据，若该数据存在则获取锁失败，否则获取\r\n锁成功。不过这里有一个问题，就是若获取锁的线程在释放锁之前挂了，那么锁就无法被释放，其他线程\r\n也就没有办法获取到锁。为了解决这个问题，我们可以将unique_value设置为`expire_timestamp`，\r\n另外的线程可以get到`expire_timestamp`，若该时间戳小于当前时间戳，我们便可以执行del命令进而\r\n释放到锁，再执行获取锁的指令，就ok了。然而虽解决了锁无法释放的问题，却引入了新的问题。这里\r\n我们假设有两个线程在同一时刻检测到了锁失效，然后相继执行释放锁加锁的步骤，像下面这样：\r\n\r\n    Thread 1:del resource_name;\r\n    Thread 1:set resource_name unique_value NX;\r\n    Thread 2:del resource_name;\r\n    Thread 2:set resource_name unique_value NX;\r\n最终Thread1和Thead2都获得了锁，违反了分布式锁的含义。因此相应的，我们不应该将释放锁的权力\r\n交给其他线程。释放锁的工作应当由获取锁的线程去做，若该线程挂了，那么该锁应当超时自动释放，redis\r\n同样提供了这样的机制，将上面的改一改：\r\n\r\n    set resource_name unique_value NX EX expire_time;\r\n即使获取锁的线程挂了，该锁也能够在超时之后释放掉。但是呢，这个命令还是有问题。假设这把锁被超时释放了，\r\n另外的线程又获取到了这把锁，然而之前获取锁的线程并没有挂掉，它只是执行的比较慢而已，在另一个线程获取锁\r\n之后它才执行释放锁的操作，然后它就把其他线程的锁给释放掉了。显然这是不符合逻辑的，上面就提到没有把持锁\r\n的线程没有释放锁的权力，那么这个时候unique_value就起到了作用，当我们获取锁的时候将键对应的值设为\r\n全局唯一的某个值，比如timestamp + clientId，然后我们可以写一段Lua脚本\r\n\r\n    if redis.call(\"get\",KEY[1]) == ARGV[1]\r\n    then\r\n        return redis.call(\"del\",KEY[1])\r\n    else\r\n        return 0\r\n    end\r\n只有当对应的值与当前线程设的值一样时，当前线程才可以释放掉锁。redis内置的lua脚本解释器也保证了\r\n每段脚本执行的原子性，不必担心有其他意外发生。\r\n\r\n这些看起来很美好，但是不幸的是，依旧存在问题。如果我们的redis是master-slave架构，某个时刻master挂了，\r\n由于master和slave之间是异步的，如果新选出来的master没有这条锁的记录，那么其他线程便能够获取到该锁。那么\r\n有没有什么办法可以解决这个问题呢，答案是有的，大名鼎鼎的redlock就是为此诞生的。由于精力有限，redlock的讨论\r\n就过段时间再说，这里先挖个坑。\r\n"}},{"title":"编程相关小技巧","payload":{"title":"编程相关小技巧","date":"2022-04-29","tags":["技巧"],"categories":"技巧","content":"\r\n目前内容较少，没有分篇叙述的必要，预计达到100个`tip`开分\r\n\r\n1. 在vscode中编写markdown文档时自动换行\r\n> - ctrl + shift + p,打开命令窗口，输入setting，打开open user settings\r\n> - 在搜索栏中搜索markdown\r\n> - 将Markdown>Preview：Breaks打上勾就ok了\r\n"}},{"title":"rabbitmq与AMQP","payload":{"title":"rabbitmq与AMQP","date":"2022-05-01","tags":["消息队列","中间件","rabbitmq"],"categories":"中间件","content":"\r\n\r\nrabbitmq是一款被广泛使用的消息队列中间件，它目前被Pivotal公司所拥有。其基于`AMQM`、`AMQP`并用`erlang`语言实现，拥有诸多特性，譬如开源、强大商业支持、跨语言、跨平台、轻量级、扩展性强、可定制、安全支持等。它可以通过分布式部署满足高可用的需求，其吞吐量亦十分可观，能够达到万/s的级别，当然吞吐量的高的代价是比较吃cpu，我们可以根据自身系统在可用性和性能两方面做权衡。另外rabbitmq还支持异地多活和异地多活多主架构。\r\nrabbitmq强悍的力量很大程度上是因为其基于`AMQP`，`AMQP`不仅定义了网络层协议而且对服务端的服务和行为也做了定义，即`AMQ model`。`AMQ model`就消息路由行为定义了三个抽象组件：`Exchange,Queue,Binding`。\r\n- Exchange：将消息路由给队列的组件\r\n- Queue：存在于内存或者磁盘中的存储消息的数据结构\r\n- Binding：Exchange将消息分发给Queue的规则\r\n\r\n将一个message发送到broker后，broker的行为如下图所示：<div align=\"center\"><img src=\"../../resources/img/rabbitmq-message-send.jpg\"></div>\r\n\r\n实际使用时，每种Exchange类型处理routing-key的行为会有所差异，有的不做任何处理，有些则需要进行复杂的模式匹配提取，header exchange甚至根本就不管routing-key是啥。rabbitmq在设计中扩展了AMQ model，exchange不仅接受queue的绑定，而且接受其他exchange的绑定，这种特性为消息的路由模式提供了相当的灵活性。\r\n\r\nrabbitmq客户端库的实现都会隐藏掉基于AMQP进行通信的复杂性，这或许对用户来说是一件好事，用户的绝大多数精力可以用在应用层上，不必关心实际上的复杂性。但我们还是应当熟悉AMQP协议，只有这样，我们才不会在应用性能没有达到预期或者是出现错误时束手无策。\r\n\r\nrabbitmq利用`RPC`模式实现AMQP的通信，但是具体实现又同一般的RPC模式有所不同。一般来说，进行RPC通信的双方，客户端发送指令给服务端，服务端处理后返回响应，这里服务端是不会发指令给客户端的，但是rabbitmq的RPC实现中，服务端会。<div align=\"center\"><img src=\"../../resources/img/rabbitmq-conversation.jpg\" height=600px></div>\r\n\r\nrabbitmq客户端与服务端之间建立通信首先需要经过三次握手。首先客户端会发送包含Protocol Header的Greeting给服务端，接着服务端发送Connection.Start给客户端，最后客户端发送Connection.StartOk给服务端，之后一个连接就建立了。在客户端与服务端之间进行有实际意义的交流之前，还得在连接中打开channel，在channel中进行AMQP帧的传输。channel是双工的，并且可以在一个连接中有多个，有点像HTTP2。\r\n\r\nAMQP的命令由类和方法组成，像Connection.Start中，Connection是对象，Start是方法。当命令被发送到客户端或者服务端时，执行命令所需的参数被封装到帧中进行传输。底层的AMQP帧大致上长这样。<div align=\"center\"><img src=\"../../resources/img/amqp-frame.jpg\" ></div>\r\n\r\n帧的头部由帧类型，channe编码，payload大小组成。有五种帧的类型如下所示：\r\n- protocol header frame：只会在在连接到rabbitmq时用到\r\n- method frame：携带RPC请求或者响应\r\n- content header frame：包含消息的大小和属性\r\n- body frame：消息内容\r\n- heartbeat frame：心跳检测确认通信双方存活\r\n\r\n在channel中的数据总是以`method frame`，`content header frame`，多个`body frame`的顺序流动。method frame被特殊编码以压缩大小，典型的method frame头两个字段包含类型和方法，之后的一个字段是exchange name，再然后是routing-key，最后可能会有一个mandatory字段以让rabbitmq在没有满足消息发布需求时给客户端进行反馈。content header frame的payload主体由Basic.Properties表组成，通过它可以很方便的实现消息的定制化。content header frame也会被特殊编码。body frame则不会被特殊编码，它可以装载各种格式的图片，json/xml格式数据或者是文档等。\r\n\r\n在AMQ model中，`exchange`和`queue`都是一等公民。创建一个exchange对应的method是Exchange.Declare,如果创建成功，rabbitmq会返回Exchange.DeclareOk,否则会返回Channel.Close。类似的，创建一个queue对应的method是Queue.Declare,如果创建成功，rabbitmq会返回Queue.DeclareOk,否则会返回Channel.Close。将一个queue绑定到exchange的method是Queue.Bind,绑定成功，rabbitmq会返回Queue.BindOk。以上的method在AMQP中都是同步命令，在AMQP中也有一些命令通过异步的方式来接受和发送消息。\r\n\r\n当我们通过Basic.Publish发布消息到rabbitmq中时，可以将消息存储到内存或者是磁盘中去，并且只会储存一份，丢到队列中的实际是实例的一份引用，不同队列的实例引用之间互不影响。当我们把消息丢到队列中去之后，剩下的就是消费了，客户端发送Basic.Consume请求消费，然后rabbitmq响应Basic.ConsumeOk表示可以开始消费，若客户端想要终止消费过程，可以发送Basic.Cancel,这是一个异步命令，所以客户端此时还是会收到rabbitmq发来的消息。\r\n\r\n受限于精力，能力和时间成本，rabbitmq的AMQP实现的了解暂时先到此为止。如果想进一步了解，可以参考[rabbitmq的官方文档](https://www.rabbitmq.com/protocol.html)。\r\n\r\n附上Basic.Properties的属性表：<div align=\"center\"><img src=\"../../resources/img/Basic-properties.png\"></div>\r\n"}},{"title":"rabbitmq中的消息发布与消费","payload":{"title":"rabbitmq中的消息发布与消费","date":"2022-05-02","tags":["rabbitmq"],"categories":"中间件","content":"\r\n>多一分则肥，少一分则瘦\r\n\r\n消息中间件消息的发布需要在高性能与可靠性之间做权衡，rabbitmq依靠AMQP的事务规范，可选的持久化机制，以及自身的传输确认机制为我们构建不同等级的可靠系统提供了可能性。<div align=\"center\"><img src=\"../../resources/img/performance-with-guarantee.png\"></div>\r\n\r\nNotification on failure -- 当我们在Basic.Publish的method frame中添加mandatory标志时，如果消息没有被正确的路由，那么rabbitmq broker就会通过Basic.Return的RPC回传消息给publisher。在我们的代码中要注册回调函数处理这种路由失败的情况。Publisher confirms -- publisher发送Confirm.Select,rabbitmq broker回复Confirm.SelectOk，之后这条传递消息的channel就成了一个confirm channel，publisher每发送一条消息给服务器，如果消息都入队等待被消费并且被持久化到磁盘中，或者是消息在所有应该路由到的队列中都被消费者消费完毕了，服务端就会回复Basic.Ack，否则就会回复Basic.Nak。服务端异步回复confirm消息，在我们的代码中需要注册回调函数处理来自服务端的回复。Alternate exchanges -- 当我们声明一个exchange，可以给它绑定一个备用exchange，当发送给给此exchange的消息无法被路由时，此备选exchange就会接管工作，将消息路由到死信队列中去，值得注意的是，一旦同时设置mandatory标志和备选队列，那么mandatory就失效了。Transactions -- AMQP规范中定义了事务来保证批处理的原子性。publisher发送TX.Select,服务端回传TX.SelectOk，事务就开始了，可以在事务中发送一条或者多条消息，消息发送完毕publisher发送TX.Commit，然后在收到服务端的TX.CommitOk后，事务就完成了。这里需要注意的是当事务执行过程中，发生错误了，那么服务端就会发送Basic.Return,publisher如果想终止事务，可以发送TX.Rollback，然后等待服务端回传TX.RollbackOk。另外，rabbitmq在实现AMQP事务规范时只有当命令只影响一条队列时，才保证其原子性，当有多条队列收到影响时，原子性就会被打破。事务机制比较影响性能。HA queues -- HA queue需要在集群环境中使用，在定义队列时，将队列声明为高可用队列，模式若设为all，则集群中的所有结点都会同步此队列的状态。若模式为nodes，则可自定义同步节点。一旦消费者在任意节点消费了此队列中的消息，所有节点中的该条消息就会立刻被删除。HA queues拥有一个主节点，其他的都是副节点，如果主节点挂了，其他的某个副节点就会成为新的主节点。如果挂了的节点恢复了，或者集群中加入了新的节点，那么它们会接受新发送来的消息，并且在队列中的旧消息都消费完毕了才会加入同步集。HA queues with transactions -- 这种方式会引入相当的响应延迟，慎重使用。Persisted messages -- 持久化选项由Basic.Properties中的delivery-mode控制，默认为1，表示不持久化，如果想要持久化，则应该设为2，另外装此消息的队列也应该被设置为持久化队列。\r\n\r\n上面一段讲了向rabbitmq发布消息的问题，这一段我们看看怎么从rabbitmq获取消息。有两种方法可以从rabbitmq获取消息，`Basic.Get` & `Basic.Consume`。Basic.Get使用一种拉的模式从broker中获取消息，consumer想要获取一个消息都必须发送一个新的Basic.Get RPC请求，broker会根据queue中是否有代办消息回复`Basic.GetOk` or `Basic.GetEmpty`，消费端需要根据回复进行相应的处理。Basic.Get的这种同步方式对性能有明显的影响，更重要的是，由于consume是消费端主动发起的，所以broker也无法优化整个传输过程。与`Basic.Get`相反的是，`Basic.Consume`以一种推的方式从broker中获取消息，发送Basic.Consume RPC请求到broker后，rabbitmq就会在broker中注册你的应用，然后直到你发送`Basic.Cancel`之前,broker都以一种异步的方式将队列中的消息发送给消费者。当然从broker获取到消息之后，消费端也需要向broker发送`Basic.Ack`让它知道消息已经被正常消费了。同publish一样，消费消息也需要在吞吐量和可靠性之间做权衡。<div align=\"center\"><img src=\"../../resources/img/consume-with-guarantee.png\"></div>\r\n\r\nno-ack -- 当向rabbitmq发送Basic.Consume注册我们的应用进行消费时，在请求中携带no-ack的标志时，broker就会知道消费端不会ack，应该尽可能快速地将消息发送给消费端。Consuming with acknowledgement and Qos > 1 -- 通过向broker发送Basic.Qos请求，我们可以设置一条channel的服务质量，broker会在这条channel上连续发送预设数量的message后，等待消费端的回复，消费端可以选择依旧每条消息都回复，也可以通过在Basic.Ack中设置multiple标志而不必每条消息都回复，broker会将没有收到回复的消息写回到队列中。当然设置multiple标志的方式会有重复消费的风险。transaction -- 事务方式可以规避重复消费的风险，代价是吞吐量不及QoS的方式。\r\n\r\n当消费端在接收消息或者处理消息的过程中发生异常情况时，rabbitmq提供两种方式将消息踢还给broker：`Basic.Reject` & `Basic.Nak`。发送Basic.Reject给服务端时，若在请求中携带requeue标志，则broker会将消息重新入队，否则broker只是简单的将消息丢弃。Basic.Nak的行为与Basic.Reject类似，不同的是其类似Basic.Ack可以在一次回复中携带多个拒绝信息，它也不是AMQP原生支持的命令。除了这两条命令，rabbitmq还提供叫做死信exchange(DLX)的扩展，DLX同队列进行绑定，一个队列中被拒绝且没有重新入队的消息或者过期的消息会被交给DLX。"}},{"title":"rabbitmq中的队列和exchange","payload":{"title":"rabbitmq中的队列和exchange","date":"2022-05-02","tags":["rabbitmq","中间件","消息队列"],"categories":"中间件","content":"\r\n\r\n队列毫无疑问在消息队列中占据着核心地位，rabbitmq提供了诸多设置让我们能够自如地定义队列。这些设置有很多，挑一些常用的列举在下方：\r\n- 自动删除\r\n- 限制唯一消费者消费\r\n- 自动过期队列\r\n- 限制消息的数量\r\n\r\n非常重要的是，一旦我们创建了一个队列，队列的设置就无法被更改了，改变队列的设置只能通过删除然后重新创建的方式。\r\n\r\n通过在`Queue.Declare`请求中加入`auto_delete`标志可以创建临时队列，所谓临时队列就是一旦消费者拿走队列的全部消息、断开连接，队列就会被删除。值得留意的是，临时队列可以被任意数量的消费者消费，只有当不再有消费者监听该队列了，这个队列才会被删除。\r\n\r\n在队列声明请求中加入`exclusive`标志可以限制消费者的数量为一，声明一个排他队列，排他队列也会自动删除，但它的行为和临时队列有所不同，排他队列在连接断开后被删除，临时队列则与是否有订阅者有关。\r\n\r\n通过在队列声明请求中加入`x-expires`参数可以声明一个定时队列，参数单位为毫秒，定时队列会在过期时间到后被自动删除，需要注意的是只要定时队列上由消费者，那么除非消费者停止订阅或者连接断开，该队列是不会被自动删除的。另外当消费者向该队列发送`Basic.Get`请求后，`x-expires`参数就失效了，该队列不再是定时队列了。rabbitmq不保证删除定时队列的及时性。\r\n\r\n通过在创建队列请求中将`durable`参数置为true，可以让该队列成为一个永久队列，并被持久化到磁盘中去，直到`Queue.Delete`命令删除该队列。\r\n\r\n通过在创建队列时设置`x-message-ttl`可以设置队列中消息的过期时间，设置`x-max-length`可以设置队列最大消息数，当队列中的消息达到了这个数目，就无法向队列中添加消息了。如果该队列声明了`DLX`，那么过期的消息和无法添加的消息会被交给`DLX`处理。\r\n\r\n声明一个队列可使用的参数及其作用如下图所示：<div align=\"center\"><img src=\"../../resources/img/queue-argument.png\"></div>\r\n\r\nrabbitmq最强大的力量来自于exchange基于消息中的routing信息将消息路由至不同队列的灵活性。通过exchange，消息可以被路由至一个或多个队列，其他exchange，还可以是外部资源。在rabbitmq中有四种类型的exchange：\r\n- Direct exchange\r\n- Fanout exchange\r\n- Topic exchange\r\n- Headers exchange\r\n\r\nDirect exchange是rabbitmq中最简单的exchange，它可以被多个队列绑定，当消息发送至此exchange时，它会将消息的routing-key同与之绑定的队列的binding-key做比较，只有当两个字符串完全相等时，exchange才会将消息丢到队列中去。\r\n\r\nFanout exchange会将接受的消息发送到所有绑定的队列中去，因为不需要进行routing-key和binding-key的比较，所有性能会很好，但是也因为缺乏选择机制，路由至所有队列中的消息都应该被消费。\r\n\r\nTopic exchange同Direct exchange一样会基于routing-key选择性的路由消息到队列中，不同的是Topic exchange不需要完全匹配，它通过基于通配符的模式匹配完成工作。\r\n\r\nHeaders exchange的允许在消息中自描述路由逻辑，在消息头的Basic.Properties中添加headers属性，headers表随意添加key/value对，队列与exchange的绑定使用的也不再是字符串数组，而是key/value对的数组，绑定会被设置一个叫x-match的参数，值为any或者all，any表示任意匹配，all则是全匹配。Headers exchange提供强大的路由机制，但代价是也给broker带来了额外的计算负担，在比较路由之前，headers表中的属性值会先被排序。但是有一点需要注意的是只要在消息的属性中设置了headers，那么无论消息被发送至什么类型的exchange上，性能都会受到影响。\r\n\r\n一个exchange可以有多个queue绑定，那么一个消息可以被发送至多个exchange吗？答案是可以的。通过exchange-to-exchange绑定，你可以做到这一切，不同于队列绑定使用Queue.Bind method，exchange绑定使用Exchange.Bind method。这种机制非常灵活，灵活可能会使系统变得复杂。rabbitmq中的主要exchange类型如下图所示：<div align=\"center\"><img src=\"../../resources/img/exchanges.png\"></div>"}}];
export const categoriesAll = ["Java","随笔","theory","leetcode","软技能","网络","nginx","底层原理","中间件","技巧"];
export const categoriesMap = [{"category":"Java","payload":[{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"}]},{"category":"随笔","payload":[{"title":"观‘技术人不要看中文’有感","date":"2022-04-29","tags":["essay"],"categories":"随笔","content":"\r\n\r\n今日B站给推送一个视频，标题叫‘[50岁程序员：技术人不准看中文！](https://www.bilibili.com/video/BV1Sr4y1J7K9?spm_id_from=333.999.0.0)’ 。短短25秒大致意思就是中文互联网下所获取学习到的相关技术已经比其原本所具备的能力打了折扣。评论最高赞的三个评论我贴在下方。![反对方论点](../resources/img/journal_review1.png)  ![支持方论点](../resources/img/journal_review2.png)\r\n\r\n就我个人来说，技术人不准看中文大致上是准确。诚然，中文互联网上是可以找到大量优质的技术文章，它们或者短小精悍，或者详尽有趣，看完也能大有收获。但是呢，这里有一个问题，我怎么才能找到这些文章呢？对于一个小白来说代价有点大。遇到问题，借助百度，搜到的答案要么同质化程度太高，要么水平低下，要么早已过时。(google好一些，但或多或少还是会遇到这种情况，怎么解决还有待探索)。一些技术论坛，rss的情况好一些，可以时不时的找到一些高质量文章，有时在评论区也能有所收获，但也都是随缘，毕竟这些生产高质量文章的大佬一是更新日期不固定，二是实时的关注点也会有所差异。当然我们也可以去看书，这里有两类，一类是由英文翻译而来的技术书，一类是中文作者原创的技术书。中文原创的技术书一般都是实战型，就着某个框架，某门技术给你现造个应用出来，这么做其实好的，编程这个东西就得实践，看一百本书都比不上做一个完整项目的收获大。但是这么做也是有问题的，一本几百页的书并且是在以项目为基础的前提下所能包含的相关技术的内涵是有限的，而且这些书一般也会绑定某个版本做项目，当我们要换个版本做应用，并且版本的变化相对较大时，我们还是得去看官方的文档，这些文档鲜少会提供中文。至于由英文翻译而来的技术书呢，则良莠不齐，有些甚至都可以看出是机翻。\r\n\r\n所以对于反对者所说的看英文文档效率低的问题我是不认同的，相对与在中文互联网中四处闲逛还是收获甚小所造成的开销，翻译层的开销是可以忽略的。至于后半段真假参半的话术，还扯上脊梁问题，那就令人反感了。这里为什么说真假参半呢，因为这里是有指导意义的，读应当读英文，那些大佬有空也可以做一些优秀的中文输出反馈到中文社区，从而形成中文互联网的良性循环。虽然在这个流量变现，而不是付费变现的时代，期待这成为现实有些困难，但万一呢 :wink: "}]},{"category":"theory","payload":[{"title":"functional programming","date":"2022-05-05","tags":["编程风格","lambda","纯函数"],"categories":"theory","content":"\r\n\r\n> 函数式编程是一种编程范式，区别于面向对象编程和面向过程编程的命令风格，其风格是声明式的，是满足若干要素的构建软件的方式。\r\n\r\n函数式编程由纯函数的组合构成，以避免共享状态、可变数据以及副作用。理解函数式编程的第一步就是要理解什么是纯函数。\r\n\r\n所谓纯函数就是那种对于给定输入总是得出固定输出且不产生任何副作用的函数。纯函数是函数的一种类型，一个函数的目的可以是值映射，一系列步骤的组合或者是同系统中的其他模块通信。纯函数总是和值映射相关，一个参数，一个固定输出。比如Math.max(11,13)无论被调用多少次，什么时候调用，其结果都是13。而且因为该函数不存在将值存盘或者输出到标准输出上的行为，理论上来说，只要Math.max(11,13)出现的地方，都可以用13去代替。即所谓的引用透明性(referential transparency)。Math.random(),System.currentTime()不是纯函数，因为它们不满足一个输入对应一个输出的原则。\r\n\r\n纯函数用副本实现不可变性的。区别于全拷贝，它将数据分成一个个很小的块，只对变化的块进行复制，很象git管理库和提交的方式。基于不可变性，纯函数也不会修改任何外部状态。\r\n\r\n纯函数不修改外部状态避免了共享状态，也意味着不会产生任何副作用。在共享状态下，并发/并行过程 + 可变状态 = 不确定性，一个不确定的系统结果是无法预测的，可能会产生各种奇奇怪怪的bug，纯函数可以帮助我们避免这种bug。\r\n\r\n函数组合就是将两个以上的函数以某种顺序组合成一个函数的过程，一个函数就像是一个管道，我们的数据就在这一系列的管道中流过。基于这种风格，我们可以减少中间变量的使用。\r\n\r\n函数式编程倾向于重用一组通用的函数式实用程序来处理数据。面向对象的编程倾向于将方法和数据放在对象中。那些并置的方法只能对它们设计用于操作的数据类型进行操作，并且通常只能对包含在该特定对象实例中的数据进行操作。在函数式编程中，任何类型的数据都是平等的。相同的 map()实用程序可以映射对象、字符串、数字或任何其他数据类型，因为它将函数作为参数来适当地处理给定的数据类型。函数式编程使用高阶函数实现了它的通用实用技巧。\r\n\r\n更加具体清晰的functional programming说明可以参考Eric Elliott的文章[Master the JavaScript Interview: What is Functional Programming?](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0),以及Russ Olsen的演讲[Functional Programming in 40 Minutes](https://www.youtube.com/watch?v=0if71HOyVjY)。\r\n"}]},{"category":"leetcode","payload":[{"title":"123.买卖股票的最佳时机Ⅲ","date":"2022-05-03","tags":["leetcode"],"categories":"leetcode","content":"\r\n\r\n> 题目描述\r\n\r\n给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你最多可以完成两笔交易。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\r\n\r\n> 例1\r\n\r\n    输入：prices = [3,3,5,0,0,3,1,4]\r\n    输出：6\r\n    解释：在第 4 天（股票价格 = 0）的时候买入，在第 6 天（股票价格 = 3）的时候卖出，这笔交易所能获得利润 = 3-0 = 3 。\r\n    随后，在第 7 天（股票价格 = 1）的时候买入，在第 8 天 （股票价格 = 4）的时候 卖出，这笔交易所能获得利润 = 4-1 = 3 。\r\n> 例2\r\n\r\n    输入：prices = [1,2,3,4,5]\r\n    输出：4\r\n    解释：在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。   \r\n    注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出.因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。\r\n> 例3\r\n\r\n    输入：prices = [7,6,4,3,1] \r\n    输出：0 \r\n    解释：在这个情况下, 没有交易完成, 所以最大利润为 0。\r\n\r\n思路：我们可做的交易数为0，1，2，也就是说最多可以做两笔交易。那么我们可以以第i天为界，计算出[0 - i]最大收益数和[i - n]最大收益数之和，得到的结果就是我们想要的答案。<div align=\"center\"><img src=\"../resources/img/leetcode_123_1.jpg\"></div>\r\n\r\n附上代码\r\n\r\n    //123.买卖股票的最佳时机 III\r\n    public int maxProfit(int[] prices) {\r\n        int ans = 0;\r\n        int len = prices.length;\r\n        //前i + 1天所能得到的最大收益\r\n        int[] beforeProfits = new int[len];\r\n        int min = prices[0],max = prices[0];\r\n        for (int i = 1; i < len; i++) {\r\n            min = Math.min(min,prices[i]);\r\n            max = Math.max(max,prices[i]);\r\n            beforeProfits[i] = Math.max(beforeProfits[i - 1],prices[i] - min);\r\n        }\r\n        min = prices[len - 1];\r\n        max = prices[len - 1];\r\n        //后n - i天所能得到的最大收益\r\n        int[] afterProfits = new int[len];\r\n        for (int i = len - 2; i >= 0; i--) {\r\n            min = Math.min(min,prices[i]);\r\n            max = Math.max(max,prices[i]);\r\n            afterProfits[i] = Math.max(afterProfits[i + 1],max - prices[i]);\r\n        }\r\n        for (int i = 0; i < len; i++) {\r\n            ans = Math.max(ans,beforeProfits[i] + afterProfits[i]);\r\n        }\r\n        return ans;\r\n    }\r\n\r\n"}]},{"category":"软技能","payload":[{"title":"DDD领域驱动设计","categories":"软技能","tags":["设计思想"],"date":"2023-04-05","content":"\n\n领域驱动设计，一个理解是领域模型驱动设计模型。领域模型表达的是与业务相关的事实，设计模型描述的是所要构建的系统。\n\n\nquestion：DDD是否与scrum冲突？\n\n\n按照美团技术团队的理解，他们将解决复杂和大规模软件的武器大致分为了三类：抽象、分治和知识。\n\n- 分治：把问题空间分割为规模更小且易于处理的若干子问题。分割后的问题需要足够小，以便一个人单枪匹马就能够解决他们；其次，必须考虑如何将分割后的各个部分分装配为整体。分割得越合理越易于理解，在装配成整体时，所需跟踪的细节也就越少。即更容易设计各部分的协作方式。评判什么是分治得好，即高内聚低耦合。\n- 抽象：使用抽象能够精简问题空间，而且问题越小越容易理解。\n- 知识：DDD可以认为是知识的一种。DDD提供知识手段，让我们知道如何抽象出限界上下文以及如何去分治。\n\n领域驱动设计与微服务架构是天然耦合的。架构设计活动可以被精简为三个层面：\n\n- 业务架构-根据业务需求设计业务模块及其关系\n- 系统架构-设计系统和子系统的模块\n- 技术架构-决定采用的技术及其框架\n\nDDD的核心诉求就是讲业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。而微服务追求业务层面的复用，设计出来的系统架构和业务一致；在技术架构上则系统模块之间充分耦合，可以自由地选择合适的技术架构，去中心化地治理技术和数据。\n\n\n美团技术团队的领域模型设计一般实践分为5个步骤：\n\n1. 根据需求划分出初步的领域和限界上下文，以及上下文之间的关系；\n2. 进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象；\n3. 对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根；\n4. 为聚合根设计仓储，并思考实体和值对象的创建方式；\n5. 在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。\n\n领域\n\n\n现实世界中，领域包含问题域和解系统。在DDD中，解系统可以映射为一个个限界上下文，限界上下文就是软件对于问题域的一个特定的、有限的解决方案。\n\n\n一个给定的业务领域会包含多个限界上下文，想与一个限界上下文沟通，则需要通过显示边界进行通信。系统通过确定的限界上下文来进行解耦，而每一个上下文内部紧密组织，职责明确，具有较高的内聚性。\n\n\n一个很形象的隐喻：细胞质所以能够存在，是因为细胞膜限定了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜。\n\n\n如何划分限界上下文\n\n\n在美团技术团队的实践中，具体做法是考虑产品所讲的通用语言，从中提取一些术语称之为概念对象，寻找对象之间的联系；或者从需求中提取一些动词，观察动词之间的关系；将紧耦合的各自圈在一起，观察他们内在的联系，从而形成对应的限界上下文。形成之后，尝试用语言来描述限界上下文的职责，看它是否清晰、准确、简洁和完整。简言之，限界上下文应该从需求出发，按领域划分。\n\n\n上下文映射图\n\n\n在进行上下文划分之后，下一步要做的就是梳理上下文之间的关系。\n\n\n> 康威定律\n\n\n任何组织在设计一套系统时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。\n\n\n所以团队结构应该和限界上下文保持一致。\n\n\n> 限界上下文之间的映射关系\n\n- 合作关系：两个上下文紧密合作的关系，一荣俱荣，一损俱损\n- 共享内核：两个上下文依赖部分共享的模型\n- 客户方-供应方开发：上下文之间有组织的上下游依赖\n- 遵奉者：下游上下文只能盲目依赖上游上下文\n- 防腐层：一个上下文通过一些适配和转换与另一个上下文交互\n- 开放主机服务：定义一种协议来让其他上下文对本上下文进行访问\n- 发布语言：通常和OHS一起使用，用于定义开放主机协议\n- 大泥路：混杂在一起的上下文关系，边界不清晰\n- 另谋他路：两个完全没有任何联系的上下文\n\n战术建模—细分上下文\n\n\n> 实体\n\n\n当一个对象由其标识(而不是属性)区分时，这种对象称为实体。比如公安系统的身份信息录入，每个人都是独一无二的，且具有唯一标识的，可以被认为是实体。\n\n\n> 值对象\n\n\n当一个对象用于对事务进行描述而没有唯一标识时，它被称作值对象。\n\n\n> 聚合根\n\n\n聚合是一组相关对象的集合，作为一个整体被外界访问，聚合根是这个聚合的根节点。聚合由根实体，值对象和实体组成。\n\n\n> 领域服务\n\n\n一些重要的领域行为或操作，可以归类为领域服务。它既不是实体，也不是值对象的范畴。\n\n\n> 领域事件\n\n\n领域事件是对领域内发生的活动进行的建模。\n\n"}]},{"category":"网络","payload":[{"title":"http协议","categories":"网络","tags":["http","网络"],"date":"2023-04-13","content":"\n\n参考：\n\n\n[https://www.shouxicto.com/article/4093.html](https://www.shouxicto.com/article/4093.html)\n\n\n### HTTP/1.1\n\n- 长连接\n\nHTTP/1.0中，默认使用的是短连接，就是每次请求都要重新建立一次连接。HTTP/1.1默认使用长连接Connection : keep-alive。\n\n- 管道\n\npipeline指客户端拥有连续发送请求的能力，但是客户端没有分辨响应的能力，即存在响应队头阻塞的问题。\n\n\n### HTTP/2\n\n\n相比较HTTP/1.1,HTTP/2做了如下改进\n\n- 二进制分帧层(核心)\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d8dd31b1-bcf7-4d65-85e7-e0ce09894cb5/HTTP2.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=8f00999b3cec5679ac91f3986a9840d3bc1cc1b8b854165c61e2180542984a17&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n二进制分帧层是指位于套接字接口和应用可见的高级HTTP API之间一个经过优化的新编码机制。在二进制分帧层上，HTTP/2.0会将所有传输信息分割为更小的消息和帧，并对它们采用二进制格式的编码，其中HTTP/1.x的首部信息会被封装到Headers帧，request body则封装到Data帧中。\n\n- 头部压缩\n\n每个HTTP传输都承载一组标头来说明传输的资源及其属性。在HTTP/1.x中，此元数据始终以纯文本的形式传输，通常高达500-800字节，如果使用HTTP Cookie，有事会达到上千字节。\n\n\nHTTP/2使用HPACK压缩格式压缩请求和响应标头元数据，这种格式由两种技术支持：\n\n1. 使用静态霍夫曼代码对传输的标头字段进行编码，从而缩小各个传输的大小。\n2. 客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表，即建立一个共享的压缩上下文，此表随后会用作参考，对之前传输的值进行有效编码。\n\nHTTP/2.0在客户端和服务端使用“首部表”跟踪和储存之前发送的键值对，对于相同的数据，不再通过每次请求和响应发送;通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型,等等)只需发送一次。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/08d37a32-fd07-4378-ada5-13e95f915cd9/HTTP2%E9%A6%96%E9%83%A8%E8%A1%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=c8558b68e929372351da213a574caebfb0cf92a1154bd3343ed7df0ecd95b207&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 多路复用\n\n在HTTP/1.x中数据是基于文本的有序传输，不能并行传输并且接收端又不知道数据包的顺序。HTTP/2中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将HTTP消息分解为互不依赖的帧，然后交错发送，在另一端再将其组装起来。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/280a438c-7404-4601-8c4d-d9fa8598ceb7/HTTP2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=71da3ab359f59857bfef9171ee99cc22befe35fbe837bc343abdb15222c774ad&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 服务器推送\n\nHTTP/2可以对一个请求发送多个响应，即除了最初请求的响应外，服务器还可以向客户端推送额外资源，而无需客户端明确地请求。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/20b147a9-3bb2-4f50-adc8-05a9038989b8/HTTP2%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=dfa0e1f0276e29ef519e8e8fc918f36883c90d00aa6b55bd510eefda6de4f95e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n### HTTP/2的缺点\n\n\nHTTP2的缺点一是建立连接的时间长，二是队头阻塞的问题依旧存在。而HTTP2的这两个缺点，都是因为HTTP2是基于TCP的应用层协议，tcp的三次握手消耗1.5RTT，加上TLS加密握手，则需要消耗3RTT，HTTP2虽然解决了http消息队头阻塞问题，但是并没有解决TCP队头阻塞问题。HTTP2废弃了管道化的方式，而引入帧、消息和数据流的概念，客户端和服务端可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来，解决了HTTP1.1队头阻塞的问题（一个响应返回发生延迟，其后续的响应都会被延迟，直到队头的响应送达）。TCP传输中会将数据拆分成一个一个小的有序的数据包，如果其中一个数据包没有按序到达，接收端就会保持连接等待数据包返回，这是就会阻塞后续的请求，造成TCP队头阻塞。\n\n\nHTTP/1.1 管道化持久连接也是使得同一个TCP连接可以被多个HTTP使用，但是HTTP/1.1中规定一个域名可以有6个TCP连接，而HTTP/2中，同一个域名只使用一个TCP连接，一旦HTTP/2中TCP队头阻塞所造成的影响会更大，因为HTTP/2的多路复用技术使得多个请求其实是基于同一个TCP连接的，如果某一个请求造成了TCP队头阻塞，那么多个请求都会受到影响。\n\n\n### HTTP/3\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/83871cf5-cec0-4f54-b13e-37d46815f9e0/HTTP3.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=e1120e9737dd47ae49ffe6a112b6f5ea6d3487dc3c03541826487d0a3316f10a&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 实现了类似 TCP 的流量控制、传输可靠性的功能。虽然 UDP 不提供可靠性的传输，但 QUIC 在 UDP 的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些 TCP 中存在的特性。\n- 集成了 TLS 加密功能。目前 QUIC 使用的是 TLS1.3，相较于早期版本 TLS1.3 有更多的优点，其中最重要的一点是减少了握手所花费的 RTT 个数。\n- 实现了 HTTP/2 中的多路复用功能。和 TCP 不同，QUIC 实现了在同一物理连接上可以有多个独立的逻辑数据流。实现了数据流的单独传输，就解决了 TCP 中队头阻塞的问题。\n"}]},{"category":"nginx","payload":[{"title":"Nginx必知必会","categories":"nginx","tags":["nginx","运维","devops"],"date":"2022-11-16","content":"\n\n[在centos下安装Nginx](b43b9a0b-0311-412a-a38d-0720a9a8df76)\n\n1. 在/etc/yum.repo.d下新建文件nginx.repo定义Nginx软件仓库细节\n\n\t```shell\n\t[nginx]\n\tname=nginx repo\n\t#OS example centos,OSRELEASE example 7.x\n\tbaseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/\n\tgpgcheck=0\n\tenabled=1\n\t```\n\n2. 执行nginx下载，配置nginx自启动，配置防火墙\n\n\t```shell\n\tyum -y install nginx\n\tsystemctl enable nginx\n\tsystemctl start nginx\n\tfirewalld-cmd --permanent --zone=public --add-port=80/tcp\n\tfirewall-cmd --reload\n\t```\n\n\n[nginx关键文件，文件夹以及命令](7de1a27a-f767-40b5-83e3-4605e4d1eafe)\n\n- 文件(夹)\n\n| /etc/nginx/               | nginx配置文件默认的文件夹根地址                                        |\n| - |  |\n| /etc/nginx/nginx.conf     | nginx默认的配置文件入口，设置了工作进程，管道，日志，加载动态模块的配置。该文件中还包含指向其他配置文件的引用 |\n| /etc/nginx/conf.d/        | 该文件夹下包含默认的HTTP服务配置文件                                      |\n| /etc/nginx/stream.conf.d/ | 该文件夹下包含stream配置文件                                         |\n| /var/log/nginx/           | 默认的日志文件夹，包含access.log和error.log                           |\n\n- 命令\n\n| nginx -h        | nginx help菜单                                         |\n|  | - |\n| nginx -v        | 版本                                                   |\n| nginx -V        | 版本，构建信息，配置参数                                         |\n| nginx -t        | 测试nginx配置                                            |\n| nginx -T        | 测试nginx配置并且打印有效配置                                    |\n| nginx -s signal | 给nginx主进程发送命令，signal example：stop quit reload reopen |\n\n\n[优雅地重启nginx](7a802821-4a1c-47be-845e-1d280bd19658)\n\n\nnginx -s reload\n\n\n[nginx负载均衡](802bf27b-a1b2-4df0-b30a-405c9d425ff8)\n\n- HTTP负载均衡\n\n\t```shell\n\tupstream backend {#upstream模块控制nginx的负载均衡\n\t\n\t\t#在两个HTTP server间做负载均衡，weight越大权重越大\n\t\tserver 10.10.12.45:80 weight=1;\n\t\tserver app.example.com:80 weight=2;\n\t\n\t\t#一个后备，当上面两个服务挂掉时启用\n\t\tserver spare.example.com:80 backup;\n\t}\n\tserver {\n\t\tlocation / {\n\t\t\tproxy_pass http://backend;\n\t\t}\n\t}\n\t```\n\n- TCP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream mysql_read {\n\t\t\tserver read1.example.com:3306 weight=5;\n\t\t\tserver read2.example.com:3306;\n\t\t\tserver 10.10.12.34:3306 backup;\n\t\t}\n\t\tserver {\n\t\t\tlisten 3306;\n\t\t\tproxy_pass mysql_read;\n\t\t}\n\t}\n\t```\n\n\n\t这个配置不会被放在conf.d文件夹下，应当创建一个stream.conf.d文件夹，在nginx.conf中加入以下配置。\n\n\n\t```shell\n\tstream{\n\t\t\tinclude /etc/nginx/stream.conf.d/*.conf;\n\t}\n\t```\n\n- UDP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream ntp {\n\t\t\tserver ntp1.example.com:123 weight=2;\n\t\t\tserver ntp2.example.com:123;\n\t\t}\n\t\tserver {\n\t\t\tlisten 123 udp;\n\t\t\tproxy_pass ntp;\n\t\t}\n\t}\n\t```\n\n\nnginx默认采用的是Round-robin轮询调度算法，nginx支持多种负载均衡方法如：最少连接，最少耗时，一致性hash，IP hash，随机调度等。可以在upstream block中进行配置：\n\n\n```shell\nupstream backend {\n\tleast_conn;\n\tserver backend.example.com;\n\tserver backend1.example.com;\n}\n```\n\n\n| Round robin       | 默认方式，按顺序分配请求给服务集群。可以通过配置weight使其成为weighted round robin                                                             |\n| -- |  |\n| Least connections | 将请求分配给打开连接数最少的服务器，可以通过weight给每个服务器设置权重                                                                             |\n| Least time        | 只在nginx plus中可用                                                                                                    |\n| Generic hash      | [https://zh.m.wikipedia.org/zh-hans/一致哈希](https://zh.m.wikipedia.org/zh-hans/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C) |\n| Random            | 随机算法，考虑weight                                                                                                      |\n| IP hash           | IP地址作为hash参数，考虑weight                                                                                              |\n\n\n[nginx流量管理](daebaa2d-2f3c-4d3c-a6e4-dc0b0bb49bae)\n\n\n### A/B Testing\n\n\n将客户端导流到不同的应用版本\n\n\n```shell\nsplit_clients \"${remote_addr}AAA\" $variant {\n\t\t20.0% \"backendv2\";\n\t\t* \"backendv1\";\n}\n```\n\n\n### GeoIP Module\n\n- 下载nginx GeoIP模块包\n\n```shell\n#下载nginx-module-geoip\nyum install nginx-module-geoip\nmkdir /etc/nginx/geoip\ncd /etc/nginx/geoip\nwget \"http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz\"\ngunzip GeoIP.dat.gz\nwget \"http://geolite.maxmind.com/\\download/geoip/database/GeoLiteCity.dat.gz\"\ngunzip GeoLiteCity.dat.gz\n```\n\n- 然后在配置文件中进行配置\n\n```shell\n#load_module指令只在主context中有效\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n#geoip_country,geoip_city只在http context中有效\nhttp {\n\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n}\n```\n\n\n有了这个module就可以将地理信息传递给后端的应用，或者借助它来进行流量路由，例如可以基于国别进行控制\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\t#来自美国的IP，变量country_access被置为0，其他被置为1\n\t\tmap $geoip_country_code $country_access{\n\t\t\t\t\"US\" 0;\n\t\t\t\tdefault 1;\n\t\t}\n\t\t#在server block中进行配置\n\t\tserver{\n\t\t\t\t#非美国的IP禁止访问\n\t\t\t\tif($country_access = '1'){\n\t\t\t\t\t\treturn 403;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n如果客户端在nginx之前途经其他的代理，可以配置找到其原始IP\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\t\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n\n\t\t#CIDR 指示nginx利用X-Forwarded-For头去查询客户端地址\n\t\tgeoip_proxy 10.0.16.0/26;\n\n\t\t#递归查找\n\t\tgeoip_proxy_recursive on;\n}\n```\n\n\n### 按照一定的规则限制连接数，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\tlimit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;\n\t\tlimit_conn_status 429;\n\t\tserver{\n\t\t\t\tlimit_conn limitbyaddr 40;\n\t\t}\n}\nlimit_conn_status和limit_conn指令在http、server、location context中有效\nlimit_conn_zone则只在http context中有效\n```\n\n\n预定义的key即规则要按照实际情况进行设置。比如请求来自NAT网络，那么根据IP地址限制连接数就是不合理的。limit_conn_zone后的字符串可以是任意数量的nginx可用变量，可以在应用层的级别去识别一个用户，比如说通过session cookie。默认的http状态码是503，但是其实服务是可用的，只是被限制了访问，所以429是更好的选择来暗示是客户端的问题\n\n\n### 按照一定的规则限制流量，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\t#速率被限制为3r/s，可以以秒或者分钟的粒度进行限流\n\t\tlimit_req_zone $binary_remote_addr zone=limitbyaddr:10m rate=3r/s;\n\t\tlimit_req_status 429;\n\t\tserver{\n\t\t\t\tlimit_req zone=limitbyaddr;\n\t\t\t\tlocation / {\n\t\t\t\t\t\t#二阶段限速，burst允许速率提升到其值而不拒绝请求\n\t\t\t\t\t\t#第二个参数有delay和nodelay选项\n\t\t\t\t\t\t#nodelay选项会立即消费brust的请求\n\t\t\t\t\t\t#但是在floor(brust/rate)时间后才会继续接受来自该客户端的请求\n\t\t\t\t\t\t#delay选项则会先消费delay数的请求，之后的延迟消费\n\t\t\t\t\t\tlimit_req zone=limitbyaddr burst=12 delay=9;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n_超出限制的访问请求会被记录到error.log中。_\n\n\n### 限制带宽\n\n\n通过配置限制每个客户端的下载带宽\n\n\n```shell\nlocation /download/ {\n\t\t#在下载10m的资源后会被限速1m/s\n\t\tlimit_rate_after 10m;\n\t\tlimit_rate 1m;\n}\n```\n\n\n[nginx内容缓存](f3dcfc09-4c20-426c-895e-f313c1003d64)\n\n\n[nginx动态配置的能力](0afd3e8d-3820-4ea7-8716-1ef02dd5a14c)\n\n\n[nginx认证](180d99e4-2155-4b93-ad35-0b3439dcb6df)\n\n\n### HTTP Basic认证\n\n\n生成一个包含用户名和密码的文件\n\n\n```shell\n#comment\n#password可以是加密或者hash后的字符串，加密使用C函数crypt()\n#具体操作方式是下载OpenSSL，执行openssl passwd password\n#password可以通过多种方式进行混淆，但是通常是不安全的，因为可以进行暴力破解\nname1:password1\nname2:password2:comment\nname3:password3\n```\n\n\n在配置文件中配置指令使得认证生效\n\n\n```shell\nlocation / {\n\t\t#未认证通过的请求显示Private site\n\t\tauth_basic \"Private site\";\n\t\tauth_basic_user_file conf.d/passwd;\n}\nauth_basic可以在http、server、location中进行配置\n```\n\n\n### 认证子请求，即对请求进行授权认证\n\n\n可以使用http_auth_request_module在将实际请求转发给相应服务前先由认证服务进行身份鉴别\n\n\n```shell\nlocation /private/ {\n\t\tauth_request /auth;\n\t\t#从auth服务中带出的一些变量\n\t\tauth_request_set $auth_status $upstream_status;\n}\n\nlocation = /auth {\n\t\tinternal;\n\t\tproxy_pass http://auth-server;\n\t\t#不需要body的场景\n\t\tproxy_pass_request_body off;\n\t\tproxy_set_header Content-Length \"\";\n\t\tproxy_set_header X-Original_URI $request_uri;\n}\n```\n\n\n[nginx安全控制](85eaab33-5d9d-4895-950c-cb71775c9c46)\n\n\n### 基于IP地址的访问控制\n\n\n```shell\nlocation /admin/ {\n\t\t#允许10.0.0.0/20域下除了10.0.0.1的访问\n\t\tdeny 10.0.0.1;\n\t\tallow 10.0.0.0/20;\n\t\t#允许2001:0db8::/32子网下所有IPV6地址的访问\n\t\tallow 2001:0db8::/32;\n\t\t#拒绝其他IP的请求\n\t\tdeny all;\n}\n\nallow、deny指令在http，server，location以及基于TCP/UDP的stream，server context中都是有效的\n```\n\n\n### 允许跨域资源共享(CORS)\n\n\n```shell\n#http 方法映射\nmap $request_method $cors_method {\n\t\tOPTIONS 11;\n\t\tGET 1;\n\t\tPOST 1;\n\t\tdefault 0;\n}\nserver {\n\t\tlocation / {\n\t\t\t\tif($cors_method ~ '1'){\n\t\t\t\t\t\t#允许跨域的方法\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\n\t\t\t\t\t\t#允许跨域的域名规则\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Origin' '*.example.com';\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Headers' \n\t\t\t\t\t\t\t'DNT,Keep-Alive,User-Agent,X-Request-With,\n\t\t\t\t\t\t\tIf-Modified-Since,Cache-Control,Content-Type';\n\t\t\t\t}\n\t\t\t\t#OPTION方法发送预检请求，获取服务的CORS规则\n\t\t\t\tif($cors_method = '11'){\n\t\t\t\t\t\t#在客户端缓存20天\n\t\t\t\t\t\tadd_header 'Access-Control-Max-Age' 1728000;\n\t\t\t\t\t\t#请求体为空\n\t\t\t\t\t\tadd_header 'Content-Type' 'text/plain; charset=UTF-8';\n\t\t\t\t\t\tadd_header 'Content-Length' 0;\n\t\t\t\t\t\treturn 204;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n### 客户端侧的加密\n\n\n```shell\n#利用一个SSL module对流量进行加密，比如ngx_http_ssl_module或者ngx_stream_ssl_module\n\nhttp { # All directives used below are also valid in stream\n\t\tserver {\n\t\t\t\t#设置一个SSL/TLS服务侦听在8443端口\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#服务证书，即发给客户端的公钥\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#用于加解密的密钥，实际上是服务端用的私钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.key;\n\t\t}\n}\n```\n\n\n### 加强客户端侧加密\n\n\n证书和证书秘钥既可以通过文件路径的方式进行配置，也可以通过变量参数的方式进行配置，客户端所能提供的最强等级标准和服务器所能接受的标准将是最终协议的结果。\n\n\n```shell\nhttp { #所有的指令在stream中也可以使用\n\t\tserver {\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#允许的ssl协议以及cipher\n\t\t\t\tssl_protocols TLSv1.2 TLSv1.3;\n\t\t\t\t#密码被设置为最高标准，拒绝aNULL,MD5\n\t\t\t\tssl_ciphers HIGH:!aNULL:!MD5;\n\t\t\t\t\n\t\t\t\t#RSA证书文件\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#RSA秘钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.pem;\n\n\t\t\t\t#变量中设置的证书使用椭圆曲线数字签名算法（ECC）\n\t\t\t\tssl_certificate $ecdsa_cert;\n\t\t\t\t#变量中设置的ECC形式的秘钥\n\t\t\t\tssl_certificate_key data:$ecdsa_key_path;\n\t\t\t\t\n\t\t\t\t#允许nginx缓存协议10分钟，内存配置为10m\n\t\t\t\tssl_session_cache shared:SSL:10m;\n\t\t\t\tssl_session_timeout 10m;\n\t\t}\n}\n\n#在相同强度下，ECC比RSA快\n```\n\n\n### 上游加密\n\n\n对nginx和上游服务之间的流量进行加密并且进行特定协议协商\n\n\n```shell\nlocation / {\n\t\tproxy_pass https://upstream.example.com;\n\t\tproxy_ssl_verify on;\n\t\t#确保nginx验证上游服务的证书有效深度最多为2\n\t\tproxy_ssl_verify_depth 2;\n\t\t#只接受TLSv1.2，默认所有版本\n\t\tproxy_ssl_protocols TLSv1.2;\n}\n```\n\n\n### 保护一个location block\n\n\n```shell\nlocation /resources {\n\t\t#安全秘钥\n\t\tsecure_link_secret mySecret;\n\t\tif($secure_link = \"\") {\n\t\t\t\treturn 403;\n\t\t}\n\t\trewrite ^ /secured/$secure_link;\n}\nlocation /secured/ {\n\t\tinternal;\n\t\troot /var/www;\n}\n```\n\n\n👆配置了一个内部block和一个公开block。如果请求的URI中包含一个md5 hash字符串并且能够被secure_link_secret指令提供的秘钥认证，则请求地址会被重写，并且交给内部block处理，否则请求会被拒绝，收到403的回复。\n\n\n### 使用秘钥生成一个安全链接\n\n\n上个单元中的合法URI长什么样子呢，举个例子，我们访问域名为www.example.com的服务器上的/var/www/secured/index.html资源，那么就需要根据index.html这个资源生成md5的十六进制编码，具体操作如下：\n\n\n```shell\necho -n 'index.htmlmySecret' | openssl md5 -hex\n(stdin)= a53bee08a4bf0bbea978ddf736363a12\n```\n\n\n然后这个生成的md5十六进制摘要会被拼接到URI中\n\n\n```shell\nwww.example.com/resources/a53bee08a4bf0bbea978ddf736363a12/index.html\n```\n\n\n这就是一个合法的URI。\n\n\n### 使用一个过期日期保护一个location block\n\n\n只有合法且在有效期内的链接才能够访问资源\n\n\n```shell\nlocation /resources {\n\t\troot /var/www;\n\t\t#第一个参数持有md5 hash，第二个参数是Unix epoch格式的link过期时间\n\t\t#arg_md5是一个http参数\n\t\tsecure_link $arg_md5,$arg_expires;\n\t\t#用于生成md5编码的字符串格式\n\t\tsecure_link_md5 \"$secure_link_expires$uri$remote_addrmySecret\";\n\t\t#如果是个无效的URI\n\t\tif($secure_link = \"\"){return 403;}\n\t\t#如果是个有效的URI但是已经过期了\n\t\tif($secure_link = \"0\"){return 410;}\n}\n```\n\n\n### 生成一个带过期时间的链接\n\n\n在unix系统中生成unix时间戳可以使用date指令\n\n\n```shell\n$ date -d \"2030-12-31 00:00\" +%s --utc\n1924905600\n```\n\n\n接下来要做的就是将在secure_link_md5指令中配置的字符串参数进行拼接，再上一个单元中拼接成的字符串则为1924905600/resources/index.html127.0.0.1 mySecret .在这里的MD5 hash同16进制摘要的MD5 hash有一些不同，它是二进制格式的，并且是将+转换为-，/转换为_，去掉=的base64编码。在unix系统中的一个例子如下：\n\n\n```shell\n$ echo -n '1924905600/resources/index.html127.0.0.1 mySecret' \\\n\t| openssl md5 -binary \\\n\t| openssl base64 \\\n\t| tr +/ -_ \\\n\t| tr -d =\nsqysOw5kMvQBL3j9ODCyoQ\n```\n\n\n现在可以在URI中拼接生成的MD5参数\n\n\n```shell\n/resources/index.html?md5=sqysOw5kMvQBL3j9ODCyoQ&expires=1924905600 \n```\n\n\n### 将一个http请求重定向为一个https请求\n\n\n```shell\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\treturn 301 https://$host$request_url;\n}\nor\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\t#只有在http_x_forwarded_proto请求头为http时，才重定向\n\t\tif($http_x_forwarded_proto = 'http'){\n\t\t\t\treturn 301 https://$host$request_url;\n\t\t}\n}\n```\n\n\n### HTTP严格传输安全（HSTS）\n\n\n通过设置Strict-Transport-Security请求头让浏览器总是进行重定向将HTTP请求转换为HTTPS请求\n\n\n```shell\n#max-age=1 year\nadd_header Strict-Transport-Security max-age=31536000;\n```\n\n\n### 满足任意数量的保障安全方式\n\n\n```shell\nlocation / {\n\t\t#参数any or all\n\t\tsatisfy any;\n\t\t\n\t\t#允许192.168.1.0/24网络访问\n\t\tallow 192.168.1.0/24;\n\t\tdeny all;\n\t\t\n\t\t#basic认证访问\n\t\tauth_basic \"closed site\";\n\t\tauth_basic_user_file conf/htpasswd;\n}\n```\n\n"}]},{"category":"底层原理","payload":[{"title":"泛型实现","categories":"底层原理","tags":["泛型","编程语言原理"],"date":"2023-04-13","content":"\n\n参考，其实就是不成形的笔记\n\n\n[https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/](https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/)\n\n\n## 类型系统（Type system）\n\n\n### 类型内存布局（Type Memory Layout）\n\n\n在二进制的世界里，存储在内存中的数据在操作系统中看到的是一串比特序列，而在拥有类型之后这串比特序列才有一定的意义。\n\n\n### 类型检查\n\n- 强弱类型：\n\n强弱类型并没有标准的定义，但是普遍认为强弱类型的核心区别在于，语言能否在某一个时刻能检查出来类型导出的错误，而不是抛出运行时错误（Unchecked RuntimeError）。强类型的编程语言可以在类型不匹配时发生错误（编译与运行时都可能发生），而弱类型的语言在类型不匹配时会做隐式的类型转换或无视类型进行操作，这会导致无法预料的运行时错误。这二者区分出来的核心现象就是，弱类型语言往往无法信赖变量的值，需要写很多额外的代码做额外的类型验证操作。\n\n- 静动检查：\n\n动态与静态的区别在于类型检查发生的阶段，动态是在运行时阶段，静态是在编译阶段。但实际上一些编程语言是混合的类型检查，比如在C#中开发者可以通过关键字来标识此数据类型检查是动态还是静态的。不少静态类型检查的编程语言也有动态的类型检查，比如Java中既有编译阶段的静态类型检查，又有运行时的动态类型检查（如父类与子类的互相转换）。\n\n- 类型推导：\n\n一些编程语言虽然不需要开发者显示定义数据类型，但编译器能够做类型推导，帮助开发者定义数据类型，如Scala与Kotlin。\n\n\nJavaScript是一个弱类型的动态类型检查语言，C是一个弱类型的静态类型检查语言。\n\n\n### 实现泛型\n\n\n通常意义下的泛型也叫参数多态，指的是声明与定义函数、复合类型、变量时不指定其具体的类型，而把这部分类型作为参数使用，使得该定义对各种具体类型都适用。参数化多态使得语言更具表达力，同时保持了完全的静态类型安全。这被称为泛化函数、泛化数据类型、泛型变量，形成了泛型编程的基础。\n\n\n> 多态理论\n\n\n\t编程语言理论(PLT)中多态(Polymorphism)包含三个主要方面：特设多态(Ad-hoc)，参数多态(Parametric)和子类型(Subtyping)。\n\n\n\tAd-hoc：也叫重载(Overloading)，允许具有相同名称的函数对不同类型执行不同的操作。例如，`+`运算符即可以将两个整数相加，也可以连接两个字符串。\n\n\n\tSubtyping：也叫包容性多态(Inclusion)，是指通过基类指针和引用使用派生类的能力。\n\n\n子类型多态也称为运行时多态性，因为编译器在编译时不定位函数的地址，而是在运行时动态调用函数。派发分为三种：\n\n- 静态派发(Static dispatch/early binding)：当程序在编译时可以找到执行的函数。C++默认使用的是直接派发，加上`virtual`修饰符可以改成虚函数表(Vtable)派发。直接派发是最快的，原因是调用指令少，还可通过编译器进行内联等方式的优化。这种派发缺点是不灵活，无法实现一些面向对象所需的技术如多态性。\n- 动态派发(dynamic dispatch/run-time dispatch/virtual method call/late binding): 当程序在运行时可以找到执行的函数。Java默认使用的是虚函数表(Vtable)派发，通过`final`修饰符可改成直接派发。虚函数表派发是有动态性的，一个类里会用表来存储类成员函数的指针，子类重写(Override)父类的函数会替代父类的函数，子类添加的函数会被加到这个表里。当程序运行时派发时会从这个表中找到对应的函数，这样就可以实现动态派发。面向对象的编程语言正是靠此机制实现了多态性(Polymorphic)。\n- 消息机制(message passing)：通过消息传递来调用被执行的函数。这种机制是在运行时可以改变函数的行为，甚至函数可以未实现，也不会引发运行时错误。Objective-C中就是通过消息传递来调用被执行的函数，甚至可以在程序运行过程中实现热更新代码。\n\n静态派发的速度是最快的，但并不灵活。而动态派发虽然比较慢，但却可以实现面向对象多态的功能。消息机制是最灵活的方式，但性能也最差。\n\n\n[embed](https://miro.com/app/board/uXjVPabTn6A=/?share_link_id=402499999270)\n\n\n### 类型擦除\n\n\n对Java来说统一的数据类型就是Object，在编译阶段做完类型检查后就将类型信息通过转换成Object进行擦除，这样只需要生成一份泛型函数的副本即可。类型擦除保证了泛型函数生成的字节码和非泛型函数的是相同的，也符合Java对兼容性的要求。不过类型擦除也给Java的泛型带来了很多的限制。\n\n\n### 虚函数表(Vtable)\n\n\nJava通过类型擦除结合虚方法表来实现泛型的效果：运行时同样的数据类型Object，却能调用原始类型的方法。\n\n\n### 字典\n\n\n编译器在编译泛型函数时只生成了一份函数副本，通过新增一个字典参数来供调用方传递类型参数(Type Parameters)，这种实现方式称为字典传递(Dictionary passing)。\n\n\n### 单态化\n\n\n单态化的思路是自动生成多个类型的泛型函数版本，看起来就是一个模版代码生成的过程，但是也需要考虑很多种情况。比如：\n\n- 生成所有类型的函数版本：这种最简单，但是会拖慢编译时间，也会让最终的二进制文件变得很庞大。\n- 生成调用类型的函数版本：这种需要编译器分阶段或多次编译，比如需要遍历寻找调用点来确定最终的类型列表，对于不同包的同名函数的处理等。\n- 是否支持独立编译：如果调用泛型函数的类型与泛型函数不在同一个包内，是否能支持泛型函数独立的编译。\n\n模板\n\n\nC++通过模板实现泛型类、方法和函数，这导致编译器为每个唯一的类型参数集编译了代码的单独副本。这种方法的一个关键优势是没有运行时性能开销，尽管它以增加二进制文件大小和编译时间为代价。\n\n\n蜡印\n\n\n蜡印其实就是模版，也是一种代码生成技术。但Go除了使用字典传递实现装箱外，还采用了`GC Shape Stenciling`的技术。这种看起来很高级的名词简单来说是为了解决蜡印或模版的问题，因为在蜡印的过程中，编译器会为每一个实例化的类型参数生成一套独立的代码。\n\n"}]},{"category":"中间件","payload":[{"title":"使用redis实现分布式锁","date":"2022-04-29","tags":["redis","分布式锁"],"categories":"中间件","content":"\r\n\r\n## 使用redis实现分布式锁\r\n\r\n>同一操作系统下的线程竞态访问某一临界资源，我们可以使用锁来帮助我们达成目的，一些编程语言\r\n都会提供内置的锁库。但是当我们的执行线程并不运行在同一操作系统之下，单一实例下的锁机制就\r\n失效了，这种情况下，我们需要分布式锁机制来帮助我们协调管理线程之间的竞争。\r\n\r\n我们可以在redis的帮助下实现分布式锁机制。只需要一条简单的命令我们便能做到它。\r\n\r\n    set resource_name unique_value NX;\r\n在我们进入临界区之前，先尝试着向redis中插入一条数据，若该数据存在则获取锁失败，否则获取\r\n锁成功。不过这里有一个问题，就是若获取锁的线程在释放锁之前挂了，那么锁就无法被释放，其他线程\r\n也就没有办法获取到锁。为了解决这个问题，我们可以将unique_value设置为`expire_timestamp`，\r\n另外的线程可以get到`expire_timestamp`，若该时间戳小于当前时间戳，我们便可以执行del命令进而\r\n释放到锁，再执行获取锁的指令，就ok了。然而虽解决了锁无法释放的问题，却引入了新的问题。这里\r\n我们假设有两个线程在同一时刻检测到了锁失效，然后相继执行释放锁加锁的步骤，像下面这样：\r\n\r\n    Thread 1:del resource_name;\r\n    Thread 1:set resource_name unique_value NX;\r\n    Thread 2:del resource_name;\r\n    Thread 2:set resource_name unique_value NX;\r\n最终Thread1和Thead2都获得了锁，违反了分布式锁的含义。因此相应的，我们不应该将释放锁的权力\r\n交给其他线程。释放锁的工作应当由获取锁的线程去做，若该线程挂了，那么该锁应当超时自动释放，redis\r\n同样提供了这样的机制，将上面的改一改：\r\n\r\n    set resource_name unique_value NX EX expire_time;\r\n即使获取锁的线程挂了，该锁也能够在超时之后释放掉。但是呢，这个命令还是有问题。假设这把锁被超时释放了，\r\n另外的线程又获取到了这把锁，然而之前获取锁的线程并没有挂掉，它只是执行的比较慢而已，在另一个线程获取锁\r\n之后它才执行释放锁的操作，然后它就把其他线程的锁给释放掉了。显然这是不符合逻辑的，上面就提到没有把持锁\r\n的线程没有释放锁的权力，那么这个时候unique_value就起到了作用，当我们获取锁的时候将键对应的值设为\r\n全局唯一的某个值，比如timestamp + clientId，然后我们可以写一段Lua脚本\r\n\r\n    if redis.call(\"get\",KEY[1]) == ARGV[1]\r\n    then\r\n        return redis.call(\"del\",KEY[1])\r\n    else\r\n        return 0\r\n    end\r\n只有当对应的值与当前线程设的值一样时，当前线程才可以释放掉锁。redis内置的lua脚本解释器也保证了\r\n每段脚本执行的原子性，不必担心有其他意外发生。\r\n\r\n这些看起来很美好，但是不幸的是，依旧存在问题。如果我们的redis是master-slave架构，某个时刻master挂了，\r\n由于master和slave之间是异步的，如果新选出来的master没有这条锁的记录，那么其他线程便能够获取到该锁。那么\r\n有没有什么办法可以解决这个问题呢，答案是有的，大名鼎鼎的redlock就是为此诞生的。由于精力有限，redlock的讨论\r\n就过段时间再说，这里先挖个坑。\r\n"}]},{"category":"技巧","payload":[{"title":"编程相关小技巧","date":"2022-04-29","tags":["技巧"],"categories":"技巧","content":"\r\n目前内容较少，没有分篇叙述的必要，预计达到100个`tip`开分\r\n\r\n1. 在vscode中编写markdown文档时自动换行\r\n> - ctrl + shift + p,打开命令窗口，输入setting，打开open user settings\r\n> - 在搜索栏中搜索markdown\r\n> - 将Markdown>Preview：Breaks打上勾就ok了\r\n"}]}];
export const tagsAll = ["spring","non-blocking","I/O","reactive","functional","programming","essay","Java","byte","code","编程风格","lambda","纯函数","leetcode","设计思想","http","网络","nginx","运维","devops","spring-security","测试","并发","泛型","编程语言原理","redis","分布式锁","技巧","消息队列","中间件","rabbitmq"];
export const tagsMap = [{"tag":"spring","payload":[{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"}]},{"tag":"non-blocking","payload":[{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"}]},{"tag":"I/O","payload":[{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"}]},{"tag":"reactive","payload":[{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"},{"title":"reactive programming","date":"2022-05-11","tags":["reactive","编程风格"],"categories":"theory","content":"\r\n\r\n"}]},{"tag":"functional","payload":[{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"}]},{"tag":"programming","payload":[{"title":"what is spring webflux","date":"2022-05-11","tags":["spring","non-blocking","I/O","reactive","functional","programming"],"categories":"Java","content":"\r\n\r\nspring5中加入了基于reactive的web框架-spring webflux，其支持完全意义上的non-blocking，可运行在netty，undertow以及Servlet3.1+的容器中。使用webflux而不是webmvc，我们可以在非阻塞式I/O的网络模型下愉快地进行函数式编程，\r\n"}]},{"tag":"essay","payload":[{"title":"观‘技术人不要看中文’有感","date":"2022-04-29","tags":["essay"],"categories":"随笔","content":"\r\n\r\n今日B站给推送一个视频，标题叫‘[50岁程序员：技术人不准看中文！](https://www.bilibili.com/video/BV1Sr4y1J7K9?spm_id_from=333.999.0.0)’ 。短短25秒大致意思就是中文互联网下所获取学习到的相关技术已经比其原本所具备的能力打了折扣。评论最高赞的三个评论我贴在下方。![反对方论点](../resources/img/journal_review1.png)  ![支持方论点](../resources/img/journal_review2.png)\r\n\r\n就我个人来说，技术人不准看中文大致上是准确。诚然，中文互联网上是可以找到大量优质的技术文章，它们或者短小精悍，或者详尽有趣，看完也能大有收获。但是呢，这里有一个问题，我怎么才能找到这些文章呢？对于一个小白来说代价有点大。遇到问题，借助百度，搜到的答案要么同质化程度太高，要么水平低下，要么早已过时。(google好一些，但或多或少还是会遇到这种情况，怎么解决还有待探索)。一些技术论坛，rss的情况好一些，可以时不时的找到一些高质量文章，有时在评论区也能有所收获，但也都是随缘，毕竟这些生产高质量文章的大佬一是更新日期不固定，二是实时的关注点也会有所差异。当然我们也可以去看书，这里有两类，一类是由英文翻译而来的技术书，一类是中文作者原创的技术书。中文原创的技术书一般都是实战型，就着某个框架，某门技术给你现造个应用出来，这么做其实好的，编程这个东西就得实践，看一百本书都比不上做一个完整项目的收获大。但是这么做也是有问题的，一本几百页的书并且是在以项目为基础的前提下所能包含的相关技术的内涵是有限的，而且这些书一般也会绑定某个版本做项目，当我们要换个版本做应用，并且版本的变化相对较大时，我们还是得去看官方的文档，这些文档鲜少会提供中文。至于由英文翻译而来的技术书呢，则良莠不齐，有些甚至都可以看出是机翻。\r\n\r\n所以对于反对者所说的看英文文档效率低的问题我是不认同的，相对与在中文互联网中四处闲逛还是收获甚小所造成的开销，翻译层的开销是可以忽略的。至于后半段真假参半的话术，还扯上脊梁问题，那就令人反感了。这里为什么说真假参半呢，因为这里是有指导意义的，读应当读英文，那些大佬有空也可以做一些优秀的中文输出反馈到中文社区，从而形成中文互联网的良性循环。虽然在这个流量变现，而不是付费变现的时代，期待这成为现实有些困难，但万一呢 :wink: "}]},{"tag":"Java","payload":[{"title":"字节码-无关性的基石","date":"2022-05-04","tags":["Java","byte","code"],"categories":"Java","content":"\r\n\r\n字节码技术是虚拟机实现平台无关性，语言无关性的基石，得益于此，Java语言才能在嵌入式，web服务端等领域大展拳脚并受到长期欢迎。围绕字节码技术，发展出一批拥有不同特性的运行于Java虚拟机之上的编程语言，如groovy，Scala，kotlin等。虚拟机只与class文件绑定，它不关心class文件来自何处，是来自本地的磁盘文件，还是来自于网络，是由.java文件编译而来，还是由.groovy文件编译而来，只要是有效的class文件，虚拟机便能够运行。\r\n\r\n一个class文件由连续的8-bit、16-bit和32-bit的无符号数的流构成，并且以大端模式存储。class文件的格式可以以一种C-like结构体的方式描述，结构体由`items`和`tables`构成。tables由零个或者任意的items构成。class文件的格式结构体描述如下，其中u1，u2，u4为`items`,_info结尾的项为`tables`\r\n\r\n    ClassFile{\r\n        u4              magic;\r\n        u2              minor_version;\r\n        u2              major_version;\r\n        u2              constant_pool_count;\r\n        cp_info         constant_pool[constant_pool_count-1];\r\n        u2              access_flags;\r\n        u2              this_class;\r\n        u2              super_class;\r\n        u2              interfaces_count;\r\n        u2              interfaces[interfaces_count];\r\n        u2              fields_count;\r\n        field_info      fields[fields_count];\r\n        u2              methods_count;\r\n        method_info     methods[methods_count];\r\n        u2              attributes_count;\r\n        attribute_info  attributes[attributes_count];\r\n    }\r\n\r\n> magic\r\n\r\n魔数，固定为OxCAFEBABE,标志为一个class文件。\r\n\r\n> minor_version,major_version\r\n\r\n它们共同决定了一个class文件的版本，不同的Java SE所能支持的class文件版本是不同的，比如Java8支持主版本45-52，Java18支持主版本45-62。主版本号 >= 56时，此版本号限制为0或者65535，之前的主版本则随意。Java虚拟机的实现如果遵循JavaSE的某版本(>=12)，那么就必须支持该版本的preview feature，并且默认关闭支持，但是提供途径可以开启支持。一个class文件的版本若为(45 - N+44).65535的形式，则其是依赖JavaSEN的preview feature的class文件。一个遵循JavaSEN的虚拟机实现，只有在开启preview feature支持时，才能加载(45 - N+44).65535的class文件，普通的则不受影响。\r\n\r\n> constant_pool_count\r\n\r\n常量池条目的数量加一。\r\n\r\n> constant_pool[]\r\n\r\n常量池是一张可包含各种字符串常量，类名，接口名，字段名以及其他表示class文件中条目的常量的表，表中entry的格式由其第一个字节`tag`指示。常量表的索引从1到constant_pool_count - 1。\r\n\r\n> access_flags\r\n\r\naccess_flags是一个掩码标记，用来指示一个类或者接口的访问权限以及各种属性。\r\n\r\n|Flag name|Value|Interpretation|\r\n|:-|:-:|:-|\r\n|ACC_PUBLIC|0x0001|Declared public; may be accessed from outside its package.|\r\n|ACC_FINAL|0x0010|Declared final; no subclasses allowed|\r\n|ACC_SUPER|0x0020|Treat superclass methods specially when invoked by the invokespecial instruction|\r\n|ACC_INTERFACE|0x0200|Is an interface, not a class|\r\n|ACC_ABSTRACT|0x0400|Declared abstract; must not be instantiated|\r\n|ACC_SYNTHETIC|0x1000|Declared synthetic; not present in the source code.|\r\n|ACC_ANNATATION|0x2000|Declared as an annotation interface.|\r\n|ACC_ENUM|0x4000|Declared as an enum class.|\r\n|ACC_MODULE|0x8000|Is a module, not a class or interface.|\r\n\r\nACC_SUPER用来指示当遇到invokespecial指令将表示的两种语义时，应该选择哪种进行解释。Java8之后，无论class文件是否设置该值，虚拟机都认为设置了。ACC_SYNTHETIC指示该类或者接口是由编译器动态生成的，而不是本身就存在于源码中的。\r\n\r\n> this_class\r\n\r\n该值是常量池表的一个有效索引，索引指向的条目必须是一个代表该类或者接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> super_class\r\n\r\n该值或为0或为指向常量池的一个有效索引，若为0，则超类为Object，否则指向常量池中一个代表超类结构的`CONSTANT_Class_info`类型。\r\n\r\n> interfaces_count\r\n\r\n代表该类或者接口有几个直接父接口。\r\n\r\n> interfaces[]\r\n\r\n一个指向常量池的有效索引的数组，每个索引指向的条目必须是代表父接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> fields_count\r\n\r\n指示该类或接口的类变量和实例变量的总数目。\r\n\r\n> fields[]\r\n\r\n字段表的每个条目必须是`field_info`结构，用来表示一个字段的完整描述。\r\n\r\n> methods_count\r\n\r\n指示该类或者接口有多少方法。\r\n\r\n> methods[]\r\n\r\n方法表的每个条目必须是`method_info`结构，用来表示一个方法的完整描述。如果结构中没有设置`ACC_NATIVE`或者`ACC_ABSTRACT`，那么方法的虚拟机指令实现也会被提供。\r\n\r\n> attributes_count\r\n\r\n指示该类属性的总数目。\r\n\r\n> attributes[]\r\n\r\n属性表的每个条目必须是`attribute_info`结构，用来表示一个属性的完整描述。属性表条目可以用来表示class文件的属性，也可以用来表示一个方法的属性。`attribute_info`的结构如下：\r\n\r\n    attribute_info {\r\n        u2 attribute_name_index; \r\n        u4 attribute_length; \r\n        u1 info[attribute_length];\r\n    }\r\n\r\n常量池表是class文件的资源仓库，与class文件中的其他item有着各种各样的联系。常量池表的第0号索引被空出来，用来在表示不引用任何常量池item的特殊含义。常量池中主要有两类常量：字面量和符号引用，字面量接近Java语言层面的常量概念，符号引用则属于编译原理方面的概念，主要包括package、Fully Qualified Name、Descriptor、Method Handle、Method Type、Invoke Dynamic、Dynamically-Computed Call Site、Dynamically-Computed Constant。\r\n\r\n类或者接口的名称在class文件中总是被表示为全限定类名的utf8编码形式，放在常量池的`CONSTANT_Utf8_info`结构中。而方法，字段，本地变量，形参则为非全限定类名的Unicode编码方式。\r\n\r\n类中的字段和方法的类型被一个叫descriptor的字符串来表示，其在常量池中是一个`CONSTANT_Utf8_info`结构。字段描述符被表示为FieldDescriptor:FieldType。Object类型的字段的描述符为Ljava/lang/Object,double[][][]类型的字段的描述符为[[[D，array类型不能超过255个维度。方法描述符被表示为：MethodDescriptor:( {ParameterDescriptor} ) ReturnDescriptor，比如Object m(int i, double d, Thread t) {...}的描述符为(IDLjava/lang/Thread;)Ljava/lang/Object;。\r\n\r\n常量池的每一项都是一个表，截至jdk18，共有17类表结构，这些表结构的第一项都是一个u1的tag，表示其是哪种类型的表结构。具体如下所示：\r\n|Constant Kind|Tag|\r\n|:-|:-|\r\n|CONSTANT_Class|7|\r\n|CONSTANT_Fieldref|9|\r\n|CONSTANT_Methodref|10|\r\n|CONSTANT_InterfaceMethodref|11|\r\n|CONSTANT_String|8|\r\n|CONSTANT_Integer|3|\r\n|CONSTANT_Float|4|\r\n|CONSTANT_Long|5|\r\n|CONSTANT_Double|6|\r\n|CONSTANT_NameAndType|12|\r\n|CONSTANT_Utf8|1|\r\n|CONSTANT_MethodHandle|15|\r\n|CONSTANT_MethodType|16|\r\n|CONSTANT_Dynamic|17|\r\n|CONSTANT_InvokeDynamic|18|\r\n|CONSTANT_Module|19|\r\n|CONSTANT_Package|20|\r\n\r\n所有类型的条目都遵循以下格式：\r\n\r\n    cp_info { \r\n        u1 tag;\r\n        u1 info[]; \r\n    }\r\n\r\n- CONSTANT_Class_info\r\n\r\n        CONSTANT_Class_info {\r\n            // 7  \r\n            u1 tag;\r\n\r\n            // 指向常量池表的某一项，该项为CONSTANT_Utf8_info结构\r\n            // 存储类的全限定类名\r\n            u2 name_index;  \r\n        }\r\n\r\n- CONSTANT_Fieldref_info\r\n\r\n        CONSTANT_Fieldref_info { \r\n            // 9\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构可表示一个类或者接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和字段描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_Methodref_info\r\n\r\n        CONSTANT_Methodref_info { \r\n            // 10\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个类\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_InterfaceMethodref_info\r\n\r\n        CONSTANT_InterfaceMethodref_info { \r\n            // 11\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_String_info\r\n\r\n        CONSTANT_String_info { \r\n            // 8\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info结构\r\n            // 该结构表示字符串对象的Unicode编码\r\n            u2 string_index; \r\n        }\r\n\r\n- CONSTANT_Integer_info\r\n\r\n        CONSTANT_Integer_info {\r\n            // 3 \r\n            u1 tag; \r\n\r\n            // 表示int值\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Float_info\r\n\r\n        CONSTANT_Float_info { \r\n            // 4 \r\n            u1 tag; \r\n\r\n            // 表示为IEEE754的单浮点数编码\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Long_info\r\n  \r\n        CONSTANT_Long_info { \r\n            // 5\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_Double_info\r\n  \r\n        CONSTANT_Double_info { \r\n            // 6\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_NameAndType_info\r\n\r\n        CONSTANT_NameAndType_info { \r\n            // 12\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法的名称\r\n            u2 name_index; \r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法描述符\r\n            u2 descriptor_index;\r\n        }\r\n\r\n- CONSTANT_Utf8_info\r\n\r\n        CONSTANT_Utf8_info { \r\n            // 1\r\n            u1 tag;\r\n\r\n            // byte数组的长度\r\n            u2 length; \r\n\r\n            // UTF-8编码\r\n            u1 bytes[length]; \r\n        }\r\n\r\n- CONSTANT_MethodHandle_info\r\n\r\n        CONSTANT_MethodHandle_info { \r\n            // 15\r\n            u1 tag;\r\n\r\n            // 表示方法句柄的类型，该类型会影响字节码的行为\r\n            // 1.REF_getField 2.REF_getStatic 3.REF_putField\r\n            // 4.REF_putStatic 5.REF_invokeVirtual 6.REF_invokeStatic\r\n            // 7.REF_invokeSpecial 8.REF_newInvokeSpecial 9.REF_invokeInterface\r\n            u1 reference_kind; \r\n\r\n            // 根据reference_kind的值，指向常量池中的某CONSTANT_Fieldref_info\r\n\r\n            // CONSTANT_Methodref_info或者CONSTANT_InterfaceMethodref_info结构\r\n            u2 reference_index;\r\n        }\r\n\r\n- CONSTANT_MethodType_info\r\n\r\n        CONSTANT_MethodType_info { \r\n            // 16\r\n            u1 tag;\r\n\r\n            // 指向常量池中的某表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n        }\r\n\r\n- CONSTANT_Dynamic_info （表示一个动态调用计算出的常量）\r\n\r\n        CONSTANT_Dynamic_info { \r\n            // 17\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示字段描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_InvokeDynamic_info （表示一个动态计算出的方法调用）\r\n  \r\n        CONSTANT_InvokeDynamic_info { \r\n            // 18\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示方法描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_Module_info\r\n\r\n        CONSTANT_Module_info { \r\n            // 19\r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示模块名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n\r\n- CONSTANT_Package_info\r\n\r\n        CONSTANT_Package_info {\r\n            // 20 \r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示包名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n    \r\nclass文件中fields数组中的条目都遵循`field_info`结构，数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n    field_info {\r\n        // 掩码标记，指示访问权限以及属性\r\n        // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED\r\n        // ACC_STATIC、ACC_FINAL、ACC_VOLATILE\r\n        // ACC_TRANSIENT、ACC_SYNTHETIC、ACC_ENUM\r\n        u2 access_flags; \r\n\r\n        // 指向常量池中一个表示字段名的CONSTANT_Utf8_info结构\r\n        u2 name_index;\r\n\r\n        // 指向常量池中一个表示字段描述符的CONSTANT_Utf8_info结构\r\n        u2 descriptor_index; \r\n\r\n        // 字段额外属性数组的大小\r\n        u2 attributes_count;\r\n\r\n        // attribute_info结构的数组\r\n        attribute_info attributes[attributes_count]; \r\n    }\r\n\r\nclass文件中methods数组中的条目都遵循`method_info`结构，每个条目表示一个方法，一个实例初始化方法，或者一个类初始化方法。数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n        method_info { \r\n            // 掩码标记，指示访问权限以及属性\r\n            // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED、ACC_STATIC\r\n            // ACC_FINAL、ACC_SYNCHRONIZED、ACC_BRIDGE、ACC_VARARGS\r\n            // ACC_NATIVE、ACC_ABSTRACT、ACC_STRICT、ACC_SYNTHETIC\r\n            u2 access_flags; \r\n\r\n            // 指向常量池中一个表示方法，<init>方法或者<clinit>方法的CONSTANT_Utf8_info结构\r\n            u2 name_index;\r\n\r\n            // 指向常量池中一个表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n\r\n            // 方法额外属性数组的大小\r\n            attributes_count;\r\n\r\n            // attribute_info结构的数组\r\n            attribute_info attributes[attributes_count]; \r\n        }\r\n\r\nattributes被用在class文件，field_info，method_info，Code_attribute，record_component_info结构中。field_info结构如下：\r\n\r\n        attribute_info {\r\n            // 指向常量池中一个表示属性名的CONSTANT_Utf8_info结构\r\n            u2 attribute_name_index; \r\n\r\n            // 表示附加属性的字节长度\r\n            u4 attribute_length;\r\n\r\n            // 附加属性\r\n            u1 info[attribute_length];\r\n        }\r\n\r\n附加属性相关的东西就说来话长了，有时间在写吧。"},{"title":"并发探索","categories":"Java","tags":["Java","并发"],"date":"2023-04-12","content":"\n\n[embed](https://miro.com/app/board/uXjVPaWzcGg=/?share_link_id=77380253885)\n\n\n[embed](https://miro.com/app/board/uXjVPZryvFY=/?share_link_id=495517938632)\n\n"}]},{"tag":"byte","payload":[{"title":"字节码-无关性的基石","date":"2022-05-04","tags":["Java","byte","code"],"categories":"Java","content":"\r\n\r\n字节码技术是虚拟机实现平台无关性，语言无关性的基石，得益于此，Java语言才能在嵌入式，web服务端等领域大展拳脚并受到长期欢迎。围绕字节码技术，发展出一批拥有不同特性的运行于Java虚拟机之上的编程语言，如groovy，Scala，kotlin等。虚拟机只与class文件绑定，它不关心class文件来自何处，是来自本地的磁盘文件，还是来自于网络，是由.java文件编译而来，还是由.groovy文件编译而来，只要是有效的class文件，虚拟机便能够运行。\r\n\r\n一个class文件由连续的8-bit、16-bit和32-bit的无符号数的流构成，并且以大端模式存储。class文件的格式可以以一种C-like结构体的方式描述，结构体由`items`和`tables`构成。tables由零个或者任意的items构成。class文件的格式结构体描述如下，其中u1，u2，u4为`items`,_info结尾的项为`tables`\r\n\r\n    ClassFile{\r\n        u4              magic;\r\n        u2              minor_version;\r\n        u2              major_version;\r\n        u2              constant_pool_count;\r\n        cp_info         constant_pool[constant_pool_count-1];\r\n        u2              access_flags;\r\n        u2              this_class;\r\n        u2              super_class;\r\n        u2              interfaces_count;\r\n        u2              interfaces[interfaces_count];\r\n        u2              fields_count;\r\n        field_info      fields[fields_count];\r\n        u2              methods_count;\r\n        method_info     methods[methods_count];\r\n        u2              attributes_count;\r\n        attribute_info  attributes[attributes_count];\r\n    }\r\n\r\n> magic\r\n\r\n魔数，固定为OxCAFEBABE,标志为一个class文件。\r\n\r\n> minor_version,major_version\r\n\r\n它们共同决定了一个class文件的版本，不同的Java SE所能支持的class文件版本是不同的，比如Java8支持主版本45-52，Java18支持主版本45-62。主版本号 >= 56时，此版本号限制为0或者65535，之前的主版本则随意。Java虚拟机的实现如果遵循JavaSE的某版本(>=12)，那么就必须支持该版本的preview feature，并且默认关闭支持，但是提供途径可以开启支持。一个class文件的版本若为(45 - N+44).65535的形式，则其是依赖JavaSEN的preview feature的class文件。一个遵循JavaSEN的虚拟机实现，只有在开启preview feature支持时，才能加载(45 - N+44).65535的class文件，普通的则不受影响。\r\n\r\n> constant_pool_count\r\n\r\n常量池条目的数量加一。\r\n\r\n> constant_pool[]\r\n\r\n常量池是一张可包含各种字符串常量，类名，接口名，字段名以及其他表示class文件中条目的常量的表，表中entry的格式由其第一个字节`tag`指示。常量表的索引从1到constant_pool_count - 1。\r\n\r\n> access_flags\r\n\r\naccess_flags是一个掩码标记，用来指示一个类或者接口的访问权限以及各种属性。\r\n\r\n|Flag name|Value|Interpretation|\r\n|:-|:-:|:-|\r\n|ACC_PUBLIC|0x0001|Declared public; may be accessed from outside its package.|\r\n|ACC_FINAL|0x0010|Declared final; no subclasses allowed|\r\n|ACC_SUPER|0x0020|Treat superclass methods specially when invoked by the invokespecial instruction|\r\n|ACC_INTERFACE|0x0200|Is an interface, not a class|\r\n|ACC_ABSTRACT|0x0400|Declared abstract; must not be instantiated|\r\n|ACC_SYNTHETIC|0x1000|Declared synthetic; not present in the source code.|\r\n|ACC_ANNATATION|0x2000|Declared as an annotation interface.|\r\n|ACC_ENUM|0x4000|Declared as an enum class.|\r\n|ACC_MODULE|0x8000|Is a module, not a class or interface.|\r\n\r\nACC_SUPER用来指示当遇到invokespecial指令将表示的两种语义时，应该选择哪种进行解释。Java8之后，无论class文件是否设置该值，虚拟机都认为设置了。ACC_SYNTHETIC指示该类或者接口是由编译器动态生成的，而不是本身就存在于源码中的。\r\n\r\n> this_class\r\n\r\n该值是常量池表的一个有效索引，索引指向的条目必须是一个代表该类或者接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> super_class\r\n\r\n该值或为0或为指向常量池的一个有效索引，若为0，则超类为Object，否则指向常量池中一个代表超类结构的`CONSTANT_Class_info`类型。\r\n\r\n> interfaces_count\r\n\r\n代表该类或者接口有几个直接父接口。\r\n\r\n> interfaces[]\r\n\r\n一个指向常量池的有效索引的数组，每个索引指向的条目必须是代表父接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> fields_count\r\n\r\n指示该类或接口的类变量和实例变量的总数目。\r\n\r\n> fields[]\r\n\r\n字段表的每个条目必须是`field_info`结构，用来表示一个字段的完整描述。\r\n\r\n> methods_count\r\n\r\n指示该类或者接口有多少方法。\r\n\r\n> methods[]\r\n\r\n方法表的每个条目必须是`method_info`结构，用来表示一个方法的完整描述。如果结构中没有设置`ACC_NATIVE`或者`ACC_ABSTRACT`，那么方法的虚拟机指令实现也会被提供。\r\n\r\n> attributes_count\r\n\r\n指示该类属性的总数目。\r\n\r\n> attributes[]\r\n\r\n属性表的每个条目必须是`attribute_info`结构，用来表示一个属性的完整描述。属性表条目可以用来表示class文件的属性，也可以用来表示一个方法的属性。`attribute_info`的结构如下：\r\n\r\n    attribute_info {\r\n        u2 attribute_name_index; \r\n        u4 attribute_length; \r\n        u1 info[attribute_length];\r\n    }\r\n\r\n常量池表是class文件的资源仓库，与class文件中的其他item有着各种各样的联系。常量池表的第0号索引被空出来，用来在表示不引用任何常量池item的特殊含义。常量池中主要有两类常量：字面量和符号引用，字面量接近Java语言层面的常量概念，符号引用则属于编译原理方面的概念，主要包括package、Fully Qualified Name、Descriptor、Method Handle、Method Type、Invoke Dynamic、Dynamically-Computed Call Site、Dynamically-Computed Constant。\r\n\r\n类或者接口的名称在class文件中总是被表示为全限定类名的utf8编码形式，放在常量池的`CONSTANT_Utf8_info`结构中。而方法，字段，本地变量，形参则为非全限定类名的Unicode编码方式。\r\n\r\n类中的字段和方法的类型被一个叫descriptor的字符串来表示，其在常量池中是一个`CONSTANT_Utf8_info`结构。字段描述符被表示为FieldDescriptor:FieldType。Object类型的字段的描述符为Ljava/lang/Object,double[][][]类型的字段的描述符为[[[D，array类型不能超过255个维度。方法描述符被表示为：MethodDescriptor:( {ParameterDescriptor} ) ReturnDescriptor，比如Object m(int i, double d, Thread t) {...}的描述符为(IDLjava/lang/Thread;)Ljava/lang/Object;。\r\n\r\n常量池的每一项都是一个表，截至jdk18，共有17类表结构，这些表结构的第一项都是一个u1的tag，表示其是哪种类型的表结构。具体如下所示：\r\n|Constant Kind|Tag|\r\n|:-|:-|\r\n|CONSTANT_Class|7|\r\n|CONSTANT_Fieldref|9|\r\n|CONSTANT_Methodref|10|\r\n|CONSTANT_InterfaceMethodref|11|\r\n|CONSTANT_String|8|\r\n|CONSTANT_Integer|3|\r\n|CONSTANT_Float|4|\r\n|CONSTANT_Long|5|\r\n|CONSTANT_Double|6|\r\n|CONSTANT_NameAndType|12|\r\n|CONSTANT_Utf8|1|\r\n|CONSTANT_MethodHandle|15|\r\n|CONSTANT_MethodType|16|\r\n|CONSTANT_Dynamic|17|\r\n|CONSTANT_InvokeDynamic|18|\r\n|CONSTANT_Module|19|\r\n|CONSTANT_Package|20|\r\n\r\n所有类型的条目都遵循以下格式：\r\n\r\n    cp_info { \r\n        u1 tag;\r\n        u1 info[]; \r\n    }\r\n\r\n- CONSTANT_Class_info\r\n\r\n        CONSTANT_Class_info {\r\n            // 7  \r\n            u1 tag;\r\n\r\n            // 指向常量池表的某一项，该项为CONSTANT_Utf8_info结构\r\n            // 存储类的全限定类名\r\n            u2 name_index;  \r\n        }\r\n\r\n- CONSTANT_Fieldref_info\r\n\r\n        CONSTANT_Fieldref_info { \r\n            // 9\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构可表示一个类或者接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和字段描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_Methodref_info\r\n\r\n        CONSTANT_Methodref_info { \r\n            // 10\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个类\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_InterfaceMethodref_info\r\n\r\n        CONSTANT_InterfaceMethodref_info { \r\n            // 11\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_String_info\r\n\r\n        CONSTANT_String_info { \r\n            // 8\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info结构\r\n            // 该结构表示字符串对象的Unicode编码\r\n            u2 string_index; \r\n        }\r\n\r\n- CONSTANT_Integer_info\r\n\r\n        CONSTANT_Integer_info {\r\n            // 3 \r\n            u1 tag; \r\n\r\n            // 表示int值\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Float_info\r\n\r\n        CONSTANT_Float_info { \r\n            // 4 \r\n            u1 tag; \r\n\r\n            // 表示为IEEE754的单浮点数编码\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Long_info\r\n  \r\n        CONSTANT_Long_info { \r\n            // 5\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_Double_info\r\n  \r\n        CONSTANT_Double_info { \r\n            // 6\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_NameAndType_info\r\n\r\n        CONSTANT_NameAndType_info { \r\n            // 12\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法的名称\r\n            u2 name_index; \r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法描述符\r\n            u2 descriptor_index;\r\n        }\r\n\r\n- CONSTANT_Utf8_info\r\n\r\n        CONSTANT_Utf8_info { \r\n            // 1\r\n            u1 tag;\r\n\r\n            // byte数组的长度\r\n            u2 length; \r\n\r\n            // UTF-8编码\r\n            u1 bytes[length]; \r\n        }\r\n\r\n- CONSTANT_MethodHandle_info\r\n\r\n        CONSTANT_MethodHandle_info { \r\n            // 15\r\n            u1 tag;\r\n\r\n            // 表示方法句柄的类型，该类型会影响字节码的行为\r\n            // 1.REF_getField 2.REF_getStatic 3.REF_putField\r\n            // 4.REF_putStatic 5.REF_invokeVirtual 6.REF_invokeStatic\r\n            // 7.REF_invokeSpecial 8.REF_newInvokeSpecial 9.REF_invokeInterface\r\n            u1 reference_kind; \r\n\r\n            // 根据reference_kind的值，指向常量池中的某CONSTANT_Fieldref_info\r\n\r\n            // CONSTANT_Methodref_info或者CONSTANT_InterfaceMethodref_info结构\r\n            u2 reference_index;\r\n        }\r\n\r\n- CONSTANT_MethodType_info\r\n\r\n        CONSTANT_MethodType_info { \r\n            // 16\r\n            u1 tag;\r\n\r\n            // 指向常量池中的某表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n        }\r\n\r\n- CONSTANT_Dynamic_info （表示一个动态调用计算出的常量）\r\n\r\n        CONSTANT_Dynamic_info { \r\n            // 17\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示字段描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_InvokeDynamic_info （表示一个动态计算出的方法调用）\r\n  \r\n        CONSTANT_InvokeDynamic_info { \r\n            // 18\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示方法描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_Module_info\r\n\r\n        CONSTANT_Module_info { \r\n            // 19\r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示模块名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n\r\n- CONSTANT_Package_info\r\n\r\n        CONSTANT_Package_info {\r\n            // 20 \r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示包名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n    \r\nclass文件中fields数组中的条目都遵循`field_info`结构，数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n    field_info {\r\n        // 掩码标记，指示访问权限以及属性\r\n        // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED\r\n        // ACC_STATIC、ACC_FINAL、ACC_VOLATILE\r\n        // ACC_TRANSIENT、ACC_SYNTHETIC、ACC_ENUM\r\n        u2 access_flags; \r\n\r\n        // 指向常量池中一个表示字段名的CONSTANT_Utf8_info结构\r\n        u2 name_index;\r\n\r\n        // 指向常量池中一个表示字段描述符的CONSTANT_Utf8_info结构\r\n        u2 descriptor_index; \r\n\r\n        // 字段额外属性数组的大小\r\n        u2 attributes_count;\r\n\r\n        // attribute_info结构的数组\r\n        attribute_info attributes[attributes_count]; \r\n    }\r\n\r\nclass文件中methods数组中的条目都遵循`method_info`结构，每个条目表示一个方法，一个实例初始化方法，或者一个类初始化方法。数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n        method_info { \r\n            // 掩码标记，指示访问权限以及属性\r\n            // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED、ACC_STATIC\r\n            // ACC_FINAL、ACC_SYNCHRONIZED、ACC_BRIDGE、ACC_VARARGS\r\n            // ACC_NATIVE、ACC_ABSTRACT、ACC_STRICT、ACC_SYNTHETIC\r\n            u2 access_flags; \r\n\r\n            // 指向常量池中一个表示方法，<init>方法或者<clinit>方法的CONSTANT_Utf8_info结构\r\n            u2 name_index;\r\n\r\n            // 指向常量池中一个表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n\r\n            // 方法额外属性数组的大小\r\n            attributes_count;\r\n\r\n            // attribute_info结构的数组\r\n            attribute_info attributes[attributes_count]; \r\n        }\r\n\r\nattributes被用在class文件，field_info，method_info，Code_attribute，record_component_info结构中。field_info结构如下：\r\n\r\n        attribute_info {\r\n            // 指向常量池中一个表示属性名的CONSTANT_Utf8_info结构\r\n            u2 attribute_name_index; \r\n\r\n            // 表示附加属性的字节长度\r\n            u4 attribute_length;\r\n\r\n            // 附加属性\r\n            u1 info[attribute_length];\r\n        }\r\n\r\n附加属性相关的东西就说来话长了，有时间在写吧。"}]},{"tag":"code","payload":[{"title":"字节码-无关性的基石","date":"2022-05-04","tags":["Java","byte","code"],"categories":"Java","content":"\r\n\r\n字节码技术是虚拟机实现平台无关性，语言无关性的基石，得益于此，Java语言才能在嵌入式，web服务端等领域大展拳脚并受到长期欢迎。围绕字节码技术，发展出一批拥有不同特性的运行于Java虚拟机之上的编程语言，如groovy，Scala，kotlin等。虚拟机只与class文件绑定，它不关心class文件来自何处，是来自本地的磁盘文件，还是来自于网络，是由.java文件编译而来，还是由.groovy文件编译而来，只要是有效的class文件，虚拟机便能够运行。\r\n\r\n一个class文件由连续的8-bit、16-bit和32-bit的无符号数的流构成，并且以大端模式存储。class文件的格式可以以一种C-like结构体的方式描述，结构体由`items`和`tables`构成。tables由零个或者任意的items构成。class文件的格式结构体描述如下，其中u1，u2，u4为`items`,_info结尾的项为`tables`\r\n\r\n    ClassFile{\r\n        u4              magic;\r\n        u2              minor_version;\r\n        u2              major_version;\r\n        u2              constant_pool_count;\r\n        cp_info         constant_pool[constant_pool_count-1];\r\n        u2              access_flags;\r\n        u2              this_class;\r\n        u2              super_class;\r\n        u2              interfaces_count;\r\n        u2              interfaces[interfaces_count];\r\n        u2              fields_count;\r\n        field_info      fields[fields_count];\r\n        u2              methods_count;\r\n        method_info     methods[methods_count];\r\n        u2              attributes_count;\r\n        attribute_info  attributes[attributes_count];\r\n    }\r\n\r\n> magic\r\n\r\n魔数，固定为OxCAFEBABE,标志为一个class文件。\r\n\r\n> minor_version,major_version\r\n\r\n它们共同决定了一个class文件的版本，不同的Java SE所能支持的class文件版本是不同的，比如Java8支持主版本45-52，Java18支持主版本45-62。主版本号 >= 56时，此版本号限制为0或者65535，之前的主版本则随意。Java虚拟机的实现如果遵循JavaSE的某版本(>=12)，那么就必须支持该版本的preview feature，并且默认关闭支持，但是提供途径可以开启支持。一个class文件的版本若为(45 - N+44).65535的形式，则其是依赖JavaSEN的preview feature的class文件。一个遵循JavaSEN的虚拟机实现，只有在开启preview feature支持时，才能加载(45 - N+44).65535的class文件，普通的则不受影响。\r\n\r\n> constant_pool_count\r\n\r\n常量池条目的数量加一。\r\n\r\n> constant_pool[]\r\n\r\n常量池是一张可包含各种字符串常量，类名，接口名，字段名以及其他表示class文件中条目的常量的表，表中entry的格式由其第一个字节`tag`指示。常量表的索引从1到constant_pool_count - 1。\r\n\r\n> access_flags\r\n\r\naccess_flags是一个掩码标记，用来指示一个类或者接口的访问权限以及各种属性。\r\n\r\n|Flag name|Value|Interpretation|\r\n|:-|:-:|:-|\r\n|ACC_PUBLIC|0x0001|Declared public; may be accessed from outside its package.|\r\n|ACC_FINAL|0x0010|Declared final; no subclasses allowed|\r\n|ACC_SUPER|0x0020|Treat superclass methods specially when invoked by the invokespecial instruction|\r\n|ACC_INTERFACE|0x0200|Is an interface, not a class|\r\n|ACC_ABSTRACT|0x0400|Declared abstract; must not be instantiated|\r\n|ACC_SYNTHETIC|0x1000|Declared synthetic; not present in the source code.|\r\n|ACC_ANNATATION|0x2000|Declared as an annotation interface.|\r\n|ACC_ENUM|0x4000|Declared as an enum class.|\r\n|ACC_MODULE|0x8000|Is a module, not a class or interface.|\r\n\r\nACC_SUPER用来指示当遇到invokespecial指令将表示的两种语义时，应该选择哪种进行解释。Java8之后，无论class文件是否设置该值，虚拟机都认为设置了。ACC_SYNTHETIC指示该类或者接口是由编译器动态生成的，而不是本身就存在于源码中的。\r\n\r\n> this_class\r\n\r\n该值是常量池表的一个有效索引，索引指向的条目必须是一个代表该类或者接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> super_class\r\n\r\n该值或为0或为指向常量池的一个有效索引，若为0，则超类为Object，否则指向常量池中一个代表超类结构的`CONSTANT_Class_info`类型。\r\n\r\n> interfaces_count\r\n\r\n代表该类或者接口有几个直接父接口。\r\n\r\n> interfaces[]\r\n\r\n一个指向常量池的有效索引的数组，每个索引指向的条目必须是代表父接口结构的`CONSTANT_Class_info`类型。\r\n\r\n> fields_count\r\n\r\n指示该类或接口的类变量和实例变量的总数目。\r\n\r\n> fields[]\r\n\r\n字段表的每个条目必须是`field_info`结构，用来表示一个字段的完整描述。\r\n\r\n> methods_count\r\n\r\n指示该类或者接口有多少方法。\r\n\r\n> methods[]\r\n\r\n方法表的每个条目必须是`method_info`结构，用来表示一个方法的完整描述。如果结构中没有设置`ACC_NATIVE`或者`ACC_ABSTRACT`，那么方法的虚拟机指令实现也会被提供。\r\n\r\n> attributes_count\r\n\r\n指示该类属性的总数目。\r\n\r\n> attributes[]\r\n\r\n属性表的每个条目必须是`attribute_info`结构，用来表示一个属性的完整描述。属性表条目可以用来表示class文件的属性，也可以用来表示一个方法的属性。`attribute_info`的结构如下：\r\n\r\n    attribute_info {\r\n        u2 attribute_name_index; \r\n        u4 attribute_length; \r\n        u1 info[attribute_length];\r\n    }\r\n\r\n常量池表是class文件的资源仓库，与class文件中的其他item有着各种各样的联系。常量池表的第0号索引被空出来，用来在表示不引用任何常量池item的特殊含义。常量池中主要有两类常量：字面量和符号引用，字面量接近Java语言层面的常量概念，符号引用则属于编译原理方面的概念，主要包括package、Fully Qualified Name、Descriptor、Method Handle、Method Type、Invoke Dynamic、Dynamically-Computed Call Site、Dynamically-Computed Constant。\r\n\r\n类或者接口的名称在class文件中总是被表示为全限定类名的utf8编码形式，放在常量池的`CONSTANT_Utf8_info`结构中。而方法，字段，本地变量，形参则为非全限定类名的Unicode编码方式。\r\n\r\n类中的字段和方法的类型被一个叫descriptor的字符串来表示，其在常量池中是一个`CONSTANT_Utf8_info`结构。字段描述符被表示为FieldDescriptor:FieldType。Object类型的字段的描述符为Ljava/lang/Object,double[][][]类型的字段的描述符为[[[D，array类型不能超过255个维度。方法描述符被表示为：MethodDescriptor:( {ParameterDescriptor} ) ReturnDescriptor，比如Object m(int i, double d, Thread t) {...}的描述符为(IDLjava/lang/Thread;)Ljava/lang/Object;。\r\n\r\n常量池的每一项都是一个表，截至jdk18，共有17类表结构，这些表结构的第一项都是一个u1的tag，表示其是哪种类型的表结构。具体如下所示：\r\n|Constant Kind|Tag|\r\n|:-|:-|\r\n|CONSTANT_Class|7|\r\n|CONSTANT_Fieldref|9|\r\n|CONSTANT_Methodref|10|\r\n|CONSTANT_InterfaceMethodref|11|\r\n|CONSTANT_String|8|\r\n|CONSTANT_Integer|3|\r\n|CONSTANT_Float|4|\r\n|CONSTANT_Long|5|\r\n|CONSTANT_Double|6|\r\n|CONSTANT_NameAndType|12|\r\n|CONSTANT_Utf8|1|\r\n|CONSTANT_MethodHandle|15|\r\n|CONSTANT_MethodType|16|\r\n|CONSTANT_Dynamic|17|\r\n|CONSTANT_InvokeDynamic|18|\r\n|CONSTANT_Module|19|\r\n|CONSTANT_Package|20|\r\n\r\n所有类型的条目都遵循以下格式：\r\n\r\n    cp_info { \r\n        u1 tag;\r\n        u1 info[]; \r\n    }\r\n\r\n- CONSTANT_Class_info\r\n\r\n        CONSTANT_Class_info {\r\n            // 7  \r\n            u1 tag;\r\n\r\n            // 指向常量池表的某一项，该项为CONSTANT_Utf8_info结构\r\n            // 存储类的全限定类名\r\n            u2 name_index;  \r\n        }\r\n\r\n- CONSTANT_Fieldref_info\r\n\r\n        CONSTANT_Fieldref_info { \r\n            // 9\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构可表示一个类或者接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和字段描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_Methodref_info\r\n\r\n        CONSTANT_Methodref_info { \r\n            // 10\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个类\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_InterfaceMethodref_info\r\n\r\n        CONSTANT_InterfaceMethodref_info { \r\n            // 11\r\n            u1 tag;\r\n\r\n            // 指向常量池的某CONSTANT_Class_info结构\r\n            // 该结构只能表示一个接口\r\n            u2 class_index; \r\n\r\n            // 指向常量池的某CONSTANT_NameAndType_info结构\r\n            // 指示名称和方法描述符\r\n            u2 name_and_type_index; \r\n        }\r\n\r\n- CONSTANT_String_info\r\n\r\n        CONSTANT_String_info { \r\n            // 8\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info结构\r\n            // 该结构表示字符串对象的Unicode编码\r\n            u2 string_index; \r\n        }\r\n\r\n- CONSTANT_Integer_info\r\n\r\n        CONSTANT_Integer_info {\r\n            // 3 \r\n            u1 tag; \r\n\r\n            // 表示int值\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Float_info\r\n\r\n        CONSTANT_Float_info { \r\n            // 4 \r\n            u1 tag; \r\n\r\n            // 表示为IEEE754的单浮点数编码\r\n            u4 bytes;\r\n        }\r\n\r\n- CONSTANT_Long_info\r\n  \r\n        CONSTANT_Long_info { \r\n            // 5\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_Double_info\r\n  \r\n        CONSTANT_Double_info { \r\n            // 6\r\n            u1 tag;\r\n\r\n            // 高位\r\n            u4 high_bytes;\r\n\r\n            // 低位 \r\n            u4 low_bytes;\r\n        }\r\n\r\n- CONSTANT_NameAndType_info\r\n\r\n        CONSTANT_NameAndType_info { \r\n            // 12\r\n            u1 tag;\r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法的名称\r\n            u2 name_index; \r\n\r\n            // 指向常量池的一个CONSTANT_Utf8_info\r\n            // 表示一个字段或者方法描述符\r\n            u2 descriptor_index;\r\n        }\r\n\r\n- CONSTANT_Utf8_info\r\n\r\n        CONSTANT_Utf8_info { \r\n            // 1\r\n            u1 tag;\r\n\r\n            // byte数组的长度\r\n            u2 length; \r\n\r\n            // UTF-8编码\r\n            u1 bytes[length]; \r\n        }\r\n\r\n- CONSTANT_MethodHandle_info\r\n\r\n        CONSTANT_MethodHandle_info { \r\n            // 15\r\n            u1 tag;\r\n\r\n            // 表示方法句柄的类型，该类型会影响字节码的行为\r\n            // 1.REF_getField 2.REF_getStatic 3.REF_putField\r\n            // 4.REF_putStatic 5.REF_invokeVirtual 6.REF_invokeStatic\r\n            // 7.REF_invokeSpecial 8.REF_newInvokeSpecial 9.REF_invokeInterface\r\n            u1 reference_kind; \r\n\r\n            // 根据reference_kind的值，指向常量池中的某CONSTANT_Fieldref_info\r\n\r\n            // CONSTANT_Methodref_info或者CONSTANT_InterfaceMethodref_info结构\r\n            u2 reference_index;\r\n        }\r\n\r\n- CONSTANT_MethodType_info\r\n\r\n        CONSTANT_MethodType_info { \r\n            // 16\r\n            u1 tag;\r\n\r\n            // 指向常量池中的某表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n        }\r\n\r\n- CONSTANT_Dynamic_info （表示一个动态调用计算出的常量）\r\n\r\n        CONSTANT_Dynamic_info { \r\n            // 17\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示字段描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_InvokeDynamic_info （表示一个动态计算出的方法调用）\r\n  \r\n        CONSTANT_InvokeDynamic_info { \r\n            // 18\r\n            u1 tag;\r\n\r\n            // 指向attribute数组中bootstrap_methods数组的有效索引值\r\n            u2 bootstrap_method_attr_index; \r\n\r\n            // 指向常量池中的一个表示方法描述符的CONSTANT_NameAndType_info结构\r\n            u2 name_and_type_index;\r\n        }\r\n\r\n- CONSTANT_Module_info\r\n\r\n        CONSTANT_Module_info { \r\n            // 19\r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示模块名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n\r\n- CONSTANT_Package_info\r\n\r\n        CONSTANT_Package_info {\r\n            // 20 \r\n            u1 tag;\r\n\r\n            // 指向常量池中一个表示包名的CONSTANT_Utf8_info结构\r\n            u2 name_index; \r\n        }\r\n    \r\nclass文件中fields数组中的条目都遵循`field_info`结构，数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n    field_info {\r\n        // 掩码标记，指示访问权限以及属性\r\n        // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED\r\n        // ACC_STATIC、ACC_FINAL、ACC_VOLATILE\r\n        // ACC_TRANSIENT、ACC_SYNTHETIC、ACC_ENUM\r\n        u2 access_flags; \r\n\r\n        // 指向常量池中一个表示字段名的CONSTANT_Utf8_info结构\r\n        u2 name_index;\r\n\r\n        // 指向常量池中一个表示字段描述符的CONSTANT_Utf8_info结构\r\n        u2 descriptor_index; \r\n\r\n        // 字段额外属性数组的大小\r\n        u2 attributes_count;\r\n\r\n        // attribute_info结构的数组\r\n        attribute_info attributes[attributes_count]; \r\n    }\r\n\r\nclass文件中methods数组中的条目都遵循`method_info`结构，每个条目表示一个方法，一个实例初始化方法，或者一个类初始化方法。数组中的任意两个条目都不可能有相同的名称和描述符。field_info结构如下：\r\n\r\n        method_info { \r\n            // 掩码标记，指示访问权限以及属性\r\n            // ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED、ACC_STATIC\r\n            // ACC_FINAL、ACC_SYNCHRONIZED、ACC_BRIDGE、ACC_VARARGS\r\n            // ACC_NATIVE、ACC_ABSTRACT、ACC_STRICT、ACC_SYNTHETIC\r\n            u2 access_flags; \r\n\r\n            // 指向常量池中一个表示方法，<init>方法或者<clinit>方法的CONSTANT_Utf8_info结构\r\n            u2 name_index;\r\n\r\n            // 指向常量池中一个表示方法描述符的CONSTANT_Utf8_info结构\r\n            u2 descriptor_index; \r\n\r\n            // 方法额外属性数组的大小\r\n            attributes_count;\r\n\r\n            // attribute_info结构的数组\r\n            attribute_info attributes[attributes_count]; \r\n        }\r\n\r\nattributes被用在class文件，field_info，method_info，Code_attribute，record_component_info结构中。field_info结构如下：\r\n\r\n        attribute_info {\r\n            // 指向常量池中一个表示属性名的CONSTANT_Utf8_info结构\r\n            u2 attribute_name_index; \r\n\r\n            // 表示附加属性的字节长度\r\n            u4 attribute_length;\r\n\r\n            // 附加属性\r\n            u1 info[attribute_length];\r\n        }\r\n\r\n附加属性相关的东西就说来话长了，有时间在写吧。"}]},{"tag":"编程风格","payload":[{"title":"functional programming","date":"2022-05-05","tags":["编程风格","lambda","纯函数"],"categories":"theory","content":"\r\n\r\n> 函数式编程是一种编程范式，区别于面向对象编程和面向过程编程的命令风格，其风格是声明式的，是满足若干要素的构建软件的方式。\r\n\r\n函数式编程由纯函数的组合构成，以避免共享状态、可变数据以及副作用。理解函数式编程的第一步就是要理解什么是纯函数。\r\n\r\n所谓纯函数就是那种对于给定输入总是得出固定输出且不产生任何副作用的函数。纯函数是函数的一种类型，一个函数的目的可以是值映射，一系列步骤的组合或者是同系统中的其他模块通信。纯函数总是和值映射相关，一个参数，一个固定输出。比如Math.max(11,13)无论被调用多少次，什么时候调用，其结果都是13。而且因为该函数不存在将值存盘或者输出到标准输出上的行为，理论上来说，只要Math.max(11,13)出现的地方，都可以用13去代替。即所谓的引用透明性(referential transparency)。Math.random(),System.currentTime()不是纯函数，因为它们不满足一个输入对应一个输出的原则。\r\n\r\n纯函数用副本实现不可变性的。区别于全拷贝，它将数据分成一个个很小的块，只对变化的块进行复制，很象git管理库和提交的方式。基于不可变性，纯函数也不会修改任何外部状态。\r\n\r\n纯函数不修改外部状态避免了共享状态，也意味着不会产生任何副作用。在共享状态下，并发/并行过程 + 可变状态 = 不确定性，一个不确定的系统结果是无法预测的，可能会产生各种奇奇怪怪的bug，纯函数可以帮助我们避免这种bug。\r\n\r\n函数组合就是将两个以上的函数以某种顺序组合成一个函数的过程，一个函数就像是一个管道，我们的数据就在这一系列的管道中流过。基于这种风格，我们可以减少中间变量的使用。\r\n\r\n函数式编程倾向于重用一组通用的函数式实用程序来处理数据。面向对象的编程倾向于将方法和数据放在对象中。那些并置的方法只能对它们设计用于操作的数据类型进行操作，并且通常只能对包含在该特定对象实例中的数据进行操作。在函数式编程中，任何类型的数据都是平等的。相同的 map()实用程序可以映射对象、字符串、数字或任何其他数据类型，因为它将函数作为参数来适当地处理给定的数据类型。函数式编程使用高阶函数实现了它的通用实用技巧。\r\n\r\n更加具体清晰的functional programming说明可以参考Eric Elliott的文章[Master the JavaScript Interview: What is Functional Programming?](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0),以及Russ Olsen的演讲[Functional Programming in 40 Minutes](https://www.youtube.com/watch?v=0if71HOyVjY)。\r\n"},{"title":"reactive programming","date":"2022-05-11","tags":["reactive","编程风格"],"categories":"theory","content":"\r\n\r\n"}]},{"tag":"lambda","payload":[{"title":"functional programming","date":"2022-05-05","tags":["编程风格","lambda","纯函数"],"categories":"theory","content":"\r\n\r\n> 函数式编程是一种编程范式，区别于面向对象编程和面向过程编程的命令风格，其风格是声明式的，是满足若干要素的构建软件的方式。\r\n\r\n函数式编程由纯函数的组合构成，以避免共享状态、可变数据以及副作用。理解函数式编程的第一步就是要理解什么是纯函数。\r\n\r\n所谓纯函数就是那种对于给定输入总是得出固定输出且不产生任何副作用的函数。纯函数是函数的一种类型，一个函数的目的可以是值映射，一系列步骤的组合或者是同系统中的其他模块通信。纯函数总是和值映射相关，一个参数，一个固定输出。比如Math.max(11,13)无论被调用多少次，什么时候调用，其结果都是13。而且因为该函数不存在将值存盘或者输出到标准输出上的行为，理论上来说，只要Math.max(11,13)出现的地方，都可以用13去代替。即所谓的引用透明性(referential transparency)。Math.random(),System.currentTime()不是纯函数，因为它们不满足一个输入对应一个输出的原则。\r\n\r\n纯函数用副本实现不可变性的。区别于全拷贝，它将数据分成一个个很小的块，只对变化的块进行复制，很象git管理库和提交的方式。基于不可变性，纯函数也不会修改任何外部状态。\r\n\r\n纯函数不修改外部状态避免了共享状态，也意味着不会产生任何副作用。在共享状态下，并发/并行过程 + 可变状态 = 不确定性，一个不确定的系统结果是无法预测的，可能会产生各种奇奇怪怪的bug，纯函数可以帮助我们避免这种bug。\r\n\r\n函数组合就是将两个以上的函数以某种顺序组合成一个函数的过程，一个函数就像是一个管道，我们的数据就在这一系列的管道中流过。基于这种风格，我们可以减少中间变量的使用。\r\n\r\n函数式编程倾向于重用一组通用的函数式实用程序来处理数据。面向对象的编程倾向于将方法和数据放在对象中。那些并置的方法只能对它们设计用于操作的数据类型进行操作，并且通常只能对包含在该特定对象实例中的数据进行操作。在函数式编程中，任何类型的数据都是平等的。相同的 map()实用程序可以映射对象、字符串、数字或任何其他数据类型，因为它将函数作为参数来适当地处理给定的数据类型。函数式编程使用高阶函数实现了它的通用实用技巧。\r\n\r\n更加具体清晰的functional programming说明可以参考Eric Elliott的文章[Master the JavaScript Interview: What is Functional Programming?](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0),以及Russ Olsen的演讲[Functional Programming in 40 Minutes](https://www.youtube.com/watch?v=0if71HOyVjY)。\r\n"}]},{"tag":"纯函数","payload":[{"title":"functional programming","date":"2022-05-05","tags":["编程风格","lambda","纯函数"],"categories":"theory","content":"\r\n\r\n> 函数式编程是一种编程范式，区别于面向对象编程和面向过程编程的命令风格，其风格是声明式的，是满足若干要素的构建软件的方式。\r\n\r\n函数式编程由纯函数的组合构成，以避免共享状态、可变数据以及副作用。理解函数式编程的第一步就是要理解什么是纯函数。\r\n\r\n所谓纯函数就是那种对于给定输入总是得出固定输出且不产生任何副作用的函数。纯函数是函数的一种类型，一个函数的目的可以是值映射，一系列步骤的组合或者是同系统中的其他模块通信。纯函数总是和值映射相关，一个参数，一个固定输出。比如Math.max(11,13)无论被调用多少次，什么时候调用，其结果都是13。而且因为该函数不存在将值存盘或者输出到标准输出上的行为，理论上来说，只要Math.max(11,13)出现的地方，都可以用13去代替。即所谓的引用透明性(referential transparency)。Math.random(),System.currentTime()不是纯函数，因为它们不满足一个输入对应一个输出的原则。\r\n\r\n纯函数用副本实现不可变性的。区别于全拷贝，它将数据分成一个个很小的块，只对变化的块进行复制，很象git管理库和提交的方式。基于不可变性，纯函数也不会修改任何外部状态。\r\n\r\n纯函数不修改外部状态避免了共享状态，也意味着不会产生任何副作用。在共享状态下，并发/并行过程 + 可变状态 = 不确定性，一个不确定的系统结果是无法预测的，可能会产生各种奇奇怪怪的bug，纯函数可以帮助我们避免这种bug。\r\n\r\n函数组合就是将两个以上的函数以某种顺序组合成一个函数的过程，一个函数就像是一个管道，我们的数据就在这一系列的管道中流过。基于这种风格，我们可以减少中间变量的使用。\r\n\r\n函数式编程倾向于重用一组通用的函数式实用程序来处理数据。面向对象的编程倾向于将方法和数据放在对象中。那些并置的方法只能对它们设计用于操作的数据类型进行操作，并且通常只能对包含在该特定对象实例中的数据进行操作。在函数式编程中，任何类型的数据都是平等的。相同的 map()实用程序可以映射对象、字符串、数字或任何其他数据类型，因为它将函数作为参数来适当地处理给定的数据类型。函数式编程使用高阶函数实现了它的通用实用技巧。\r\n\r\n更加具体清晰的functional programming说明可以参考Eric Elliott的文章[Master the JavaScript Interview: What is Functional Programming?](https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0),以及Russ Olsen的演讲[Functional Programming in 40 Minutes](https://www.youtube.com/watch?v=0if71HOyVjY)。\r\n"}]},{"tag":"leetcode","payload":[{"title":"123.买卖股票的最佳时机Ⅲ","date":"2022-05-03","tags":["leetcode"],"categories":"leetcode","content":"\r\n\r\n> 题目描述\r\n\r\n给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你最多可以完成两笔交易。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\r\n\r\n> 例1\r\n\r\n    输入：prices = [3,3,5,0,0,3,1,4]\r\n    输出：6\r\n    解释：在第 4 天（股票价格 = 0）的时候买入，在第 6 天（股票价格 = 3）的时候卖出，这笔交易所能获得利润 = 3-0 = 3 。\r\n    随后，在第 7 天（股票价格 = 1）的时候买入，在第 8 天 （股票价格 = 4）的时候 卖出，这笔交易所能获得利润 = 4-1 = 3 。\r\n> 例2\r\n\r\n    输入：prices = [1,2,3,4,5]\r\n    输出：4\r\n    解释：在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。   \r\n    注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出.因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。\r\n> 例3\r\n\r\n    输入：prices = [7,6,4,3,1] \r\n    输出：0 \r\n    解释：在这个情况下, 没有交易完成, 所以最大利润为 0。\r\n\r\n思路：我们可做的交易数为0，1，2，也就是说最多可以做两笔交易。那么我们可以以第i天为界，计算出[0 - i]最大收益数和[i - n]最大收益数之和，得到的结果就是我们想要的答案。<div align=\"center\"><img src=\"../resources/img/leetcode_123_1.jpg\"></div>\r\n\r\n附上代码\r\n\r\n    //123.买卖股票的最佳时机 III\r\n    public int maxProfit(int[] prices) {\r\n        int ans = 0;\r\n        int len = prices.length;\r\n        //前i + 1天所能得到的最大收益\r\n        int[] beforeProfits = new int[len];\r\n        int min = prices[0],max = prices[0];\r\n        for (int i = 1; i < len; i++) {\r\n            min = Math.min(min,prices[i]);\r\n            max = Math.max(max,prices[i]);\r\n            beforeProfits[i] = Math.max(beforeProfits[i - 1],prices[i] - min);\r\n        }\r\n        min = prices[len - 1];\r\n        max = prices[len - 1];\r\n        //后n - i天所能得到的最大收益\r\n        int[] afterProfits = new int[len];\r\n        for (int i = len - 2; i >= 0; i--) {\r\n            min = Math.min(min,prices[i]);\r\n            max = Math.max(max,prices[i]);\r\n            afterProfits[i] = Math.max(afterProfits[i + 1],max - prices[i]);\r\n        }\r\n        for (int i = 0; i < len; i++) {\r\n            ans = Math.max(ans,beforeProfits[i] + afterProfits[i]);\r\n        }\r\n        return ans;\r\n    }\r\n\r\n"},{"title":"42.接雨水","date":"2022-05-03","tags":["leetcode"],"categories":"leetcode","content":"\r\n\r\n> 题目描述\r\n\r\n给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。\r\n\r\n> 例1\r\n\r\n    输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]\r\n    输出：6\r\n\r\n> 例2\r\n\r\n    输入：height = [4,2,0,3,2,5]\r\n    输出：9\r\n\r\n> 思路\r\n\r\n- 首先找出所有的制高点，所谓制高点就是广义极大值点\r\n- （关键）以每个制高点为左边界，找到其右边界。具体做法是沿着制高点数组向右找第一个大于等于的制高点作为右边界，如果找到头也没找到，则把其中最大的作为右边界\r\n- 从最左制高点开始将其作为左边界，将上一步找到的其右边界作为右边界，找到它们当中的较低点作为水平面值，从此点开始向左或者向右将深度加到结果中去，直到遇到某处的高度大于水平面值为止。之后将右边界作为左边界循环此步，直到边界抵达最右制高点。\r\n\r\n> 附上代码\r\n\r\n    public int trap(int[] height) {\r\n        int ans = 0;\r\n        int len = height.length;\r\n        if(len == 1){\r\n            return ans;\r\n        }\r\n        //制高点list\r\n        List<Integer> list = new ArrayList<>();\r\n        //将所有制高点的数组下标按顺序放入list中\r\n        if(height[0] >= height[1]){\r\n            list.add(0);\r\n        }\r\n        for (int i = 1; i < len - 1; i++) {\r\n            if(height[i] >= height[i - 1] && height[i] >= height[i + 1]){\r\n                list.add(i);\r\n            }\r\n        }\r\n        if(height[len - 1] >= height[len - 2]){\r\n            list.add(len - 1);\r\n        }\r\n        int size = list.size();\r\n        //所有制高点的右边界的list下标\r\n        int[] rightFirstHigher = new int[size];\r\n        rightFirstHigher[size - 1] = size;\r\n        //关键步骤，从右向左找到所有制高点的右边界的list下标\r\n        for (int i = size - 2; i >= 0; i--) {\r\n            //next期望找到第一个大于等于当前制高点的下标，nextI为未找到next前小于当前制高点的最高点的下标\r\n            int h = height[list.get(i)],next = i + 1,nextI = i + 1;\r\n            while (next < size && height[list.get(next)] < h){\r\n                if(height[list.get(next)] > height[list.get(nextI)]){\r\n                    nextI = next;\r\n                }\r\n                next = rightFirstHigher[next];\r\n            }\r\n            //没找到，右边界为nextI，否则为next\r\n            rightFirstHigher[i] = next == size ? nextI : next;\r\n        }\r\n        //统计各区间的水量\r\n        for (int i = 0; i < size - 1; i=rightFirstHigher[i]) {\r\n            int left = list.get(i),right = list.get(rightFirstHigher[i]);\r\n            int min = Math.min(height[left],height[right]);\r\n            if(height[left] < height[right]){\r\n                for (int j = left + 1; j < right; j++) {\r\n                    //保证不大于水平面高度\r\n                    if(height[j] > min){\r\n                        break;\r\n                    }\r\n                    ans += min - height[j];\r\n                }\r\n            }else {\r\n                for (int j = right - 1; j > left; j--) {\r\n                    if(height[j] > min){\r\n                        break;\r\n                    }\r\n                    ans += min - height[j];\r\n                }\r\n            }\r\n        }\r\n        return ans;\r\n    }\r\n\r\n时空间复杂度感人:joy:\r\n"}]},{"tag":"设计思想","payload":[{"title":"DDD领域驱动设计","categories":"软技能","tags":["设计思想"],"date":"2023-04-05","content":"\n\n领域驱动设计，一个理解是领域模型驱动设计模型。领域模型表达的是与业务相关的事实，设计模型描述的是所要构建的系统。\n\n\nquestion：DDD是否与scrum冲突？\n\n\n按照美团技术团队的理解，他们将解决复杂和大规模软件的武器大致分为了三类：抽象、分治和知识。\n\n- 分治：把问题空间分割为规模更小且易于处理的若干子问题。分割后的问题需要足够小，以便一个人单枪匹马就能够解决他们；其次，必须考虑如何将分割后的各个部分分装配为整体。分割得越合理越易于理解，在装配成整体时，所需跟踪的细节也就越少。即更容易设计各部分的协作方式。评判什么是分治得好，即高内聚低耦合。\n- 抽象：使用抽象能够精简问题空间，而且问题越小越容易理解。\n- 知识：DDD可以认为是知识的一种。DDD提供知识手段，让我们知道如何抽象出限界上下文以及如何去分治。\n\n领域驱动设计与微服务架构是天然耦合的。架构设计活动可以被精简为三个层面：\n\n- 业务架构-根据业务需求设计业务模块及其关系\n- 系统架构-设计系统和子系统的模块\n- 技术架构-决定采用的技术及其框架\n\nDDD的核心诉求就是讲业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。而微服务追求业务层面的复用，设计出来的系统架构和业务一致；在技术架构上则系统模块之间充分耦合，可以自由地选择合适的技术架构，去中心化地治理技术和数据。\n\n\n美团技术团队的领域模型设计一般实践分为5个步骤：\n\n1. 根据需求划分出初步的领域和限界上下文，以及上下文之间的关系；\n2. 进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象；\n3. 对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根；\n4. 为聚合根设计仓储，并思考实体和值对象的创建方式；\n5. 在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。\n\n领域\n\n\n现实世界中，领域包含问题域和解系统。在DDD中，解系统可以映射为一个个限界上下文，限界上下文就是软件对于问题域的一个特定的、有限的解决方案。\n\n\n一个给定的业务领域会包含多个限界上下文，想与一个限界上下文沟通，则需要通过显示边界进行通信。系统通过确定的限界上下文来进行解耦，而每一个上下文内部紧密组织，职责明确，具有较高的内聚性。\n\n\n一个很形象的隐喻：细胞质所以能够存在，是因为细胞膜限定了什么在细胞内，什么在细胞外，并且确定了什么物质可以通过细胞膜。\n\n\n如何划分限界上下文\n\n\n在美团技术团队的实践中，具体做法是考虑产品所讲的通用语言，从中提取一些术语称之为概念对象，寻找对象之间的联系；或者从需求中提取一些动词，观察动词之间的关系；将紧耦合的各自圈在一起，观察他们内在的联系，从而形成对应的限界上下文。形成之后，尝试用语言来描述限界上下文的职责，看它是否清晰、准确、简洁和完整。简言之，限界上下文应该从需求出发，按领域划分。\n\n\n上下文映射图\n\n\n在进行上下文划分之后，下一步要做的就是梳理上下文之间的关系。\n\n\n> 康威定律\n\n\n任何组织在设计一套系统时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。\n\n\n所以团队结构应该和限界上下文保持一致。\n\n\n> 限界上下文之间的映射关系\n\n- 合作关系：两个上下文紧密合作的关系，一荣俱荣，一损俱损\n- 共享内核：两个上下文依赖部分共享的模型\n- 客户方-供应方开发：上下文之间有组织的上下游依赖\n- 遵奉者：下游上下文只能盲目依赖上游上下文\n- 防腐层：一个上下文通过一些适配和转换与另一个上下文交互\n- 开放主机服务：定义一种协议来让其他上下文对本上下文进行访问\n- 发布语言：通常和OHS一起使用，用于定义开放主机协议\n- 大泥路：混杂在一起的上下文关系，边界不清晰\n- 另谋他路：两个完全没有任何联系的上下文\n\n战术建模—细分上下文\n\n\n> 实体\n\n\n当一个对象由其标识(而不是属性)区分时，这种对象称为实体。比如公安系统的身份信息录入，每个人都是独一无二的，且具有唯一标识的，可以被认为是实体。\n\n\n> 值对象\n\n\n当一个对象用于对事务进行描述而没有唯一标识时，它被称作值对象。\n\n\n> 聚合根\n\n\n聚合是一组相关对象的集合，作为一个整体被外界访问，聚合根是这个聚合的根节点。聚合由根实体，值对象和实体组成。\n\n\n> 领域服务\n\n\n一些重要的领域行为或操作，可以归类为领域服务。它既不是实体，也不是值对象的范畴。\n\n\n> 领域事件\n\n\n领域事件是对领域内发生的活动进行的建模。\n\n"}]},{"tag":"http","payload":[{"title":"http协议","categories":"网络","tags":["http","网络"],"date":"2023-04-13","content":"\n\n参考：\n\n\n[https://www.shouxicto.com/article/4093.html](https://www.shouxicto.com/article/4093.html)\n\n\n### HTTP/1.1\n\n- 长连接\n\nHTTP/1.0中，默认使用的是短连接，就是每次请求都要重新建立一次连接。HTTP/1.1默认使用长连接Connection : keep-alive。\n\n- 管道\n\npipeline指客户端拥有连续发送请求的能力，但是客户端没有分辨响应的能力，即存在响应队头阻塞的问题。\n\n\n### HTTP/2\n\n\n相比较HTTP/1.1,HTTP/2做了如下改进\n\n- 二进制分帧层(核心)\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d8dd31b1-bcf7-4d65-85e7-e0ce09894cb5/HTTP2.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=8f00999b3cec5679ac91f3986a9840d3bc1cc1b8b854165c61e2180542984a17&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n二进制分帧层是指位于套接字接口和应用可见的高级HTTP API之间一个经过优化的新编码机制。在二进制分帧层上，HTTP/2.0会将所有传输信息分割为更小的消息和帧，并对它们采用二进制格式的编码，其中HTTP/1.x的首部信息会被封装到Headers帧，request body则封装到Data帧中。\n\n- 头部压缩\n\n每个HTTP传输都承载一组标头来说明传输的资源及其属性。在HTTP/1.x中，此元数据始终以纯文本的形式传输，通常高达500-800字节，如果使用HTTP Cookie，有事会达到上千字节。\n\n\nHTTP/2使用HPACK压缩格式压缩请求和响应标头元数据，这种格式由两种技术支持：\n\n1. 使用静态霍夫曼代码对传输的标头字段进行编码，从而缩小各个传输的大小。\n2. 客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表，即建立一个共享的压缩上下文，此表随后会用作参考，对之前传输的值进行有效编码。\n\nHTTP/2.0在客户端和服务端使用“首部表”跟踪和储存之前发送的键值对，对于相同的数据，不再通过每次请求和响应发送;通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型,等等)只需发送一次。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/08d37a32-fd07-4378-ada5-13e95f915cd9/HTTP2%E9%A6%96%E9%83%A8%E8%A1%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=c8558b68e929372351da213a574caebfb0cf92a1154bd3343ed7df0ecd95b207&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 多路复用\n\n在HTTP/1.x中数据是基于文本的有序传输，不能并行传输并且接收端又不知道数据包的顺序。HTTP/2中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将HTTP消息分解为互不依赖的帧，然后交错发送，在另一端再将其组装起来。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/280a438c-7404-4601-8c4d-d9fa8598ceb7/HTTP2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=71da3ab359f59857bfef9171ee99cc22befe35fbe837bc343abdb15222c774ad&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 服务器推送\n\nHTTP/2可以对一个请求发送多个响应，即除了最初请求的响应外，服务器还可以向客户端推送额外资源，而无需客户端明确地请求。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/20b147a9-3bb2-4f50-adc8-05a9038989b8/HTTP2%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=dfa0e1f0276e29ef519e8e8fc918f36883c90d00aa6b55bd510eefda6de4f95e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n### HTTP/2的缺点\n\n\nHTTP2的缺点一是建立连接的时间长，二是队头阻塞的问题依旧存在。而HTTP2的这两个缺点，都是因为HTTP2是基于TCP的应用层协议，tcp的三次握手消耗1.5RTT，加上TLS加密握手，则需要消耗3RTT，HTTP2虽然解决了http消息队头阻塞问题，但是并没有解决TCP队头阻塞问题。HTTP2废弃了管道化的方式，而引入帧、消息和数据流的概念，客户端和服务端可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来，解决了HTTP1.1队头阻塞的问题（一个响应返回发生延迟，其后续的响应都会被延迟，直到队头的响应送达）。TCP传输中会将数据拆分成一个一个小的有序的数据包，如果其中一个数据包没有按序到达，接收端就会保持连接等待数据包返回，这是就会阻塞后续的请求，造成TCP队头阻塞。\n\n\nHTTP/1.1 管道化持久连接也是使得同一个TCP连接可以被多个HTTP使用，但是HTTP/1.1中规定一个域名可以有6个TCP连接，而HTTP/2中，同一个域名只使用一个TCP连接，一旦HTTP/2中TCP队头阻塞所造成的影响会更大，因为HTTP/2的多路复用技术使得多个请求其实是基于同一个TCP连接的，如果某一个请求造成了TCP队头阻塞，那么多个请求都会受到影响。\n\n\n### HTTP/3\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/83871cf5-cec0-4f54-b13e-37d46815f9e0/HTTP3.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=e1120e9737dd47ae49ffe6a112b6f5ea6d3487dc3c03541826487d0a3316f10a&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 实现了类似 TCP 的流量控制、传输可靠性的功能。虽然 UDP 不提供可靠性的传输，但 QUIC 在 UDP 的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些 TCP 中存在的特性。\n- 集成了 TLS 加密功能。目前 QUIC 使用的是 TLS1.3，相较于早期版本 TLS1.3 有更多的优点，其中最重要的一点是减少了握手所花费的 RTT 个数。\n- 实现了 HTTP/2 中的多路复用功能。和 TCP 不同，QUIC 实现了在同一物理连接上可以有多个独立的逻辑数据流。实现了数据流的单独传输，就解决了 TCP 中队头阻塞的问题。\n"}]},{"tag":"网络","payload":[{"title":"http协议","categories":"网络","tags":["http","网络"],"date":"2023-04-13","content":"\n\n参考：\n\n\n[https://www.shouxicto.com/article/4093.html](https://www.shouxicto.com/article/4093.html)\n\n\n### HTTP/1.1\n\n- 长连接\n\nHTTP/1.0中，默认使用的是短连接，就是每次请求都要重新建立一次连接。HTTP/1.1默认使用长连接Connection : keep-alive。\n\n- 管道\n\npipeline指客户端拥有连续发送请求的能力，但是客户端没有分辨响应的能力，即存在响应队头阻塞的问题。\n\n\n### HTTP/2\n\n\n相比较HTTP/1.1,HTTP/2做了如下改进\n\n- 二进制分帧层(核心)\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d8dd31b1-bcf7-4d65-85e7-e0ce09894cb5/HTTP2.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=8f00999b3cec5679ac91f3986a9840d3bc1cc1b8b854165c61e2180542984a17&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n二进制分帧层是指位于套接字接口和应用可见的高级HTTP API之间一个经过优化的新编码机制。在二进制分帧层上，HTTP/2.0会将所有传输信息分割为更小的消息和帧，并对它们采用二进制格式的编码，其中HTTP/1.x的首部信息会被封装到Headers帧，request body则封装到Data帧中。\n\n- 头部压缩\n\n每个HTTP传输都承载一组标头来说明传输的资源及其属性。在HTTP/1.x中，此元数据始终以纯文本的形式传输，通常高达500-800字节，如果使用HTTP Cookie，有事会达到上千字节。\n\n\nHTTP/2使用HPACK压缩格式压缩请求和响应标头元数据，这种格式由两种技术支持：\n\n1. 使用静态霍夫曼代码对传输的标头字段进行编码，从而缩小各个传输的大小。\n2. 客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表，即建立一个共享的压缩上下文，此表随后会用作参考，对之前传输的值进行有效编码。\n\nHTTP/2.0在客户端和服务端使用“首部表”跟踪和储存之前发送的键值对，对于相同的数据，不再通过每次请求和响应发送;通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型,等等)只需发送一次。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/08d37a32-fd07-4378-ada5-13e95f915cd9/HTTP2%E9%A6%96%E9%83%A8%E8%A1%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=c8558b68e929372351da213a574caebfb0cf92a1154bd3343ed7df0ecd95b207&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 多路复用\n\n在HTTP/1.x中数据是基于文本的有序传输，不能并行传输并且接收端又不知道数据包的顺序。HTTP/2中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将HTTP消息分解为互不依赖的帧，然后交错发送，在另一端再将其组装起来。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/280a438c-7404-4601-8c4d-d9fa8598ceb7/HTTP2%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=71da3ab359f59857bfef9171ee99cc22befe35fbe837bc343abdb15222c774ad&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 服务器推送\n\nHTTP/2可以对一个请求发送多个响应，即除了最初请求的响应外，服务器还可以向客户端推送额外资源，而无需客户端明确地请求。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/20b147a9-3bb2-4f50-adc8-05a9038989b8/HTTP2%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A8%E9%80%81.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=dfa0e1f0276e29ef519e8e8fc918f36883c90d00aa6b55bd510eefda6de4f95e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n### HTTP/2的缺点\n\n\nHTTP2的缺点一是建立连接的时间长，二是队头阻塞的问题依旧存在。而HTTP2的这两个缺点，都是因为HTTP2是基于TCP的应用层协议，tcp的三次握手消耗1.5RTT，加上TLS加密握手，则需要消耗3RTT，HTTP2虽然解决了http消息队头阻塞问题，但是并没有解决TCP队头阻塞问题。HTTP2废弃了管道化的方式，而引入帧、消息和数据流的概念，客户端和服务端可以把HTTP消息分解为互不依赖的帧，然后乱序发送，最后再在另一端把它们重新组合起来，解决了HTTP1.1队头阻塞的问题（一个响应返回发生延迟，其后续的响应都会被延迟，直到队头的响应送达）。TCP传输中会将数据拆分成一个一个小的有序的数据包，如果其中一个数据包没有按序到达，接收端就会保持连接等待数据包返回，这是就会阻塞后续的请求，造成TCP队头阻塞。\n\n\nHTTP/1.1 管道化持久连接也是使得同一个TCP连接可以被多个HTTP使用，但是HTTP/1.1中规定一个域名可以有6个TCP连接，而HTTP/2中，同一个域名只使用一个TCP连接，一旦HTTP/2中TCP队头阻塞所造成的影响会更大，因为HTTP/2的多路复用技术使得多个请求其实是基于同一个TCP连接的，如果某一个请求造成了TCP队头阻塞，那么多个请求都会受到影响。\n\n\n### HTTP/3\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/83871cf5-cec0-4f54-b13e-37d46815f9e0/HTTP3.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085125Z&X-Amz-Expires=3600&X-Amz-Signature=e1120e9737dd47ae49ffe6a112b6f5ea6d3487dc3c03541826487d0a3316f10a&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n- 实现了类似 TCP 的流量控制、传输可靠性的功能。虽然 UDP 不提供可靠性的传输，但 QUIC 在 UDP 的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些 TCP 中存在的特性。\n- 集成了 TLS 加密功能。目前 QUIC 使用的是 TLS1.3，相较于早期版本 TLS1.3 有更多的优点，其中最重要的一点是减少了握手所花费的 RTT 个数。\n- 实现了 HTTP/2 中的多路复用功能。和 TCP 不同，QUIC 实现了在同一物理连接上可以有多个独立的逻辑数据流。实现了数据流的单独传输，就解决了 TCP 中队头阻塞的问题。\n"}]},{"tag":"nginx","payload":[{"title":"Nginx必知必会","categories":"nginx","tags":["nginx","运维","devops"],"date":"2022-11-16","content":"\n\n[在centos下安装Nginx](b43b9a0b-0311-412a-a38d-0720a9a8df76)\n\n1. 在/etc/yum.repo.d下新建文件nginx.repo定义Nginx软件仓库细节\n\n\t```shell\n\t[nginx]\n\tname=nginx repo\n\t#OS example centos,OSRELEASE example 7.x\n\tbaseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/\n\tgpgcheck=0\n\tenabled=1\n\t```\n\n2. 执行nginx下载，配置nginx自启动，配置防火墙\n\n\t```shell\n\tyum -y install nginx\n\tsystemctl enable nginx\n\tsystemctl start nginx\n\tfirewalld-cmd --permanent --zone=public --add-port=80/tcp\n\tfirewall-cmd --reload\n\t```\n\n\n[nginx关键文件，文件夹以及命令](7de1a27a-f767-40b5-83e3-4605e4d1eafe)\n\n- 文件(夹)\n\n| /etc/nginx/               | nginx配置文件默认的文件夹根地址                                        |\n| - |  |\n| /etc/nginx/nginx.conf     | nginx默认的配置文件入口，设置了工作进程，管道，日志，加载动态模块的配置。该文件中还包含指向其他配置文件的引用 |\n| /etc/nginx/conf.d/        | 该文件夹下包含默认的HTTP服务配置文件                                      |\n| /etc/nginx/stream.conf.d/ | 该文件夹下包含stream配置文件                                         |\n| /var/log/nginx/           | 默认的日志文件夹，包含access.log和error.log                           |\n\n- 命令\n\n| nginx -h        | nginx help菜单                                         |\n|  | - |\n| nginx -v        | 版本                                                   |\n| nginx -V        | 版本，构建信息，配置参数                                         |\n| nginx -t        | 测试nginx配置                                            |\n| nginx -T        | 测试nginx配置并且打印有效配置                                    |\n| nginx -s signal | 给nginx主进程发送命令，signal example：stop quit reload reopen |\n\n\n[优雅地重启nginx](7a802821-4a1c-47be-845e-1d280bd19658)\n\n\nnginx -s reload\n\n\n[nginx负载均衡](802bf27b-a1b2-4df0-b30a-405c9d425ff8)\n\n- HTTP负载均衡\n\n\t```shell\n\tupstream backend {#upstream模块控制nginx的负载均衡\n\t\n\t\t#在两个HTTP server间做负载均衡，weight越大权重越大\n\t\tserver 10.10.12.45:80 weight=1;\n\t\tserver app.example.com:80 weight=2;\n\t\n\t\t#一个后备，当上面两个服务挂掉时启用\n\t\tserver spare.example.com:80 backup;\n\t}\n\tserver {\n\t\tlocation / {\n\t\t\tproxy_pass http://backend;\n\t\t}\n\t}\n\t```\n\n- TCP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream mysql_read {\n\t\t\tserver read1.example.com:3306 weight=5;\n\t\t\tserver read2.example.com:3306;\n\t\t\tserver 10.10.12.34:3306 backup;\n\t\t}\n\t\tserver {\n\t\t\tlisten 3306;\n\t\t\tproxy_pass mysql_read;\n\t\t}\n\t}\n\t```\n\n\n\t这个配置不会被放在conf.d文件夹下，应当创建一个stream.conf.d文件夹，在nginx.conf中加入以下配置。\n\n\n\t```shell\n\tstream{\n\t\t\tinclude /etc/nginx/stream.conf.d/*.conf;\n\t}\n\t```\n\n- UDP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream ntp {\n\t\t\tserver ntp1.example.com:123 weight=2;\n\t\t\tserver ntp2.example.com:123;\n\t\t}\n\t\tserver {\n\t\t\tlisten 123 udp;\n\t\t\tproxy_pass ntp;\n\t\t}\n\t}\n\t```\n\n\nnginx默认采用的是Round-robin轮询调度算法，nginx支持多种负载均衡方法如：最少连接，最少耗时，一致性hash，IP hash，随机调度等。可以在upstream block中进行配置：\n\n\n```shell\nupstream backend {\n\tleast_conn;\n\tserver backend.example.com;\n\tserver backend1.example.com;\n}\n```\n\n\n| Round robin       | 默认方式，按顺序分配请求给服务集群。可以通过配置weight使其成为weighted round robin                                                             |\n| -- |  |\n| Least connections | 将请求分配给打开连接数最少的服务器，可以通过weight给每个服务器设置权重                                                                             |\n| Least time        | 只在nginx plus中可用                                                                                                    |\n| Generic hash      | [https://zh.m.wikipedia.org/zh-hans/一致哈希](https://zh.m.wikipedia.org/zh-hans/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C) |\n| Random            | 随机算法，考虑weight                                                                                                      |\n| IP hash           | IP地址作为hash参数，考虑weight                                                                                              |\n\n\n[nginx流量管理](daebaa2d-2f3c-4d3c-a6e4-dc0b0bb49bae)\n\n\n### A/B Testing\n\n\n将客户端导流到不同的应用版本\n\n\n```shell\nsplit_clients \"${remote_addr}AAA\" $variant {\n\t\t20.0% \"backendv2\";\n\t\t* \"backendv1\";\n}\n```\n\n\n### GeoIP Module\n\n- 下载nginx GeoIP模块包\n\n```shell\n#下载nginx-module-geoip\nyum install nginx-module-geoip\nmkdir /etc/nginx/geoip\ncd /etc/nginx/geoip\nwget \"http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz\"\ngunzip GeoIP.dat.gz\nwget \"http://geolite.maxmind.com/\\download/geoip/database/GeoLiteCity.dat.gz\"\ngunzip GeoLiteCity.dat.gz\n```\n\n- 然后在配置文件中进行配置\n\n```shell\n#load_module指令只在主context中有效\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n#geoip_country,geoip_city只在http context中有效\nhttp {\n\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n}\n```\n\n\n有了这个module就可以将地理信息传递给后端的应用，或者借助它来进行流量路由，例如可以基于国别进行控制\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\t#来自美国的IP，变量country_access被置为0，其他被置为1\n\t\tmap $geoip_country_code $country_access{\n\t\t\t\t\"US\" 0;\n\t\t\t\tdefault 1;\n\t\t}\n\t\t#在server block中进行配置\n\t\tserver{\n\t\t\t\t#非美国的IP禁止访问\n\t\t\t\tif($country_access = '1'){\n\t\t\t\t\t\treturn 403;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n如果客户端在nginx之前途经其他的代理，可以配置找到其原始IP\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\t\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n\n\t\t#CIDR 指示nginx利用X-Forwarded-For头去查询客户端地址\n\t\tgeoip_proxy 10.0.16.0/26;\n\n\t\t#递归查找\n\t\tgeoip_proxy_recursive on;\n}\n```\n\n\n### 按照一定的规则限制连接数，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\tlimit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;\n\t\tlimit_conn_status 429;\n\t\tserver{\n\t\t\t\tlimit_conn limitbyaddr 40;\n\t\t}\n}\nlimit_conn_status和limit_conn指令在http、server、location context中有效\nlimit_conn_zone则只在http context中有效\n```\n\n\n预定义的key即规则要按照实际情况进行设置。比如请求来自NAT网络，那么根据IP地址限制连接数就是不合理的。limit_conn_zone后的字符串可以是任意数量的nginx可用变量，可以在应用层的级别去识别一个用户，比如说通过session cookie。默认的http状态码是503，但是其实服务是可用的，只是被限制了访问，所以429是更好的选择来暗示是客户端的问题\n\n\n### 按照一定的规则限制流量，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\t#速率被限制为3r/s，可以以秒或者分钟的粒度进行限流\n\t\tlimit_req_zone $binary_remote_addr zone=limitbyaddr:10m rate=3r/s;\n\t\tlimit_req_status 429;\n\t\tserver{\n\t\t\t\tlimit_req zone=limitbyaddr;\n\t\t\t\tlocation / {\n\t\t\t\t\t\t#二阶段限速，burst允许速率提升到其值而不拒绝请求\n\t\t\t\t\t\t#第二个参数有delay和nodelay选项\n\t\t\t\t\t\t#nodelay选项会立即消费brust的请求\n\t\t\t\t\t\t#但是在floor(brust/rate)时间后才会继续接受来自该客户端的请求\n\t\t\t\t\t\t#delay选项则会先消费delay数的请求，之后的延迟消费\n\t\t\t\t\t\tlimit_req zone=limitbyaddr burst=12 delay=9;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n_超出限制的访问请求会被记录到error.log中。_\n\n\n### 限制带宽\n\n\n通过配置限制每个客户端的下载带宽\n\n\n```shell\nlocation /download/ {\n\t\t#在下载10m的资源后会被限速1m/s\n\t\tlimit_rate_after 10m;\n\t\tlimit_rate 1m;\n}\n```\n\n\n[nginx内容缓存](f3dcfc09-4c20-426c-895e-f313c1003d64)\n\n\n[nginx动态配置的能力](0afd3e8d-3820-4ea7-8716-1ef02dd5a14c)\n\n\n[nginx认证](180d99e4-2155-4b93-ad35-0b3439dcb6df)\n\n\n### HTTP Basic认证\n\n\n生成一个包含用户名和密码的文件\n\n\n```shell\n#comment\n#password可以是加密或者hash后的字符串，加密使用C函数crypt()\n#具体操作方式是下载OpenSSL，执行openssl passwd password\n#password可以通过多种方式进行混淆，但是通常是不安全的，因为可以进行暴力破解\nname1:password1\nname2:password2:comment\nname3:password3\n```\n\n\n在配置文件中配置指令使得认证生效\n\n\n```shell\nlocation / {\n\t\t#未认证通过的请求显示Private site\n\t\tauth_basic \"Private site\";\n\t\tauth_basic_user_file conf.d/passwd;\n}\nauth_basic可以在http、server、location中进行配置\n```\n\n\n### 认证子请求，即对请求进行授权认证\n\n\n可以使用http_auth_request_module在将实际请求转发给相应服务前先由认证服务进行身份鉴别\n\n\n```shell\nlocation /private/ {\n\t\tauth_request /auth;\n\t\t#从auth服务中带出的一些变量\n\t\tauth_request_set $auth_status $upstream_status;\n}\n\nlocation = /auth {\n\t\tinternal;\n\t\tproxy_pass http://auth-server;\n\t\t#不需要body的场景\n\t\tproxy_pass_request_body off;\n\t\tproxy_set_header Content-Length \"\";\n\t\tproxy_set_header X-Original_URI $request_uri;\n}\n```\n\n\n[nginx安全控制](85eaab33-5d9d-4895-950c-cb71775c9c46)\n\n\n### 基于IP地址的访问控制\n\n\n```shell\nlocation /admin/ {\n\t\t#允许10.0.0.0/20域下除了10.0.0.1的访问\n\t\tdeny 10.0.0.1;\n\t\tallow 10.0.0.0/20;\n\t\t#允许2001:0db8::/32子网下所有IPV6地址的访问\n\t\tallow 2001:0db8::/32;\n\t\t#拒绝其他IP的请求\n\t\tdeny all;\n}\n\nallow、deny指令在http，server，location以及基于TCP/UDP的stream，server context中都是有效的\n```\n\n\n### 允许跨域资源共享(CORS)\n\n\n```shell\n#http 方法映射\nmap $request_method $cors_method {\n\t\tOPTIONS 11;\n\t\tGET 1;\n\t\tPOST 1;\n\t\tdefault 0;\n}\nserver {\n\t\tlocation / {\n\t\t\t\tif($cors_method ~ '1'){\n\t\t\t\t\t\t#允许跨域的方法\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\n\t\t\t\t\t\t#允许跨域的域名规则\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Origin' '*.example.com';\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Headers' \n\t\t\t\t\t\t\t'DNT,Keep-Alive,User-Agent,X-Request-With,\n\t\t\t\t\t\t\tIf-Modified-Since,Cache-Control,Content-Type';\n\t\t\t\t}\n\t\t\t\t#OPTION方法发送预检请求，获取服务的CORS规则\n\t\t\t\tif($cors_method = '11'){\n\t\t\t\t\t\t#在客户端缓存20天\n\t\t\t\t\t\tadd_header 'Access-Control-Max-Age' 1728000;\n\t\t\t\t\t\t#请求体为空\n\t\t\t\t\t\tadd_header 'Content-Type' 'text/plain; charset=UTF-8';\n\t\t\t\t\t\tadd_header 'Content-Length' 0;\n\t\t\t\t\t\treturn 204;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n### 客户端侧的加密\n\n\n```shell\n#利用一个SSL module对流量进行加密，比如ngx_http_ssl_module或者ngx_stream_ssl_module\n\nhttp { # All directives used below are also valid in stream\n\t\tserver {\n\t\t\t\t#设置一个SSL/TLS服务侦听在8443端口\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#服务证书，即发给客户端的公钥\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#用于加解密的密钥，实际上是服务端用的私钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.key;\n\t\t}\n}\n```\n\n\n### 加强客户端侧加密\n\n\n证书和证书秘钥既可以通过文件路径的方式进行配置，也可以通过变量参数的方式进行配置，客户端所能提供的最强等级标准和服务器所能接受的标准将是最终协议的结果。\n\n\n```shell\nhttp { #所有的指令在stream中也可以使用\n\t\tserver {\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#允许的ssl协议以及cipher\n\t\t\t\tssl_protocols TLSv1.2 TLSv1.3;\n\t\t\t\t#密码被设置为最高标准，拒绝aNULL,MD5\n\t\t\t\tssl_ciphers HIGH:!aNULL:!MD5;\n\t\t\t\t\n\t\t\t\t#RSA证书文件\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#RSA秘钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.pem;\n\n\t\t\t\t#变量中设置的证书使用椭圆曲线数字签名算法（ECC）\n\t\t\t\tssl_certificate $ecdsa_cert;\n\t\t\t\t#变量中设置的ECC形式的秘钥\n\t\t\t\tssl_certificate_key data:$ecdsa_key_path;\n\t\t\t\t\n\t\t\t\t#允许nginx缓存协议10分钟，内存配置为10m\n\t\t\t\tssl_session_cache shared:SSL:10m;\n\t\t\t\tssl_session_timeout 10m;\n\t\t}\n}\n\n#在相同强度下，ECC比RSA快\n```\n\n\n### 上游加密\n\n\n对nginx和上游服务之间的流量进行加密并且进行特定协议协商\n\n\n```shell\nlocation / {\n\t\tproxy_pass https://upstream.example.com;\n\t\tproxy_ssl_verify on;\n\t\t#确保nginx验证上游服务的证书有效深度最多为2\n\t\tproxy_ssl_verify_depth 2;\n\t\t#只接受TLSv1.2，默认所有版本\n\t\tproxy_ssl_protocols TLSv1.2;\n}\n```\n\n\n### 保护一个location block\n\n\n```shell\nlocation /resources {\n\t\t#安全秘钥\n\t\tsecure_link_secret mySecret;\n\t\tif($secure_link = \"\") {\n\t\t\t\treturn 403;\n\t\t}\n\t\trewrite ^ /secured/$secure_link;\n}\nlocation /secured/ {\n\t\tinternal;\n\t\troot /var/www;\n}\n```\n\n\n👆配置了一个内部block和一个公开block。如果请求的URI中包含一个md5 hash字符串并且能够被secure_link_secret指令提供的秘钥认证，则请求地址会被重写，并且交给内部block处理，否则请求会被拒绝，收到403的回复。\n\n\n### 使用秘钥生成一个安全链接\n\n\n上个单元中的合法URI长什么样子呢，举个例子，我们访问域名为www.example.com的服务器上的/var/www/secured/index.html资源，那么就需要根据index.html这个资源生成md5的十六进制编码，具体操作如下：\n\n\n```shell\necho -n 'index.htmlmySecret' | openssl md5 -hex\n(stdin)= a53bee08a4bf0bbea978ddf736363a12\n```\n\n\n然后这个生成的md5十六进制摘要会被拼接到URI中\n\n\n```shell\nwww.example.com/resources/a53bee08a4bf0bbea978ddf736363a12/index.html\n```\n\n\n这就是一个合法的URI。\n\n\n### 使用一个过期日期保护一个location block\n\n\n只有合法且在有效期内的链接才能够访问资源\n\n\n```shell\nlocation /resources {\n\t\troot /var/www;\n\t\t#第一个参数持有md5 hash，第二个参数是Unix epoch格式的link过期时间\n\t\t#arg_md5是一个http参数\n\t\tsecure_link $arg_md5,$arg_expires;\n\t\t#用于生成md5编码的字符串格式\n\t\tsecure_link_md5 \"$secure_link_expires$uri$remote_addrmySecret\";\n\t\t#如果是个无效的URI\n\t\tif($secure_link = \"\"){return 403;}\n\t\t#如果是个有效的URI但是已经过期了\n\t\tif($secure_link = \"0\"){return 410;}\n}\n```\n\n\n### 生成一个带过期时间的链接\n\n\n在unix系统中生成unix时间戳可以使用date指令\n\n\n```shell\n$ date -d \"2030-12-31 00:00\" +%s --utc\n1924905600\n```\n\n\n接下来要做的就是将在secure_link_md5指令中配置的字符串参数进行拼接，再上一个单元中拼接成的字符串则为1924905600/resources/index.html127.0.0.1 mySecret .在这里的MD5 hash同16进制摘要的MD5 hash有一些不同，它是二进制格式的，并且是将+转换为-，/转换为_，去掉=的base64编码。在unix系统中的一个例子如下：\n\n\n```shell\n$ echo -n '1924905600/resources/index.html127.0.0.1 mySecret' \\\n\t| openssl md5 -binary \\\n\t| openssl base64 \\\n\t| tr +/ -_ \\\n\t| tr -d =\nsqysOw5kMvQBL3j9ODCyoQ\n```\n\n\n现在可以在URI中拼接生成的MD5参数\n\n\n```shell\n/resources/index.html?md5=sqysOw5kMvQBL3j9ODCyoQ&expires=1924905600 \n```\n\n\n### 将一个http请求重定向为一个https请求\n\n\n```shell\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\treturn 301 https://$host$request_url;\n}\nor\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\t#只有在http_x_forwarded_proto请求头为http时，才重定向\n\t\tif($http_x_forwarded_proto = 'http'){\n\t\t\t\treturn 301 https://$host$request_url;\n\t\t}\n}\n```\n\n\n### HTTP严格传输安全（HSTS）\n\n\n通过设置Strict-Transport-Security请求头让浏览器总是进行重定向将HTTP请求转换为HTTPS请求\n\n\n```shell\n#max-age=1 year\nadd_header Strict-Transport-Security max-age=31536000;\n```\n\n\n### 满足任意数量的保障安全方式\n\n\n```shell\nlocation / {\n\t\t#参数any or all\n\t\tsatisfy any;\n\t\t\n\t\t#允许192.168.1.0/24网络访问\n\t\tallow 192.168.1.0/24;\n\t\tdeny all;\n\t\t\n\t\t#basic认证访问\n\t\tauth_basic \"closed site\";\n\t\tauth_basic_user_file conf/htpasswd;\n}\n```\n\n"}]},{"tag":"运维","payload":[{"title":"Nginx必知必会","categories":"nginx","tags":["nginx","运维","devops"],"date":"2022-11-16","content":"\n\n[在centos下安装Nginx](b43b9a0b-0311-412a-a38d-0720a9a8df76)\n\n1. 在/etc/yum.repo.d下新建文件nginx.repo定义Nginx软件仓库细节\n\n\t```shell\n\t[nginx]\n\tname=nginx repo\n\t#OS example centos,OSRELEASE example 7.x\n\tbaseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/\n\tgpgcheck=0\n\tenabled=1\n\t```\n\n2. 执行nginx下载，配置nginx自启动，配置防火墙\n\n\t```shell\n\tyum -y install nginx\n\tsystemctl enable nginx\n\tsystemctl start nginx\n\tfirewalld-cmd --permanent --zone=public --add-port=80/tcp\n\tfirewall-cmd --reload\n\t```\n\n\n[nginx关键文件，文件夹以及命令](7de1a27a-f767-40b5-83e3-4605e4d1eafe)\n\n- 文件(夹)\n\n| /etc/nginx/               | nginx配置文件默认的文件夹根地址                                        |\n| - |  |\n| /etc/nginx/nginx.conf     | nginx默认的配置文件入口，设置了工作进程，管道，日志，加载动态模块的配置。该文件中还包含指向其他配置文件的引用 |\n| /etc/nginx/conf.d/        | 该文件夹下包含默认的HTTP服务配置文件                                      |\n| /etc/nginx/stream.conf.d/ | 该文件夹下包含stream配置文件                                         |\n| /var/log/nginx/           | 默认的日志文件夹，包含access.log和error.log                           |\n\n- 命令\n\n| nginx -h        | nginx help菜单                                         |\n|  | - |\n| nginx -v        | 版本                                                   |\n| nginx -V        | 版本，构建信息，配置参数                                         |\n| nginx -t        | 测试nginx配置                                            |\n| nginx -T        | 测试nginx配置并且打印有效配置                                    |\n| nginx -s signal | 给nginx主进程发送命令，signal example：stop quit reload reopen |\n\n\n[优雅地重启nginx](7a802821-4a1c-47be-845e-1d280bd19658)\n\n\nnginx -s reload\n\n\n[nginx负载均衡](802bf27b-a1b2-4df0-b30a-405c9d425ff8)\n\n- HTTP负载均衡\n\n\t```shell\n\tupstream backend {#upstream模块控制nginx的负载均衡\n\t\n\t\t#在两个HTTP server间做负载均衡，weight越大权重越大\n\t\tserver 10.10.12.45:80 weight=1;\n\t\tserver app.example.com:80 weight=2;\n\t\n\t\t#一个后备，当上面两个服务挂掉时启用\n\t\tserver spare.example.com:80 backup;\n\t}\n\tserver {\n\t\tlocation / {\n\t\t\tproxy_pass http://backend;\n\t\t}\n\t}\n\t```\n\n- TCP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream mysql_read {\n\t\t\tserver read1.example.com:3306 weight=5;\n\t\t\tserver read2.example.com:3306;\n\t\t\tserver 10.10.12.34:3306 backup;\n\t\t}\n\t\tserver {\n\t\t\tlisten 3306;\n\t\t\tproxy_pass mysql_read;\n\t\t}\n\t}\n\t```\n\n\n\t这个配置不会被放在conf.d文件夹下，应当创建一个stream.conf.d文件夹，在nginx.conf中加入以下配置。\n\n\n\t```shell\n\tstream{\n\t\t\tinclude /etc/nginx/stream.conf.d/*.conf;\n\t}\n\t```\n\n- UDP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream ntp {\n\t\t\tserver ntp1.example.com:123 weight=2;\n\t\t\tserver ntp2.example.com:123;\n\t\t}\n\t\tserver {\n\t\t\tlisten 123 udp;\n\t\t\tproxy_pass ntp;\n\t\t}\n\t}\n\t```\n\n\nnginx默认采用的是Round-robin轮询调度算法，nginx支持多种负载均衡方法如：最少连接，最少耗时，一致性hash，IP hash，随机调度等。可以在upstream block中进行配置：\n\n\n```shell\nupstream backend {\n\tleast_conn;\n\tserver backend.example.com;\n\tserver backend1.example.com;\n}\n```\n\n\n| Round robin       | 默认方式，按顺序分配请求给服务集群。可以通过配置weight使其成为weighted round robin                                                             |\n| -- |  |\n| Least connections | 将请求分配给打开连接数最少的服务器，可以通过weight给每个服务器设置权重                                                                             |\n| Least time        | 只在nginx plus中可用                                                                                                    |\n| Generic hash      | [https://zh.m.wikipedia.org/zh-hans/一致哈希](https://zh.m.wikipedia.org/zh-hans/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C) |\n| Random            | 随机算法，考虑weight                                                                                                      |\n| IP hash           | IP地址作为hash参数，考虑weight                                                                                              |\n\n\n[nginx流量管理](daebaa2d-2f3c-4d3c-a6e4-dc0b0bb49bae)\n\n\n### A/B Testing\n\n\n将客户端导流到不同的应用版本\n\n\n```shell\nsplit_clients \"${remote_addr}AAA\" $variant {\n\t\t20.0% \"backendv2\";\n\t\t* \"backendv1\";\n}\n```\n\n\n### GeoIP Module\n\n- 下载nginx GeoIP模块包\n\n```shell\n#下载nginx-module-geoip\nyum install nginx-module-geoip\nmkdir /etc/nginx/geoip\ncd /etc/nginx/geoip\nwget \"http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz\"\ngunzip GeoIP.dat.gz\nwget \"http://geolite.maxmind.com/\\download/geoip/database/GeoLiteCity.dat.gz\"\ngunzip GeoLiteCity.dat.gz\n```\n\n- 然后在配置文件中进行配置\n\n```shell\n#load_module指令只在主context中有效\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n#geoip_country,geoip_city只在http context中有效\nhttp {\n\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n}\n```\n\n\n有了这个module就可以将地理信息传递给后端的应用，或者借助它来进行流量路由，例如可以基于国别进行控制\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\t#来自美国的IP，变量country_access被置为0，其他被置为1\n\t\tmap $geoip_country_code $country_access{\n\t\t\t\t\"US\" 0;\n\t\t\t\tdefault 1;\n\t\t}\n\t\t#在server block中进行配置\n\t\tserver{\n\t\t\t\t#非美国的IP禁止访问\n\t\t\t\tif($country_access = '1'){\n\t\t\t\t\t\treturn 403;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n如果客户端在nginx之前途经其他的代理，可以配置找到其原始IP\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\t\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n\n\t\t#CIDR 指示nginx利用X-Forwarded-For头去查询客户端地址\n\t\tgeoip_proxy 10.0.16.0/26;\n\n\t\t#递归查找\n\t\tgeoip_proxy_recursive on;\n}\n```\n\n\n### 按照一定的规则限制连接数，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\tlimit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;\n\t\tlimit_conn_status 429;\n\t\tserver{\n\t\t\t\tlimit_conn limitbyaddr 40;\n\t\t}\n}\nlimit_conn_status和limit_conn指令在http、server、location context中有效\nlimit_conn_zone则只在http context中有效\n```\n\n\n预定义的key即规则要按照实际情况进行设置。比如请求来自NAT网络，那么根据IP地址限制连接数就是不合理的。limit_conn_zone后的字符串可以是任意数量的nginx可用变量，可以在应用层的级别去识别一个用户，比如说通过session cookie。默认的http状态码是503，但是其实服务是可用的，只是被限制了访问，所以429是更好的选择来暗示是客户端的问题\n\n\n### 按照一定的规则限制流量，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\t#速率被限制为3r/s，可以以秒或者分钟的粒度进行限流\n\t\tlimit_req_zone $binary_remote_addr zone=limitbyaddr:10m rate=3r/s;\n\t\tlimit_req_status 429;\n\t\tserver{\n\t\t\t\tlimit_req zone=limitbyaddr;\n\t\t\t\tlocation / {\n\t\t\t\t\t\t#二阶段限速，burst允许速率提升到其值而不拒绝请求\n\t\t\t\t\t\t#第二个参数有delay和nodelay选项\n\t\t\t\t\t\t#nodelay选项会立即消费brust的请求\n\t\t\t\t\t\t#但是在floor(brust/rate)时间后才会继续接受来自该客户端的请求\n\t\t\t\t\t\t#delay选项则会先消费delay数的请求，之后的延迟消费\n\t\t\t\t\t\tlimit_req zone=limitbyaddr burst=12 delay=9;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n_超出限制的访问请求会被记录到error.log中。_\n\n\n### 限制带宽\n\n\n通过配置限制每个客户端的下载带宽\n\n\n```shell\nlocation /download/ {\n\t\t#在下载10m的资源后会被限速1m/s\n\t\tlimit_rate_after 10m;\n\t\tlimit_rate 1m;\n}\n```\n\n\n[nginx内容缓存](f3dcfc09-4c20-426c-895e-f313c1003d64)\n\n\n[nginx动态配置的能力](0afd3e8d-3820-4ea7-8716-1ef02dd5a14c)\n\n\n[nginx认证](180d99e4-2155-4b93-ad35-0b3439dcb6df)\n\n\n### HTTP Basic认证\n\n\n生成一个包含用户名和密码的文件\n\n\n```shell\n#comment\n#password可以是加密或者hash后的字符串，加密使用C函数crypt()\n#具体操作方式是下载OpenSSL，执行openssl passwd password\n#password可以通过多种方式进行混淆，但是通常是不安全的，因为可以进行暴力破解\nname1:password1\nname2:password2:comment\nname3:password3\n```\n\n\n在配置文件中配置指令使得认证生效\n\n\n```shell\nlocation / {\n\t\t#未认证通过的请求显示Private site\n\t\tauth_basic \"Private site\";\n\t\tauth_basic_user_file conf.d/passwd;\n}\nauth_basic可以在http、server、location中进行配置\n```\n\n\n### 认证子请求，即对请求进行授权认证\n\n\n可以使用http_auth_request_module在将实际请求转发给相应服务前先由认证服务进行身份鉴别\n\n\n```shell\nlocation /private/ {\n\t\tauth_request /auth;\n\t\t#从auth服务中带出的一些变量\n\t\tauth_request_set $auth_status $upstream_status;\n}\n\nlocation = /auth {\n\t\tinternal;\n\t\tproxy_pass http://auth-server;\n\t\t#不需要body的场景\n\t\tproxy_pass_request_body off;\n\t\tproxy_set_header Content-Length \"\";\n\t\tproxy_set_header X-Original_URI $request_uri;\n}\n```\n\n\n[nginx安全控制](85eaab33-5d9d-4895-950c-cb71775c9c46)\n\n\n### 基于IP地址的访问控制\n\n\n```shell\nlocation /admin/ {\n\t\t#允许10.0.0.0/20域下除了10.0.0.1的访问\n\t\tdeny 10.0.0.1;\n\t\tallow 10.0.0.0/20;\n\t\t#允许2001:0db8::/32子网下所有IPV6地址的访问\n\t\tallow 2001:0db8::/32;\n\t\t#拒绝其他IP的请求\n\t\tdeny all;\n}\n\nallow、deny指令在http，server，location以及基于TCP/UDP的stream，server context中都是有效的\n```\n\n\n### 允许跨域资源共享(CORS)\n\n\n```shell\n#http 方法映射\nmap $request_method $cors_method {\n\t\tOPTIONS 11;\n\t\tGET 1;\n\t\tPOST 1;\n\t\tdefault 0;\n}\nserver {\n\t\tlocation / {\n\t\t\t\tif($cors_method ~ '1'){\n\t\t\t\t\t\t#允许跨域的方法\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\n\t\t\t\t\t\t#允许跨域的域名规则\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Origin' '*.example.com';\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Headers' \n\t\t\t\t\t\t\t'DNT,Keep-Alive,User-Agent,X-Request-With,\n\t\t\t\t\t\t\tIf-Modified-Since,Cache-Control,Content-Type';\n\t\t\t\t}\n\t\t\t\t#OPTION方法发送预检请求，获取服务的CORS规则\n\t\t\t\tif($cors_method = '11'){\n\t\t\t\t\t\t#在客户端缓存20天\n\t\t\t\t\t\tadd_header 'Access-Control-Max-Age' 1728000;\n\t\t\t\t\t\t#请求体为空\n\t\t\t\t\t\tadd_header 'Content-Type' 'text/plain; charset=UTF-8';\n\t\t\t\t\t\tadd_header 'Content-Length' 0;\n\t\t\t\t\t\treturn 204;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n### 客户端侧的加密\n\n\n```shell\n#利用一个SSL module对流量进行加密，比如ngx_http_ssl_module或者ngx_stream_ssl_module\n\nhttp { # All directives used below are also valid in stream\n\t\tserver {\n\t\t\t\t#设置一个SSL/TLS服务侦听在8443端口\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#服务证书，即发给客户端的公钥\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#用于加解密的密钥，实际上是服务端用的私钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.key;\n\t\t}\n}\n```\n\n\n### 加强客户端侧加密\n\n\n证书和证书秘钥既可以通过文件路径的方式进行配置，也可以通过变量参数的方式进行配置，客户端所能提供的最强等级标准和服务器所能接受的标准将是最终协议的结果。\n\n\n```shell\nhttp { #所有的指令在stream中也可以使用\n\t\tserver {\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#允许的ssl协议以及cipher\n\t\t\t\tssl_protocols TLSv1.2 TLSv1.3;\n\t\t\t\t#密码被设置为最高标准，拒绝aNULL,MD5\n\t\t\t\tssl_ciphers HIGH:!aNULL:!MD5;\n\t\t\t\t\n\t\t\t\t#RSA证书文件\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#RSA秘钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.pem;\n\n\t\t\t\t#变量中设置的证书使用椭圆曲线数字签名算法（ECC）\n\t\t\t\tssl_certificate $ecdsa_cert;\n\t\t\t\t#变量中设置的ECC形式的秘钥\n\t\t\t\tssl_certificate_key data:$ecdsa_key_path;\n\t\t\t\t\n\t\t\t\t#允许nginx缓存协议10分钟，内存配置为10m\n\t\t\t\tssl_session_cache shared:SSL:10m;\n\t\t\t\tssl_session_timeout 10m;\n\t\t}\n}\n\n#在相同强度下，ECC比RSA快\n```\n\n\n### 上游加密\n\n\n对nginx和上游服务之间的流量进行加密并且进行特定协议协商\n\n\n```shell\nlocation / {\n\t\tproxy_pass https://upstream.example.com;\n\t\tproxy_ssl_verify on;\n\t\t#确保nginx验证上游服务的证书有效深度最多为2\n\t\tproxy_ssl_verify_depth 2;\n\t\t#只接受TLSv1.2，默认所有版本\n\t\tproxy_ssl_protocols TLSv1.2;\n}\n```\n\n\n### 保护一个location block\n\n\n```shell\nlocation /resources {\n\t\t#安全秘钥\n\t\tsecure_link_secret mySecret;\n\t\tif($secure_link = \"\") {\n\t\t\t\treturn 403;\n\t\t}\n\t\trewrite ^ /secured/$secure_link;\n}\nlocation /secured/ {\n\t\tinternal;\n\t\troot /var/www;\n}\n```\n\n\n👆配置了一个内部block和一个公开block。如果请求的URI中包含一个md5 hash字符串并且能够被secure_link_secret指令提供的秘钥认证，则请求地址会被重写，并且交给内部block处理，否则请求会被拒绝，收到403的回复。\n\n\n### 使用秘钥生成一个安全链接\n\n\n上个单元中的合法URI长什么样子呢，举个例子，我们访问域名为www.example.com的服务器上的/var/www/secured/index.html资源，那么就需要根据index.html这个资源生成md5的十六进制编码，具体操作如下：\n\n\n```shell\necho -n 'index.htmlmySecret' | openssl md5 -hex\n(stdin)= a53bee08a4bf0bbea978ddf736363a12\n```\n\n\n然后这个生成的md5十六进制摘要会被拼接到URI中\n\n\n```shell\nwww.example.com/resources/a53bee08a4bf0bbea978ddf736363a12/index.html\n```\n\n\n这就是一个合法的URI。\n\n\n### 使用一个过期日期保护一个location block\n\n\n只有合法且在有效期内的链接才能够访问资源\n\n\n```shell\nlocation /resources {\n\t\troot /var/www;\n\t\t#第一个参数持有md5 hash，第二个参数是Unix epoch格式的link过期时间\n\t\t#arg_md5是一个http参数\n\t\tsecure_link $arg_md5,$arg_expires;\n\t\t#用于生成md5编码的字符串格式\n\t\tsecure_link_md5 \"$secure_link_expires$uri$remote_addrmySecret\";\n\t\t#如果是个无效的URI\n\t\tif($secure_link = \"\"){return 403;}\n\t\t#如果是个有效的URI但是已经过期了\n\t\tif($secure_link = \"0\"){return 410;}\n}\n```\n\n\n### 生成一个带过期时间的链接\n\n\n在unix系统中生成unix时间戳可以使用date指令\n\n\n```shell\n$ date -d \"2030-12-31 00:00\" +%s --utc\n1924905600\n```\n\n\n接下来要做的就是将在secure_link_md5指令中配置的字符串参数进行拼接，再上一个单元中拼接成的字符串则为1924905600/resources/index.html127.0.0.1 mySecret .在这里的MD5 hash同16进制摘要的MD5 hash有一些不同，它是二进制格式的，并且是将+转换为-，/转换为_，去掉=的base64编码。在unix系统中的一个例子如下：\n\n\n```shell\n$ echo -n '1924905600/resources/index.html127.0.0.1 mySecret' \\\n\t| openssl md5 -binary \\\n\t| openssl base64 \\\n\t| tr +/ -_ \\\n\t| tr -d =\nsqysOw5kMvQBL3j9ODCyoQ\n```\n\n\n现在可以在URI中拼接生成的MD5参数\n\n\n```shell\n/resources/index.html?md5=sqysOw5kMvQBL3j9ODCyoQ&expires=1924905600 \n```\n\n\n### 将一个http请求重定向为一个https请求\n\n\n```shell\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\treturn 301 https://$host$request_url;\n}\nor\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\t#只有在http_x_forwarded_proto请求头为http时，才重定向\n\t\tif($http_x_forwarded_proto = 'http'){\n\t\t\t\treturn 301 https://$host$request_url;\n\t\t}\n}\n```\n\n\n### HTTP严格传输安全（HSTS）\n\n\n通过设置Strict-Transport-Security请求头让浏览器总是进行重定向将HTTP请求转换为HTTPS请求\n\n\n```shell\n#max-age=1 year\nadd_header Strict-Transport-Security max-age=31536000;\n```\n\n\n### 满足任意数量的保障安全方式\n\n\n```shell\nlocation / {\n\t\t#参数any or all\n\t\tsatisfy any;\n\t\t\n\t\t#允许192.168.1.0/24网络访问\n\t\tallow 192.168.1.0/24;\n\t\tdeny all;\n\t\t\n\t\t#basic认证访问\n\t\tauth_basic \"closed site\";\n\t\tauth_basic_user_file conf/htpasswd;\n}\n```\n\n"}]},{"tag":"devops","payload":[{"title":"Nginx必知必会","categories":"nginx","tags":["nginx","运维","devops"],"date":"2022-11-16","content":"\n\n[在centos下安装Nginx](b43b9a0b-0311-412a-a38d-0720a9a8df76)\n\n1. 在/etc/yum.repo.d下新建文件nginx.repo定义Nginx软件仓库细节\n\n\t```shell\n\t[nginx]\n\tname=nginx repo\n\t#OS example centos,OSRELEASE example 7.x\n\tbaseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/\n\tgpgcheck=0\n\tenabled=1\n\t```\n\n2. 执行nginx下载，配置nginx自启动，配置防火墙\n\n\t```shell\n\tyum -y install nginx\n\tsystemctl enable nginx\n\tsystemctl start nginx\n\tfirewalld-cmd --permanent --zone=public --add-port=80/tcp\n\tfirewall-cmd --reload\n\t```\n\n\n[nginx关键文件，文件夹以及命令](7de1a27a-f767-40b5-83e3-4605e4d1eafe)\n\n- 文件(夹)\n\n| /etc/nginx/               | nginx配置文件默认的文件夹根地址                                        |\n| - |  |\n| /etc/nginx/nginx.conf     | nginx默认的配置文件入口，设置了工作进程，管道，日志，加载动态模块的配置。该文件中还包含指向其他配置文件的引用 |\n| /etc/nginx/conf.d/        | 该文件夹下包含默认的HTTP服务配置文件                                      |\n| /etc/nginx/stream.conf.d/ | 该文件夹下包含stream配置文件                                         |\n| /var/log/nginx/           | 默认的日志文件夹，包含access.log和error.log                           |\n\n- 命令\n\n| nginx -h        | nginx help菜单                                         |\n|  | - |\n| nginx -v        | 版本                                                   |\n| nginx -V        | 版本，构建信息，配置参数                                         |\n| nginx -t        | 测试nginx配置                                            |\n| nginx -T        | 测试nginx配置并且打印有效配置                                    |\n| nginx -s signal | 给nginx主进程发送命令，signal example：stop quit reload reopen |\n\n\n[优雅地重启nginx](7a802821-4a1c-47be-845e-1d280bd19658)\n\n\nnginx -s reload\n\n\n[nginx负载均衡](802bf27b-a1b2-4df0-b30a-405c9d425ff8)\n\n- HTTP负载均衡\n\n\t```shell\n\tupstream backend {#upstream模块控制nginx的负载均衡\n\t\n\t\t#在两个HTTP server间做负载均衡，weight越大权重越大\n\t\tserver 10.10.12.45:80 weight=1;\n\t\tserver app.example.com:80 weight=2;\n\t\n\t\t#一个后备，当上面两个服务挂掉时启用\n\t\tserver spare.example.com:80 backup;\n\t}\n\tserver {\n\t\tlocation / {\n\t\t\tproxy_pass http://backend;\n\t\t}\n\t}\n\t```\n\n- TCP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream mysql_read {\n\t\t\tserver read1.example.com:3306 weight=5;\n\t\t\tserver read2.example.com:3306;\n\t\t\tserver 10.10.12.34:3306 backup;\n\t\t}\n\t\tserver {\n\t\t\tlisten 3306;\n\t\t\tproxy_pass mysql_read;\n\t\t}\n\t}\n\t```\n\n\n\t这个配置不会被放在conf.d文件夹下，应当创建一个stream.conf.d文件夹，在nginx.conf中加入以下配置。\n\n\n\t```shell\n\tstream{\n\t\t\tinclude /etc/nginx/stream.conf.d/*.conf;\n\t}\n\t```\n\n- UDP负载均衡\n\n\t```shell\n\tstream {\n\t\tupstream ntp {\n\t\t\tserver ntp1.example.com:123 weight=2;\n\t\t\tserver ntp2.example.com:123;\n\t\t}\n\t\tserver {\n\t\t\tlisten 123 udp;\n\t\t\tproxy_pass ntp;\n\t\t}\n\t}\n\t```\n\n\nnginx默认采用的是Round-robin轮询调度算法，nginx支持多种负载均衡方法如：最少连接，最少耗时，一致性hash，IP hash，随机调度等。可以在upstream block中进行配置：\n\n\n```shell\nupstream backend {\n\tleast_conn;\n\tserver backend.example.com;\n\tserver backend1.example.com;\n}\n```\n\n\n| Round robin       | 默认方式，按顺序分配请求给服务集群。可以通过配置weight使其成为weighted round robin                                                             |\n| -- |  |\n| Least connections | 将请求分配给打开连接数最少的服务器，可以通过weight给每个服务器设置权重                                                                             |\n| Least time        | 只在nginx plus中可用                                                                                                    |\n| Generic hash      | [https://zh.m.wikipedia.org/zh-hans/一致哈希](https://zh.m.wikipedia.org/zh-hans/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C) |\n| Random            | 随机算法，考虑weight                                                                                                      |\n| IP hash           | IP地址作为hash参数，考虑weight                                                                                              |\n\n\n[nginx流量管理](daebaa2d-2f3c-4d3c-a6e4-dc0b0bb49bae)\n\n\n### A/B Testing\n\n\n将客户端导流到不同的应用版本\n\n\n```shell\nsplit_clients \"${remote_addr}AAA\" $variant {\n\t\t20.0% \"backendv2\";\n\t\t* \"backendv1\";\n}\n```\n\n\n### GeoIP Module\n\n- 下载nginx GeoIP模块包\n\n```shell\n#下载nginx-module-geoip\nyum install nginx-module-geoip\nmkdir /etc/nginx/geoip\ncd /etc/nginx/geoip\nwget \"http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz\"\ngunzip GeoIP.dat.gz\nwget \"http://geolite.maxmind.com/\\download/geoip/database/GeoLiteCity.dat.gz\"\ngunzip GeoLiteCity.dat.gz\n```\n\n- 然后在配置文件中进行配置\n\n```shell\n#load_module指令只在主context中有效\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n#geoip_country,geoip_city只在http context中有效\nhttp {\n\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n}\n```\n\n\n有了这个module就可以将地理信息传递给后端的应用，或者借助它来进行流量路由，例如可以基于国别进行控制\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\t#来自美国的IP，变量country_access被置为0，其他被置为1\n\t\tmap $geoip_country_code $country_access{\n\t\t\t\t\"US\" 0;\n\t\t\t\tdefault 1;\n\t\t}\n\t\t#在server block中进行配置\n\t\tserver{\n\t\t\t\t#非美国的IP禁止访问\n\t\t\t\tif($country_access = '1'){\n\t\t\t\t\t\treturn 403;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n如果客户端在nginx之前途经其他的代理，可以配置找到其原始IP\n\n\n```shell\nload_module \"/usr/lib64/nginx/modules/ngx_http_geoip_module.so\";\n\nhttp{\n\t\tgeoip_country /etc/nginx/geoip/GeoIP.dat;\n\t\tgeoip_city /etc/nginx/geoip/GeoLiteCity.dat;\n\n\t\t#CIDR 指示nginx利用X-Forwarded-For头去查询客户端地址\n\t\tgeoip_proxy 10.0.16.0/26;\n\n\t\t#递归查找\n\t\tgeoip_proxy_recursive on;\n}\n```\n\n\n### 按照一定的规则限制连接数，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\tlimit_conn_zone $binary_remote_addr zone=limitbyaddr:10m;\n\t\tlimit_conn_status 429;\n\t\tserver{\n\t\t\t\tlimit_conn limitbyaddr 40;\n\t\t}\n}\nlimit_conn_status和limit_conn指令在http、server、location context中有效\nlimit_conn_zone则只在http context中有效\n```\n\n\n预定义的key即规则要按照实际情况进行设置。比如请求来自NAT网络，那么根据IP地址限制连接数就是不合理的。limit_conn_zone后的字符串可以是任意数量的nginx可用变量，可以在应用层的级别去识别一个用户，比如说通过session cookie。默认的http状态码是503，但是其实服务是可用的，只是被限制了访问，所以429是更好的选择来暗示是客户端的问题\n\n\n### 按照一定的规则限制流量，譬如IP\n\n\n```shell\nhttp{\n\t\t#定义了一个名叫limitbyaddr的共享内存空间，预定义的key为二进制IP地址，空间被设置为10m\n\t\t#速率被限制为3r/s，可以以秒或者分钟的粒度进行限流\n\t\tlimit_req_zone $binary_remote_addr zone=limitbyaddr:10m rate=3r/s;\n\t\tlimit_req_status 429;\n\t\tserver{\n\t\t\t\tlimit_req zone=limitbyaddr;\n\t\t\t\tlocation / {\n\t\t\t\t\t\t#二阶段限速，burst允许速率提升到其值而不拒绝请求\n\t\t\t\t\t\t#第二个参数有delay和nodelay选项\n\t\t\t\t\t\t#nodelay选项会立即消费brust的请求\n\t\t\t\t\t\t#但是在floor(brust/rate)时间后才会继续接受来自该客户端的请求\n\t\t\t\t\t\t#delay选项则会先消费delay数的请求，之后的延迟消费\n\t\t\t\t\t\tlimit_req zone=limitbyaddr burst=12 delay=9;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n_超出限制的访问请求会被记录到error.log中。_\n\n\n### 限制带宽\n\n\n通过配置限制每个客户端的下载带宽\n\n\n```shell\nlocation /download/ {\n\t\t#在下载10m的资源后会被限速1m/s\n\t\tlimit_rate_after 10m;\n\t\tlimit_rate 1m;\n}\n```\n\n\n[nginx内容缓存](f3dcfc09-4c20-426c-895e-f313c1003d64)\n\n\n[nginx动态配置的能力](0afd3e8d-3820-4ea7-8716-1ef02dd5a14c)\n\n\n[nginx认证](180d99e4-2155-4b93-ad35-0b3439dcb6df)\n\n\n### HTTP Basic认证\n\n\n生成一个包含用户名和密码的文件\n\n\n```shell\n#comment\n#password可以是加密或者hash后的字符串，加密使用C函数crypt()\n#具体操作方式是下载OpenSSL，执行openssl passwd password\n#password可以通过多种方式进行混淆，但是通常是不安全的，因为可以进行暴力破解\nname1:password1\nname2:password2:comment\nname3:password3\n```\n\n\n在配置文件中配置指令使得认证生效\n\n\n```shell\nlocation / {\n\t\t#未认证通过的请求显示Private site\n\t\tauth_basic \"Private site\";\n\t\tauth_basic_user_file conf.d/passwd;\n}\nauth_basic可以在http、server、location中进行配置\n```\n\n\n### 认证子请求，即对请求进行授权认证\n\n\n可以使用http_auth_request_module在将实际请求转发给相应服务前先由认证服务进行身份鉴别\n\n\n```shell\nlocation /private/ {\n\t\tauth_request /auth;\n\t\t#从auth服务中带出的一些变量\n\t\tauth_request_set $auth_status $upstream_status;\n}\n\nlocation = /auth {\n\t\tinternal;\n\t\tproxy_pass http://auth-server;\n\t\t#不需要body的场景\n\t\tproxy_pass_request_body off;\n\t\tproxy_set_header Content-Length \"\";\n\t\tproxy_set_header X-Original_URI $request_uri;\n}\n```\n\n\n[nginx安全控制](85eaab33-5d9d-4895-950c-cb71775c9c46)\n\n\n### 基于IP地址的访问控制\n\n\n```shell\nlocation /admin/ {\n\t\t#允许10.0.0.0/20域下除了10.0.0.1的访问\n\t\tdeny 10.0.0.1;\n\t\tallow 10.0.0.0/20;\n\t\t#允许2001:0db8::/32子网下所有IPV6地址的访问\n\t\tallow 2001:0db8::/32;\n\t\t#拒绝其他IP的请求\n\t\tdeny all;\n}\n\nallow、deny指令在http，server，location以及基于TCP/UDP的stream，server context中都是有效的\n```\n\n\n### 允许跨域资源共享(CORS)\n\n\n```shell\n#http 方法映射\nmap $request_method $cors_method {\n\t\tOPTIONS 11;\n\t\tGET 1;\n\t\tPOST 1;\n\t\tdefault 0;\n}\nserver {\n\t\tlocation / {\n\t\t\t\tif($cors_method ~ '1'){\n\t\t\t\t\t\t#允许跨域的方法\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS';\n\t\t\t\t\t\t#允许跨域的域名规则\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Origin' '*.example.com';\n\t\t\t\t\t\tadd_header 'Access-Control-Allow-Headers' \n\t\t\t\t\t\t\t'DNT,Keep-Alive,User-Agent,X-Request-With,\n\t\t\t\t\t\t\tIf-Modified-Since,Cache-Control,Content-Type';\n\t\t\t\t}\n\t\t\t\t#OPTION方法发送预检请求，获取服务的CORS规则\n\t\t\t\tif($cors_method = '11'){\n\t\t\t\t\t\t#在客户端缓存20天\n\t\t\t\t\t\tadd_header 'Access-Control-Max-Age' 1728000;\n\t\t\t\t\t\t#请求体为空\n\t\t\t\t\t\tadd_header 'Content-Type' 'text/plain; charset=UTF-8';\n\t\t\t\t\t\tadd_header 'Content-Length' 0;\n\t\t\t\t\t\treturn 204;\n\t\t\t\t}\n\t\t}\n}\n```\n\n\n### 客户端侧的加密\n\n\n```shell\n#利用一个SSL module对流量进行加密，比如ngx_http_ssl_module或者ngx_stream_ssl_module\n\nhttp { # All directives used below are also valid in stream\n\t\tserver {\n\t\t\t\t#设置一个SSL/TLS服务侦听在8443端口\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#服务证书，即发给客户端的公钥\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#用于加解密的密钥，实际上是服务端用的私钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.key;\n\t\t}\n}\n```\n\n\n### 加强客户端侧加密\n\n\n证书和证书秘钥既可以通过文件路径的方式进行配置，也可以通过变量参数的方式进行配置，客户端所能提供的最强等级标准和服务器所能接受的标准将是最终协议的结果。\n\n\n```shell\nhttp { #所有的指令在stream中也可以使用\n\t\tserver {\n\t\t\t\tlisten 8443 ssl;\n\t\t\t\t#允许的ssl协议以及cipher\n\t\t\t\tssl_protocols TLSv1.2 TLSv1.3;\n\t\t\t\t#密码被设置为最高标准，拒绝aNULL,MD5\n\t\t\t\tssl_ciphers HIGH:!aNULL:!MD5;\n\t\t\t\t\n\t\t\t\t#RSA证书文件\n\t\t\t\tssl_certificate /etc/nginx/ssl/example.crt;\n\t\t\t\t#RSA秘钥\n\t\t\t\tssl_certificate_key /etc/nginx/ssl/example.pem;\n\n\t\t\t\t#变量中设置的证书使用椭圆曲线数字签名算法（ECC）\n\t\t\t\tssl_certificate $ecdsa_cert;\n\t\t\t\t#变量中设置的ECC形式的秘钥\n\t\t\t\tssl_certificate_key data:$ecdsa_key_path;\n\t\t\t\t\n\t\t\t\t#允许nginx缓存协议10分钟，内存配置为10m\n\t\t\t\tssl_session_cache shared:SSL:10m;\n\t\t\t\tssl_session_timeout 10m;\n\t\t}\n}\n\n#在相同强度下，ECC比RSA快\n```\n\n\n### 上游加密\n\n\n对nginx和上游服务之间的流量进行加密并且进行特定协议协商\n\n\n```shell\nlocation / {\n\t\tproxy_pass https://upstream.example.com;\n\t\tproxy_ssl_verify on;\n\t\t#确保nginx验证上游服务的证书有效深度最多为2\n\t\tproxy_ssl_verify_depth 2;\n\t\t#只接受TLSv1.2，默认所有版本\n\t\tproxy_ssl_protocols TLSv1.2;\n}\n```\n\n\n### 保护一个location block\n\n\n```shell\nlocation /resources {\n\t\t#安全秘钥\n\t\tsecure_link_secret mySecret;\n\t\tif($secure_link = \"\") {\n\t\t\t\treturn 403;\n\t\t}\n\t\trewrite ^ /secured/$secure_link;\n}\nlocation /secured/ {\n\t\tinternal;\n\t\troot /var/www;\n}\n```\n\n\n👆配置了一个内部block和一个公开block。如果请求的URI中包含一个md5 hash字符串并且能够被secure_link_secret指令提供的秘钥认证，则请求地址会被重写，并且交给内部block处理，否则请求会被拒绝，收到403的回复。\n\n\n### 使用秘钥生成一个安全链接\n\n\n上个单元中的合法URI长什么样子呢，举个例子，我们访问域名为www.example.com的服务器上的/var/www/secured/index.html资源，那么就需要根据index.html这个资源生成md5的十六进制编码，具体操作如下：\n\n\n```shell\necho -n 'index.htmlmySecret' | openssl md5 -hex\n(stdin)= a53bee08a4bf0bbea978ddf736363a12\n```\n\n\n然后这个生成的md5十六进制摘要会被拼接到URI中\n\n\n```shell\nwww.example.com/resources/a53bee08a4bf0bbea978ddf736363a12/index.html\n```\n\n\n这就是一个合法的URI。\n\n\n### 使用一个过期日期保护一个location block\n\n\n只有合法且在有效期内的链接才能够访问资源\n\n\n```shell\nlocation /resources {\n\t\troot /var/www;\n\t\t#第一个参数持有md5 hash，第二个参数是Unix epoch格式的link过期时间\n\t\t#arg_md5是一个http参数\n\t\tsecure_link $arg_md5,$arg_expires;\n\t\t#用于生成md5编码的字符串格式\n\t\tsecure_link_md5 \"$secure_link_expires$uri$remote_addrmySecret\";\n\t\t#如果是个无效的URI\n\t\tif($secure_link = \"\"){return 403;}\n\t\t#如果是个有效的URI但是已经过期了\n\t\tif($secure_link = \"0\"){return 410;}\n}\n```\n\n\n### 生成一个带过期时间的链接\n\n\n在unix系统中生成unix时间戳可以使用date指令\n\n\n```shell\n$ date -d \"2030-12-31 00:00\" +%s --utc\n1924905600\n```\n\n\n接下来要做的就是将在secure_link_md5指令中配置的字符串参数进行拼接，再上一个单元中拼接成的字符串则为1924905600/resources/index.html127.0.0.1 mySecret .在这里的MD5 hash同16进制摘要的MD5 hash有一些不同，它是二进制格式的，并且是将+转换为-，/转换为_，去掉=的base64编码。在unix系统中的一个例子如下：\n\n\n```shell\n$ echo -n '1924905600/resources/index.html127.0.0.1 mySecret' \\\n\t| openssl md5 -binary \\\n\t| openssl base64 \\\n\t| tr +/ -_ \\\n\t| tr -d =\nsqysOw5kMvQBL3j9ODCyoQ\n```\n\n\n现在可以在URI中拼接生成的MD5参数\n\n\n```shell\n/resources/index.html?md5=sqysOw5kMvQBL3j9ODCyoQ&expires=1924905600 \n```\n\n\n### 将一个http请求重定向为一个https请求\n\n\n```shell\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\treturn 301 https://$host$request_url;\n}\nor\nserver {\n\t\tlisten 80 default_server;\n\t\tlisten [::]:80 default_server;\n\t\tserver_name _;\n\t\t#只有在http_x_forwarded_proto请求头为http时，才重定向\n\t\tif($http_x_forwarded_proto = 'http'){\n\t\t\t\treturn 301 https://$host$request_url;\n\t\t}\n}\n```\n\n\n### HTTP严格传输安全（HSTS）\n\n\n通过设置Strict-Transport-Security请求头让浏览器总是进行重定向将HTTP请求转换为HTTPS请求\n\n\n```shell\n#max-age=1 year\nadd_header Strict-Transport-Security max-age=31536000;\n```\n\n\n### 满足任意数量的保障安全方式\n\n\n```shell\nlocation / {\n\t\t#参数any or all\n\t\tsatisfy any;\n\t\t\n\t\t#允许192.168.1.0/24网络访问\n\t\tallow 192.168.1.0/24;\n\t\tdeny all;\n\t\t\n\t\t#basic认证访问\n\t\tauth_basic \"closed site\";\n\t\tauth_basic_user_file conf/htpasswd;\n}\n```\n\n"}]},{"tag":"spring-security","payload":[{"title":"spring security(servlet)","categories":"Java","tags":["spring-security"],"date":"2023-02-22","content":"\n\n以下内容均是基于spring security 5.7.4版本，并且是基于webmvc。\n\n\n由于spring gateway的web依赖是webflux，webflux是spring基于响应式编程实践创建的web框架，如果要将spring security集成进spring gateway中，则需要对webflux以及projectreactor有一点了解。projectreactor参考[https://projectreactor.io/](https://projectreactor.io/)。webflux参考[https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html#spring-webflux](https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html#spring-webflux)。\n\n\nspring security是一个拥有认证，授权，提供网络保护的Java安全框架\n\n\n**架构篇**\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/acb6293f-2142-4c49-bf8f-ee6ff2597bbc/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=b5bfed3f9075809ff04944668725c99658c6bab268a7eafff496f581f7aaa254&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nspring securtiy的servlet是基于Filter的servlet。当客户端向应用发送请求时，servlet容器会创建一个包含有一系列过滤器和一个servlet的FilterChain Bean，这个bean会去处理基于请求URI生成的HttpServletRequest对象。\n\n\nFilterChain中的Filter的作用主要有两个，其一是防止下游的Filter或者Servlet被调用，那么这个Filter一般会返回一个HttpServletResponse。其二是修改被下游的Filter或者是Servlet使用的HttpServletRequest或HttpServletResponse。\n\n\nFilterChain用例\n\n\n```javascript\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) {\n\t// do something before the rest of the application\n    chain.doFilter(request, response); // invoke the rest of the application\n    // do something after the rest of the application\n}\n```\n\n\n**DelegatingFilterProxy**\n\n\nspring提供一个叫做DelegatingFilterProxy的Filter实现，这个类运用代理模式将servlet容器中的Filter和spring容器中的bean关联起来。基于DelegatingFilterProxy的机制，可以实现不同安全框架的融合。DelegatingFilterProxy的另一个好处是可以实现Filter bean的懒加载。\n\n\nDelegatingFilterProxy的伪码如下所示：\n\n\n```javascript\npublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) {\n\t// Lazily get Filter that was registered as a Spring Bean\n\tFilter delegate = getFilterBean(someBeanName);\n\t// delegate work to the Spring Bean\n\tdelegate.doFilter(request, response);\n}\n```\n\n\n**FilterChainProxy**\n\n\nspring security提供一个叫做FilterChainProxy的类，该类是一个特殊的Filter允许通过SecurityFilterChain代理一系列的Filter。既然FilterChainProxy是一个Filter的bean，它通常会被包在DelegatingFilterProxy中。\n\n\nSecurityFilterChain\n\n\n一个SecurityFilterChain中包含一系列的Filter，FilterChainProxy可以根据某个请求走哪一个过滤链。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/80db0144-3520-436b-9d58-1d64a781c435/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=717a76002bfaa76312c2e37ccd4a1d9e76181a49a34116a54b2b81820c9e2e37&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n**Security Filters**\n\n\nFilters的顺序对于程序的执行很重要。\n\n\nspring security filter的综合顺序如下\n\n- [`ForceEagerSessionCreationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/session-management.html#session-mgmt-force-session-creation)\n- ChannelProcessingFilter\n- WebAsyncManagerIntegrationFilter\n- SecurityContextPersistenceFilter\n- HeaderWriterFilter\n- CorsFilter\n- CsrfFilter\n- LogoutFilter\n- OAuth2AuthorizationRequestRedirectFilter\n- Saml2WebSsoAuthenticationRequestFilter\n- X509AuthenticationFilter\n- AbstractPreAuthenticatedProcessingFilter\n- CasAuthenticationFilter\n- OAuth2LoginAuthenticationFilter\n- Saml2WebSsoAuthenticationFilter\n- [`UsernamePasswordAuthenticationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/passwords/form.html#servlet-authentication-usernamepasswordauthenticationfilter)\n- OpenIDAuthenticationFilter\n- DefaultLoginPageGeneratingFilter\n- DefaultLogoutPageGeneratingFilter\n- ConcurrentSessionFilter\n- [`DigestAuthenticationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/passwords/digest.html#servlet-authentication-digest)\n- BearerTokenAuthenticationFilter\n- [`BasicAuthenticationFilter`](https://docs.spring.io/spring-security/reference/servlet/authentication/passwords/basic.html#servlet-authentication-basic)\n- RequestCacheAwareFilter\n- SecurityContextHolderAwareRequestFilter\n- JaasApiIntegrationFilter\n- RememberMeAuthenticationFilter\n- AnonymousAuthenticationFilter\n- OAuth2AuthorizationCodeGrantFilter\n- SessionManagementFilter\n- [`ExceptionTranslationFilter`](https://docs.spring.io/spring-security/reference/servlet/architecture.html#servlet-exceptiontranslationfilter)\n- [`FilterSecurityInterceptor`](https://docs.spring.io/spring-security/reference/servlet/authorization/authorize-requests.html#servlet-authorization-filtersecurityinterceptor)\n- SwitchUserFilter\n\n处理**Security Exceptions**\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/06c70dbd-e31d-48d8-90e5-0244c3e1da06/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=c1e1bb041178890b54837ec948e2062dbb27247674c909730ca52887f0b79cf3&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nspring security的异常由ExceptionTranslationFilter处理，它本身也是一个Filter，它负责将AccessDeniedException和AuthenticationException转化为HTTP 响应。\n\n1. 首先, the ExceptionTranslationFilter调用 `FilterChain.doFilter(request, response)`\n去执行应用接下来的部分。\n2. 如果一个用户还没有认证过或者是一个AuthenticationException，就会启动认证流程。以下步骤会被执行，SecurityContextHolder会被清空。HttpServletRequest会被保存在RequestCache中，用来在认证通过之后进行请求重放。AuthenticationEntryPoint会被用来在认证失败后，进行特殊的认证流程。\n3. 如果上面的流程没有通过，就是一个AccessDeniedException。AccessDeniedHandler会对这种情况进行处理。\n\nExceptionTranslationFilter的伪码如下：\n\n\n```javascript\ntry {\n\tfilterChain.doFilter(request, response); \n} catch (AccessDeniedException | AuthenticationException ex) {\n\tif (!authenticated || ex instanceof AuthenticationException) {\n\t\tstartAuthentication(); \n\t} else {\n\t\taccessDenied(); \n\t}\n}\n```\n\n\n# **spring security的认证**\n\n\n### 与认证相关的一些概念和类\n\n\nSecurityContextHolder - spring security储存当前认证用户细节的地方\n\n\nSecurityContext - 可以从SecurityContextHolder 中获取，包含当前认证用户的Authenticaiton\n\n\nAuthenticaiton - 可以是作为AuthenticationManager输入用来提供一个用户进行认证的凭证，也可以是从SecurityContext 中获取的当前用户。\n\n\nGrantedAuthority - 在Authenticaiton 中授予给Principal的权限。\n\n\nAuthenticationManager - 定义了spring security Filter执行authentication的API。\n\n\nProviderManager - AuthenticationManager 的一般实现类。\n\n\nAuthenticationProvider - 被ProviderManager 用来执行特定的认证。\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/14b7014e-7a40-4b85-8927-a884f19ae923/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=6be1ccb275d4c65cc14b6644c5a9be694425a0532eb6b307f07182941b073ce4&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nspring security认证的核心是SecurityContextHolder 。spring security并不关心SecurityContextHolder 怎么产生的，只要它有一个值，它就会被当作是当前的认证用户。\n\n\n最简单的指示一个认证用户的方式是直接设置SecurityContextHolder 。\n\n\n```javascript\n//1.创建一个空SecurityContext \nSecurityContext context = SecurityContextHolder.createEmptyContext(); \n//2.创建一个新的Authentication 对象\nAuthentication authentication =\n    new TestingAuthenticationToken(\"username\", \"password\", \"ROLE_USER\"); \ncontext.setAuthentication(authentication);\n\nSecurityContextHolder.setContext(context);\n```\n\n\n从SecurityContextHolder 中获取当前认证用户的方式\n\n\n```javascript\nSecurityContext context = SecurityContextHolder.getContext();\nAuthentication authentication = context.getAuthentication();\nString username = authentication.getName();\nObject principal = authentication.getPrincipal();\nCollection<? extends GrantedAuthority> authorities = authentication.getAuthorities();\n```\n\n\n**AbstractAuthenticationProcessingFilter**\n\n\nAbstractAuthenticationProcessingFilter是用于认证用户凭证的一个基本Filter，其大致的流程图如下：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/37772f05-68cc-446f-8747-a4d8b32d7d02/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=ee689335ddfb9c60027b8fd10598bc8e584bd5b404af4fda883b90d641bec67e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n1. 当用户提交他们的凭证时，AbstractAuthenticationProcessingFilter会从HttpServletRequest中构造出一个用于认证的Authentication对象。Authentication的类型取决于AbstractAuthenticationProcessingFilter的子类。比如UsernamePasswordAuthenticationFilter会创建UsernamePasswordAuthenticationToken。\n2. Authentication被传递给AuthenticationManager来进行认证。\n3. 如果认证失败，SecurityContextHolder被清空。RememberMeServices.loginFail被调用，如果remember me没有被设置，那么上面的函数便不会被调用。AuthenticationFailureHandler被掉用。\n4. 如果认证成功。\n- `SessionAuthenticationStrategy` 处理新的登录。\n- [Authentication](https://docs.spring.io/spring-security/reference/servlet/authentication/architecture.html#servlet-authentication-authentication) 被设置到 [SecurityContextHolder](https://docs.spring.io/spring-security/reference/servlet/authentication/architecture.html#servlet-authentication-securitycontextholder)。之后 `SecurityContextPersistenceFilter` 将 `SecurityContext` 保存到 `HttpSession`.\n- `RememberMeServices.loginSuccess` 被调用，如果remember me没有被设置，那么上面的函数便不会被调用。\n- `ApplicationEventPublisher` 发布一个 `InteractiveAuthenticationSuccessEvent。`\n- `AuthenticationSuccessHandler` 被调用。\n\n### 用户名密码登录\n\n\n用户名密码登录分为Form,Basic,Digest登录三种形式，spring security中的Form登录的账号名密码提交流程如下图所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/581243ef-bed4-4d3b-8850-49d134a77542/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=95ff2f5d11603fc1ebab7a57e881e12eaf42a19f75c230dd0121ba517f500560&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n一旦用户名密码被提交，UsernamePasswordAuthenticationFilter就开始执行它的认证工作，UsernamePasswordAuthenticationFilter继承自AbstractAuthenticationProcessingFilter,它的流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ea389297-5be0-404e-b7d8-494afdc20b90/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=2e69b676db9b71f12260b7eca232c3ec8c470dee96e7259a5391450055dd9bf3&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nFrom登录可以自定义配置，Java代码如下所示：\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t.formLogin(form -> form \n\t\t\t.loginPage(\"/login\") //你能控制的部分\n\t\t\t.permitAll()\n\t\t);\n\t// ...\n}\n```\n\n\nBasic HTTP Authentication是服务器向未认证客户端请求认证信息的一种登陆方式，在Spring中的流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7ae42cc3-dcbe-4d05-8f0b-68dd932cc60f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085115Z&X-Amz-Expires=3600&X-Amz-Signature=9b5d13db6c679042701ccb4f2c44c665d8e4b6f381f8dab55aa2fe4cea6a17b6&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n同样的，拿到账号名密码之后会执行类似的认证流程：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fb58b283-dfd4-4411-9f58-29a36ff52c3a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=149a82ccbf624a5a1c4677ac7900fbe57f9c215a0cc6f61b4b630aaaf29d05ab&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nBasic登录的配置如下：\n\n\n```javascript\n@Bean\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t// ...\n\t\t.httpBasic(withDefaults());\n\treturn http.build();\n}\n```\n\n\nrabbitmq 管理端web登陆方式就是Form登录和Basic登录的结合。\n\n\nDigest登录略。\n\n\n**Persisting Authentication**\n\n\nspring security中与认证信息持久化相关的一个类是SecurityContextRepository，可以通过如下的方式进行配置：\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t// ...\n\t\t.securityContext((securityContext) -> securityContext\n\t\t\t.securityContextRepository(new RequestAttributeSecurityContextRepository())//**SecurityContextRepository的一个实现类**\n\t\t);\n\treturn http.build();\n}\n```\n\n\nSecurityContextPersistenceFilter负责将SecurityContext持久化，其流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7da295e8-dd44-4b91-aa70-e20694fdd1a2/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=b98f403dea02febcb4437fa8628db324cf49cec35398f21b798a04f7b84ccf4f&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nSecurityContextHolderFilter负责加载SecurityContext信息，其流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7d1355e0-9d67-4f2d-8268-598a54faac6f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=4ebf7b5f107a5672a7243666ce5204204f775d90c969d774c78a25e6c953044e&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\nSecurityContextHolderFilter不会显式的保存SecurityContext信息，需要在配置中明确信息的保存。\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n\thttp\n\t\t// ...\n\t\t.securityContext((securityContext) -> securityContext\n\t\t\t.requireExplicitSave(true)\n\t\t);\n\treturn http.build();\n}\n```\n\n\n### Logout\n\n\n一般来说，logout会自动配置。默认的URL - /logout将会执行用户登出操作：\n\n- 使session无效\n- 清除任何配置的RememberMe认证\n- 清除SecurityContextHolder\n- 重定向到/login?logout\n\n使用者可以自定义登出逻辑\n\n\n```javascript\npublic SecurityFilterChain filterChain(HttpSecurity http) {\n    http\n        .logout(logout -> logout                                                \n            .logoutUrl(\"/my/logout\")  //自定义logout url                                       \n            .logoutSuccessUrl(\"/my/index\")  //登出成功重定向地址                               \n            .logoutSuccessHandler(logoutSuccessHandler)  //登出成功处理器，如果配了这个，logoutSuccessUrl将被忽略               \n            .invalidateHttpSession(true)                                     \n            .addLogoutHandler(logoutHandler)                                    \n            .deleteCookies(cookieNamesToClear)                                  \n        )\n        ...\n}\n```\n\n\n# **Authorization**\n\n\n### **Authorization Architecture**\n\n\n在授权中，核心对象是Authority。在认证完成之后，所有Authentication的实现类都会储存一个GrantedAuthority对象的列表，一个GrantedAuthority表示系统内某主体的一个权限。GrantedAuthority会在接下来AuthorizationManager的授权流程中被使用。\n\n\nGrantedAuthority是一个只提供一个方法的接口\n\n\n```javascript\nString getAuthority();\n```\n\n\nAuthorizationManager调用该方法获取一个表示该GrantedAuthority的字符串，通过该字符串作出授权决策。\n\n\n前置调用处理\n\n\nspring security提供两个Manager对收到的web请求的作前置权限控制。分别是AccessDecisionManager以及AccessDecisionManager。一般情况下官方推荐使用AuthorizationManager来代替AccessDecisionManager。AuthorizationManager被AuthorizationFilter调用，负责最终的访问控制。AuthorizationManager包含两个主要方法：\n\n\n```javascript\n//主体方法，负责做权限决策，如果授权成功返回一个positive AuthorizationDecision。否则则是negative的\nAuthorizationDecision check(Supplier<Authentication> authentication, Object secureObject);\n\n//调用check()，如果check()返回negative AuthorizationDecision,则抛出AccessDeniedException.\ndefault AuthorizationDecision verify(Supplier<Authentication> authentication, Object secureObject)\n        throws AccessDeniedException {\n    // ...\n}\n```\n\n\n### spring security的访问控制模型\n\n\nspring security基于RBAC（role based access control）实现其访问控制功能，RBAC的概念请参考[https://icyfenix.cn/architect-perspective/general-architecture/system-security/authorization.html#rbac](https://icyfenix.cn/architect-perspective/general-architecture/system-security/authorization.html#rbac)。\n\n\nspring security中的role可以是一种继承的结构。可以在配置文件中配置HierarchyVoter bean来进行设置。\n\n\n```javascript\n//ROLE_ADMIN ⇒ ROLE_STAFF ⇒ ROLE_USER ⇒ ROLE_GUEST, > 代表包含\n@Bean\nAccessDecisionVoter hierarchyVoter() {\n    RoleHierarchy hierarchy = new RoleHierarchyImpl();\n    hierarchy.setHierarchy(\"ROLE_ADMIN > ROLE_STAFF\\n\" +\n            \"ROLE_STAFF > ROLE_USER\\n\" +\n            \"ROLE_USER > ROLE_GUEST\");\n    return new RoleHierarchyVoter(hierarchy);\n}\n```\n\n\n**使用AuthorizationFilter对HttpServletRequests进行授权**\n\n\nAuthorizationFilter被插入FilterChainProxy中作为Security Filters的一份子。在configuration类中进行AuthorizationFilter配置。\n\n\n```javascript\n@Bean\nSecurityFilterChain web(HttpSecurity http) throws AuthenticationException {\n    http\n        .authorizeHttpRequests((authorize) -> authorize //可以配置一个bean\n            .anyRequest().authenticated();\n        )\n        // ...\n\n    return http.build();\n}\n```\n\n\n使用AuthorizationFilter的流程图如下所示：\n\n\n![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/90f57f18-5dd9-4ff0-a3e1-8b63c1ea17ee/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230417%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230417T085118Z&X-Amz-Expires=3600&X-Amz-Signature=fe408d6bcea809916481f87e02097a665cb999e09659bfa57c9b61a4fa54cbae&X-Amz-SignedHeaders=host&x-id=GetObject)\n\n\n可以按照一定的优先顺序配置授权规则\n\n\n```javascript\n@Bean\nSecurityFilterChain web(HttpSecurity http) throws Exception {\n\thttp\n\t\t// ...\n\t\t.authorizeHttpRequests(authorize -> authorize                                  \n\t\t\t.mvcMatchers(\"/resources/**\", \"/signup\", \"/about\").permitAll()  //任何user都可以访问的路径       \n\t\t\t.mvcMatchers(\"/admin/**\").hasRole(\"ADMIN\")  //只有admin角色可以访问的路径                         \n\t\t\t.mvcMatchers(\"/db/**\").access((authentication, request) ->\n\t\t\t    Optional.of(hasRole(\"ADMIN\").check(authentication, request))\n\t\t\t        .filter((decision) -> !decision.isGranted())\n\t\t\t        .orElseGet(() -> hasRole(\"DBA\").check(authentication, request)); //同时拥有admin和dba可以访问的路径\n\t\t\t)   \n\t\t\t.anyRequest().denyAll() //其他未在上面配置的路径拒绝                                                \n\t\t);\n\n\treturn http.build();\n}\n```\n\n\n更多配置方式参考[https://docs.spring.io/spring-security/reference/servlet/authorization/authorize-http-requests.html](https://docs.spring.io/spring-security/reference/servlet/authorization/authorize-http-requests.html)。\n\n\nspring security支持SpEL,感兴趣可以参考[https://docs.spring.io/spring-security/reference/servlet/authorization/expression-based.html](https://docs.spring.io/spring-security/reference/servlet/authorization/expression-based.html)\n\n"}]},{"tag":"测试","payload":[{"title":"单元测试","categories":"Java","tags":["测试"],"date":"2023-04-16","content":"\n"}]},{"tag":"并发","payload":[{"title":"并发探索","categories":"Java","tags":["Java","并发"],"date":"2023-04-12","content":"\n\n[embed](https://miro.com/app/board/uXjVPaWzcGg=/?share_link_id=77380253885)\n\n\n[embed](https://miro.com/app/board/uXjVPZryvFY=/?share_link_id=495517938632)\n\n"}]},{"tag":"泛型","payload":[{"title":"泛型实现","categories":"底层原理","tags":["泛型","编程语言原理"],"date":"2023-04-13","content":"\n\n参考，其实就是不成形的笔记\n\n\n[https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/](https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/)\n\n\n## 类型系统（Type system）\n\n\n### 类型内存布局（Type Memory Layout）\n\n\n在二进制的世界里，存储在内存中的数据在操作系统中看到的是一串比特序列，而在拥有类型之后这串比特序列才有一定的意义。\n\n\n### 类型检查\n\n- 强弱类型：\n\n强弱类型并没有标准的定义，但是普遍认为强弱类型的核心区别在于，语言能否在某一个时刻能检查出来类型导出的错误，而不是抛出运行时错误（Unchecked RuntimeError）。强类型的编程语言可以在类型不匹配时发生错误（编译与运行时都可能发生），而弱类型的语言在类型不匹配时会做隐式的类型转换或无视类型进行操作，这会导致无法预料的运行时错误。这二者区分出来的核心现象就是，弱类型语言往往无法信赖变量的值，需要写很多额外的代码做额外的类型验证操作。\n\n- 静动检查：\n\n动态与静态的区别在于类型检查发生的阶段，动态是在运行时阶段，静态是在编译阶段。但实际上一些编程语言是混合的类型检查，比如在C#中开发者可以通过关键字来标识此数据类型检查是动态还是静态的。不少静态类型检查的编程语言也有动态的类型检查，比如Java中既有编译阶段的静态类型检查，又有运行时的动态类型检查（如父类与子类的互相转换）。\n\n- 类型推导：\n\n一些编程语言虽然不需要开发者显示定义数据类型，但编译器能够做类型推导，帮助开发者定义数据类型，如Scala与Kotlin。\n\n\nJavaScript是一个弱类型的动态类型检查语言，C是一个弱类型的静态类型检查语言。\n\n\n### 实现泛型\n\n\n通常意义下的泛型也叫参数多态，指的是声明与定义函数、复合类型、变量时不指定其具体的类型，而把这部分类型作为参数使用，使得该定义对各种具体类型都适用。参数化多态使得语言更具表达力，同时保持了完全的静态类型安全。这被称为泛化函数、泛化数据类型、泛型变量，形成了泛型编程的基础。\n\n\n> 多态理论\n\n\n\t编程语言理论(PLT)中多态(Polymorphism)包含三个主要方面：特设多态(Ad-hoc)，参数多态(Parametric)和子类型(Subtyping)。\n\n\n\tAd-hoc：也叫重载(Overloading)，允许具有相同名称的函数对不同类型执行不同的操作。例如，`+`运算符即可以将两个整数相加，也可以连接两个字符串。\n\n\n\tSubtyping：也叫包容性多态(Inclusion)，是指通过基类指针和引用使用派生类的能力。\n\n\n子类型多态也称为运行时多态性，因为编译器在编译时不定位函数的地址，而是在运行时动态调用函数。派发分为三种：\n\n- 静态派发(Static dispatch/early binding)：当程序在编译时可以找到执行的函数。C++默认使用的是直接派发，加上`virtual`修饰符可以改成虚函数表(Vtable)派发。直接派发是最快的，原因是调用指令少，还可通过编译器进行内联等方式的优化。这种派发缺点是不灵活，无法实现一些面向对象所需的技术如多态性。\n- 动态派发(dynamic dispatch/run-time dispatch/virtual method call/late binding): 当程序在运行时可以找到执行的函数。Java默认使用的是虚函数表(Vtable)派发，通过`final`修饰符可改成直接派发。虚函数表派发是有动态性的，一个类里会用表来存储类成员函数的指针，子类重写(Override)父类的函数会替代父类的函数，子类添加的函数会被加到这个表里。当程序运行时派发时会从这个表中找到对应的函数，这样就可以实现动态派发。面向对象的编程语言正是靠此机制实现了多态性(Polymorphic)。\n- 消息机制(message passing)：通过消息传递来调用被执行的函数。这种机制是在运行时可以改变函数的行为，甚至函数可以未实现，也不会引发运行时错误。Objective-C中就是通过消息传递来调用被执行的函数，甚至可以在程序运行过程中实现热更新代码。\n\n静态派发的速度是最快的，但并不灵活。而动态派发虽然比较慢，但却可以实现面向对象多态的功能。消息机制是最灵活的方式，但性能也最差。\n\n\n[embed](https://miro.com/app/board/uXjVPabTn6A=/?share_link_id=402499999270)\n\n\n### 类型擦除\n\n\n对Java来说统一的数据类型就是Object，在编译阶段做完类型检查后就将类型信息通过转换成Object进行擦除，这样只需要生成一份泛型函数的副本即可。类型擦除保证了泛型函数生成的字节码和非泛型函数的是相同的，也符合Java对兼容性的要求。不过类型擦除也给Java的泛型带来了很多的限制。\n\n\n### 虚函数表(Vtable)\n\n\nJava通过类型擦除结合虚方法表来实现泛型的效果：运行时同样的数据类型Object，却能调用原始类型的方法。\n\n\n### 字典\n\n\n编译器在编译泛型函数时只生成了一份函数副本，通过新增一个字典参数来供调用方传递类型参数(Type Parameters)，这种实现方式称为字典传递(Dictionary passing)。\n\n\n### 单态化\n\n\n单态化的思路是自动生成多个类型的泛型函数版本，看起来就是一个模版代码生成的过程，但是也需要考虑很多种情况。比如：\n\n- 生成所有类型的函数版本：这种最简单，但是会拖慢编译时间，也会让最终的二进制文件变得很庞大。\n- 生成调用类型的函数版本：这种需要编译器分阶段或多次编译，比如需要遍历寻找调用点来确定最终的类型列表，对于不同包的同名函数的处理等。\n- 是否支持独立编译：如果调用泛型函数的类型与泛型函数不在同一个包内，是否能支持泛型函数独立的编译。\n\n模板\n\n\nC++通过模板实现泛型类、方法和函数，这导致编译器为每个唯一的类型参数集编译了代码的单独副本。这种方法的一个关键优势是没有运行时性能开销，尽管它以增加二进制文件大小和编译时间为代价。\n\n\n蜡印\n\n\n蜡印其实就是模版，也是一种代码生成技术。但Go除了使用字典传递实现装箱外，还采用了`GC Shape Stenciling`的技术。这种看起来很高级的名词简单来说是为了解决蜡印或模版的问题，因为在蜡印的过程中，编译器会为每一个实例化的类型参数生成一套独立的代码。\n\n"}]},{"tag":"编程语言原理","payload":[{"title":"泛型实现","categories":"底层原理","tags":["泛型","编程语言原理"],"date":"2023-04-13","content":"\n\n参考，其实就是不成形的笔记\n\n\n[https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/](https://www.bmpi.dev/dev/deep-in-program-language/how-to-implement-generics/)\n\n\n## 类型系统（Type system）\n\n\n### 类型内存布局（Type Memory Layout）\n\n\n在二进制的世界里，存储在内存中的数据在操作系统中看到的是一串比特序列，而在拥有类型之后这串比特序列才有一定的意义。\n\n\n### 类型检查\n\n- 强弱类型：\n\n强弱类型并没有标准的定义，但是普遍认为强弱类型的核心区别在于，语言能否在某一个时刻能检查出来类型导出的错误，而不是抛出运行时错误（Unchecked RuntimeError）。强类型的编程语言可以在类型不匹配时发生错误（编译与运行时都可能发生），而弱类型的语言在类型不匹配时会做隐式的类型转换或无视类型进行操作，这会导致无法预料的运行时错误。这二者区分出来的核心现象就是，弱类型语言往往无法信赖变量的值，需要写很多额外的代码做额外的类型验证操作。\n\n- 静动检查：\n\n动态与静态的区别在于类型检查发生的阶段，动态是在运行时阶段，静态是在编译阶段。但实际上一些编程语言是混合的类型检查，比如在C#中开发者可以通过关键字来标识此数据类型检查是动态还是静态的。不少静态类型检查的编程语言也有动态的类型检查，比如Java中既有编译阶段的静态类型检查，又有运行时的动态类型检查（如父类与子类的互相转换）。\n\n- 类型推导：\n\n一些编程语言虽然不需要开发者显示定义数据类型，但编译器能够做类型推导，帮助开发者定义数据类型，如Scala与Kotlin。\n\n\nJavaScript是一个弱类型的动态类型检查语言，C是一个弱类型的静态类型检查语言。\n\n\n### 实现泛型\n\n\n通常意义下的泛型也叫参数多态，指的是声明与定义函数、复合类型、变量时不指定其具体的类型，而把这部分类型作为参数使用，使得该定义对各种具体类型都适用。参数化多态使得语言更具表达力，同时保持了完全的静态类型安全。这被称为泛化函数、泛化数据类型、泛型变量，形成了泛型编程的基础。\n\n\n> 多态理论\n\n\n\t编程语言理论(PLT)中多态(Polymorphism)包含三个主要方面：特设多态(Ad-hoc)，参数多态(Parametric)和子类型(Subtyping)。\n\n\n\tAd-hoc：也叫重载(Overloading)，允许具有相同名称的函数对不同类型执行不同的操作。例如，`+`运算符即可以将两个整数相加，也可以连接两个字符串。\n\n\n\tSubtyping：也叫包容性多态(Inclusion)，是指通过基类指针和引用使用派生类的能力。\n\n\n子类型多态也称为运行时多态性，因为编译器在编译时不定位函数的地址，而是在运行时动态调用函数。派发分为三种：\n\n- 静态派发(Static dispatch/early binding)：当程序在编译时可以找到执行的函数。C++默认使用的是直接派发，加上`virtual`修饰符可以改成虚函数表(Vtable)派发。直接派发是最快的，原因是调用指令少，还可通过编译器进行内联等方式的优化。这种派发缺点是不灵活，无法实现一些面向对象所需的技术如多态性。\n- 动态派发(dynamic dispatch/run-time dispatch/virtual method call/late binding): 当程序在运行时可以找到执行的函数。Java默认使用的是虚函数表(Vtable)派发，通过`final`修饰符可改成直接派发。虚函数表派发是有动态性的，一个类里会用表来存储类成员函数的指针，子类重写(Override)父类的函数会替代父类的函数，子类添加的函数会被加到这个表里。当程序运行时派发时会从这个表中找到对应的函数，这样就可以实现动态派发。面向对象的编程语言正是靠此机制实现了多态性(Polymorphic)。\n- 消息机制(message passing)：通过消息传递来调用被执行的函数。这种机制是在运行时可以改变函数的行为，甚至函数可以未实现，也不会引发运行时错误。Objective-C中就是通过消息传递来调用被执行的函数，甚至可以在程序运行过程中实现热更新代码。\n\n静态派发的速度是最快的，但并不灵活。而动态派发虽然比较慢，但却可以实现面向对象多态的功能。消息机制是最灵活的方式，但性能也最差。\n\n\n[embed](https://miro.com/app/board/uXjVPabTn6A=/?share_link_id=402499999270)\n\n\n### 类型擦除\n\n\n对Java来说统一的数据类型就是Object，在编译阶段做完类型检查后就将类型信息通过转换成Object进行擦除，这样只需要生成一份泛型函数的副本即可。类型擦除保证了泛型函数生成的字节码和非泛型函数的是相同的，也符合Java对兼容性的要求。不过类型擦除也给Java的泛型带来了很多的限制。\n\n\n### 虚函数表(Vtable)\n\n\nJava通过类型擦除结合虚方法表来实现泛型的效果：运行时同样的数据类型Object，却能调用原始类型的方法。\n\n\n### 字典\n\n\n编译器在编译泛型函数时只生成了一份函数副本，通过新增一个字典参数来供调用方传递类型参数(Type Parameters)，这种实现方式称为字典传递(Dictionary passing)。\n\n\n### 单态化\n\n\n单态化的思路是自动生成多个类型的泛型函数版本，看起来就是一个模版代码生成的过程，但是也需要考虑很多种情况。比如：\n\n- 生成所有类型的函数版本：这种最简单，但是会拖慢编译时间，也会让最终的二进制文件变得很庞大。\n- 生成调用类型的函数版本：这种需要编译器分阶段或多次编译，比如需要遍历寻找调用点来确定最终的类型列表，对于不同包的同名函数的处理等。\n- 是否支持独立编译：如果调用泛型函数的类型与泛型函数不在同一个包内，是否能支持泛型函数独立的编译。\n\n模板\n\n\nC++通过模板实现泛型类、方法和函数，这导致编译器为每个唯一的类型参数集编译了代码的单独副本。这种方法的一个关键优势是没有运行时性能开销，尽管它以增加二进制文件大小和编译时间为代价。\n\n\n蜡印\n\n\n蜡印其实就是模版，也是一种代码生成技术。但Go除了使用字典传递实现装箱外，还采用了`GC Shape Stenciling`的技术。这种看起来很高级的名词简单来说是为了解决蜡印或模版的问题，因为在蜡印的过程中，编译器会为每一个实例化的类型参数生成一套独立的代码。\n\n"}]},{"tag":"redis","payload":[{"title":"使用redis实现分布式锁","date":"2022-04-29","tags":["redis","分布式锁"],"categories":"中间件","content":"\r\n\r\n## 使用redis实现分布式锁\r\n\r\n>同一操作系统下的线程竞态访问某一临界资源，我们可以使用锁来帮助我们达成目的，一些编程语言\r\n都会提供内置的锁库。但是当我们的执行线程并不运行在同一操作系统之下，单一实例下的锁机制就\r\n失效了，这种情况下，我们需要分布式锁机制来帮助我们协调管理线程之间的竞争。\r\n\r\n我们可以在redis的帮助下实现分布式锁机制。只需要一条简单的命令我们便能做到它。\r\n\r\n    set resource_name unique_value NX;\r\n在我们进入临界区之前，先尝试着向redis中插入一条数据，若该数据存在则获取锁失败，否则获取\r\n锁成功。不过这里有一个问题，就是若获取锁的线程在释放锁之前挂了，那么锁就无法被释放，其他线程\r\n也就没有办法获取到锁。为了解决这个问题，我们可以将unique_value设置为`expire_timestamp`，\r\n另外的线程可以get到`expire_timestamp`，若该时间戳小于当前时间戳，我们便可以执行del命令进而\r\n释放到锁，再执行获取锁的指令，就ok了。然而虽解决了锁无法释放的问题，却引入了新的问题。这里\r\n我们假设有两个线程在同一时刻检测到了锁失效，然后相继执行释放锁加锁的步骤，像下面这样：\r\n\r\n    Thread 1:del resource_name;\r\n    Thread 1:set resource_name unique_value NX;\r\n    Thread 2:del resource_name;\r\n    Thread 2:set resource_name unique_value NX;\r\n最终Thread1和Thead2都获得了锁，违反了分布式锁的含义。因此相应的，我们不应该将释放锁的权力\r\n交给其他线程。释放锁的工作应当由获取锁的线程去做，若该线程挂了，那么该锁应当超时自动释放，redis\r\n同样提供了这样的机制，将上面的改一改：\r\n\r\n    set resource_name unique_value NX EX expire_time;\r\n即使获取锁的线程挂了，该锁也能够在超时之后释放掉。但是呢，这个命令还是有问题。假设这把锁被超时释放了，\r\n另外的线程又获取到了这把锁，然而之前获取锁的线程并没有挂掉，它只是执行的比较慢而已，在另一个线程获取锁\r\n之后它才执行释放锁的操作，然后它就把其他线程的锁给释放掉了。显然这是不符合逻辑的，上面就提到没有把持锁\r\n的线程没有释放锁的权力，那么这个时候unique_value就起到了作用，当我们获取锁的时候将键对应的值设为\r\n全局唯一的某个值，比如timestamp + clientId，然后我们可以写一段Lua脚本\r\n\r\n    if redis.call(\"get\",KEY[1]) == ARGV[1]\r\n    then\r\n        return redis.call(\"del\",KEY[1])\r\n    else\r\n        return 0\r\n    end\r\n只有当对应的值与当前线程设的值一样时，当前线程才可以释放掉锁。redis内置的lua脚本解释器也保证了\r\n每段脚本执行的原子性，不必担心有其他意外发生。\r\n\r\n这些看起来很美好，但是不幸的是，依旧存在问题。如果我们的redis是master-slave架构，某个时刻master挂了，\r\n由于master和slave之间是异步的，如果新选出来的master没有这条锁的记录，那么其他线程便能够获取到该锁。那么\r\n有没有什么办法可以解决这个问题呢，答案是有的，大名鼎鼎的redlock就是为此诞生的。由于精力有限，redlock的讨论\r\n就过段时间再说，这里先挖个坑。\r\n"}]},{"tag":"分布式锁","payload":[{"title":"使用redis实现分布式锁","date":"2022-04-29","tags":["redis","分布式锁"],"categories":"中间件","content":"\r\n\r\n## 使用redis实现分布式锁\r\n\r\n>同一操作系统下的线程竞态访问某一临界资源，我们可以使用锁来帮助我们达成目的，一些编程语言\r\n都会提供内置的锁库。但是当我们的执行线程并不运行在同一操作系统之下，单一实例下的锁机制就\r\n失效了，这种情况下，我们需要分布式锁机制来帮助我们协调管理线程之间的竞争。\r\n\r\n我们可以在redis的帮助下实现分布式锁机制。只需要一条简单的命令我们便能做到它。\r\n\r\n    set resource_name unique_value NX;\r\n在我们进入临界区之前，先尝试着向redis中插入一条数据，若该数据存在则获取锁失败，否则获取\r\n锁成功。不过这里有一个问题，就是若获取锁的线程在释放锁之前挂了，那么锁就无法被释放，其他线程\r\n也就没有办法获取到锁。为了解决这个问题，我们可以将unique_value设置为`expire_timestamp`，\r\n另外的线程可以get到`expire_timestamp`，若该时间戳小于当前时间戳，我们便可以执行del命令进而\r\n释放到锁，再执行获取锁的指令，就ok了。然而虽解决了锁无法释放的问题，却引入了新的问题。这里\r\n我们假设有两个线程在同一时刻检测到了锁失效，然后相继执行释放锁加锁的步骤，像下面这样：\r\n\r\n    Thread 1:del resource_name;\r\n    Thread 1:set resource_name unique_value NX;\r\n    Thread 2:del resource_name;\r\n    Thread 2:set resource_name unique_value NX;\r\n最终Thread1和Thead2都获得了锁，违反了分布式锁的含义。因此相应的，我们不应该将释放锁的权力\r\n交给其他线程。释放锁的工作应当由获取锁的线程去做，若该线程挂了，那么该锁应当超时自动释放，redis\r\n同样提供了这样的机制，将上面的改一改：\r\n\r\n    set resource_name unique_value NX EX expire_time;\r\n即使获取锁的线程挂了，该锁也能够在超时之后释放掉。但是呢，这个命令还是有问题。假设这把锁被超时释放了，\r\n另外的线程又获取到了这把锁，然而之前获取锁的线程并没有挂掉，它只是执行的比较慢而已，在另一个线程获取锁\r\n之后它才执行释放锁的操作，然后它就把其他线程的锁给释放掉了。显然这是不符合逻辑的，上面就提到没有把持锁\r\n的线程没有释放锁的权力，那么这个时候unique_value就起到了作用，当我们获取锁的时候将键对应的值设为\r\n全局唯一的某个值，比如timestamp + clientId，然后我们可以写一段Lua脚本\r\n\r\n    if redis.call(\"get\",KEY[1]) == ARGV[1]\r\n    then\r\n        return redis.call(\"del\",KEY[1])\r\n    else\r\n        return 0\r\n    end\r\n只有当对应的值与当前线程设的值一样时，当前线程才可以释放掉锁。redis内置的lua脚本解释器也保证了\r\n每段脚本执行的原子性，不必担心有其他意外发生。\r\n\r\n这些看起来很美好，但是不幸的是，依旧存在问题。如果我们的redis是master-slave架构，某个时刻master挂了，\r\n由于master和slave之间是异步的，如果新选出来的master没有这条锁的记录，那么其他线程便能够获取到该锁。那么\r\n有没有什么办法可以解决这个问题呢，答案是有的，大名鼎鼎的redlock就是为此诞生的。由于精力有限，redlock的讨论\r\n就过段时间再说，这里先挖个坑。\r\n"}]},{"tag":"技巧","payload":[{"title":"编程相关小技巧","date":"2022-04-29","tags":["技巧"],"categories":"技巧","content":"\r\n目前内容较少，没有分篇叙述的必要，预计达到100个`tip`开分\r\n\r\n1. 在vscode中编写markdown文档时自动换行\r\n> - ctrl + shift + p,打开命令窗口，输入setting，打开open user settings\r\n> - 在搜索栏中搜索markdown\r\n> - 将Markdown>Preview：Breaks打上勾就ok了\r\n"}]},{"tag":"消息队列","payload":[{"title":"rabbitmq与AMQP","date":"2022-05-01","tags":["消息队列","中间件","rabbitmq"],"categories":"中间件","content":"\r\n\r\nrabbitmq是一款被广泛使用的消息队列中间件，它目前被Pivotal公司所拥有。其基于`AMQM`、`AMQP`并用`erlang`语言实现，拥有诸多特性，譬如开源、强大商业支持、跨语言、跨平台、轻量级、扩展性强、可定制、安全支持等。它可以通过分布式部署满足高可用的需求，其吞吐量亦十分可观，能够达到万/s的级别，当然吞吐量的高的代价是比较吃cpu，我们可以根据自身系统在可用性和性能两方面做权衡。另外rabbitmq还支持异地多活和异地多活多主架构。\r\nrabbitmq强悍的力量很大程度上是因为其基于`AMQP`，`AMQP`不仅定义了网络层协议而且对服务端的服务和行为也做了定义，即`AMQ model`。`AMQ model`就消息路由行为定义了三个抽象组件：`Exchange,Queue,Binding`。\r\n- Exchange：将消息路由给队列的组件\r\n- Queue：存在于内存或者磁盘中的存储消息的数据结构\r\n- Binding：Exchange将消息分发给Queue的规则\r\n\r\n将一个message发送到broker后，broker的行为如下图所示：<div align=\"center\"><img src=\"../../resources/img/rabbitmq-message-send.jpg\"></div>\r\n\r\n实际使用时，每种Exchange类型处理routing-key的行为会有所差异，有的不做任何处理，有些则需要进行复杂的模式匹配提取，header exchange甚至根本就不管routing-key是啥。rabbitmq在设计中扩展了AMQ model，exchange不仅接受queue的绑定，而且接受其他exchange的绑定，这种特性为消息的路由模式提供了相当的灵活性。\r\n\r\nrabbitmq客户端库的实现都会隐藏掉基于AMQP进行通信的复杂性，这或许对用户来说是一件好事，用户的绝大多数精力可以用在应用层上，不必关心实际上的复杂性。但我们还是应当熟悉AMQP协议，只有这样，我们才不会在应用性能没有达到预期或者是出现错误时束手无策。\r\n\r\nrabbitmq利用`RPC`模式实现AMQP的通信，但是具体实现又同一般的RPC模式有所不同。一般来说，进行RPC通信的双方，客户端发送指令给服务端，服务端处理后返回响应，这里服务端是不会发指令给客户端的，但是rabbitmq的RPC实现中，服务端会。<div align=\"center\"><img src=\"../../resources/img/rabbitmq-conversation.jpg\" height=600px></div>\r\n\r\nrabbitmq客户端与服务端之间建立通信首先需要经过三次握手。首先客户端会发送包含Protocol Header的Greeting给服务端，接着服务端发送Connection.Start给客户端，最后客户端发送Connection.StartOk给服务端，之后一个连接就建立了。在客户端与服务端之间进行有实际意义的交流之前，还得在连接中打开channel，在channel中进行AMQP帧的传输。channel是双工的，并且可以在一个连接中有多个，有点像HTTP2。\r\n\r\nAMQP的命令由类和方法组成，像Connection.Start中，Connection是对象，Start是方法。当命令被发送到客户端或者服务端时，执行命令所需的参数被封装到帧中进行传输。底层的AMQP帧大致上长这样。<div align=\"center\"><img src=\"../../resources/img/amqp-frame.jpg\" ></div>\r\n\r\n帧的头部由帧类型，channe编码，payload大小组成。有五种帧的类型如下所示：\r\n- protocol header frame：只会在在连接到rabbitmq时用到\r\n- method frame：携带RPC请求或者响应\r\n- content header frame：包含消息的大小和属性\r\n- body frame：消息内容\r\n- heartbeat frame：心跳检测确认通信双方存活\r\n\r\n在channel中的数据总是以`method frame`，`content header frame`，多个`body frame`的顺序流动。method frame被特殊编码以压缩大小，典型的method frame头两个字段包含类型和方法，之后的一个字段是exchange name，再然后是routing-key，最后可能会有一个mandatory字段以让rabbitmq在没有满足消息发布需求时给客户端进行反馈。content header frame的payload主体由Basic.Properties表组成，通过它可以很方便的实现消息的定制化。content header frame也会被特殊编码。body frame则不会被特殊编码，它可以装载各种格式的图片，json/xml格式数据或者是文档等。\r\n\r\n在AMQ model中，`exchange`和`queue`都是一等公民。创建一个exchange对应的method是Exchange.Declare,如果创建成功，rabbitmq会返回Exchange.DeclareOk,否则会返回Channel.Close。类似的，创建一个queue对应的method是Queue.Declare,如果创建成功，rabbitmq会返回Queue.DeclareOk,否则会返回Channel.Close。将一个queue绑定到exchange的method是Queue.Bind,绑定成功，rabbitmq会返回Queue.BindOk。以上的method在AMQP中都是同步命令，在AMQP中也有一些命令通过异步的方式来接受和发送消息。\r\n\r\n当我们通过Basic.Publish发布消息到rabbitmq中时，可以将消息存储到内存或者是磁盘中去，并且只会储存一份，丢到队列中的实际是实例的一份引用，不同队列的实例引用之间互不影响。当我们把消息丢到队列中去之后，剩下的就是消费了，客户端发送Basic.Consume请求消费，然后rabbitmq响应Basic.ConsumeOk表示可以开始消费，若客户端想要终止消费过程，可以发送Basic.Cancel,这是一个异步命令，所以客户端此时还是会收到rabbitmq发来的消息。\r\n\r\n受限于精力，能力和时间成本，rabbitmq的AMQP实现的了解暂时先到此为止。如果想进一步了解，可以参考[rabbitmq的官方文档](https://www.rabbitmq.com/protocol.html)。\r\n\r\n附上Basic.Properties的属性表：<div align=\"center\"><img src=\"../../resources/img/Basic-properties.png\"></div>\r\n"},{"title":"rabbitmq中的队列和exchange","date":"2022-05-02","tags":["rabbitmq","中间件","消息队列"],"categories":"中间件","content":"\r\n\r\n队列毫无疑问在消息队列中占据着核心地位，rabbitmq提供了诸多设置让我们能够自如地定义队列。这些设置有很多，挑一些常用的列举在下方：\r\n- 自动删除\r\n- 限制唯一消费者消费\r\n- 自动过期队列\r\n- 限制消息的数量\r\n\r\n非常重要的是，一旦我们创建了一个队列，队列的设置就无法被更改了，改变队列的设置只能通过删除然后重新创建的方式。\r\n\r\n通过在`Queue.Declare`请求中加入`auto_delete`标志可以创建临时队列，所谓临时队列就是一旦消费者拿走队列的全部消息、断开连接，队列就会被删除。值得留意的是，临时队列可以被任意数量的消费者消费，只有当不再有消费者监听该队列了，这个队列才会被删除。\r\n\r\n在队列声明请求中加入`exclusive`标志可以限制消费者的数量为一，声明一个排他队列，排他队列也会自动删除，但它的行为和临时队列有所不同，排他队列在连接断开后被删除，临时队列则与是否有订阅者有关。\r\n\r\n通过在队列声明请求中加入`x-expires`参数可以声明一个定时队列，参数单位为毫秒，定时队列会在过期时间到后被自动删除，需要注意的是只要定时队列上由消费者，那么除非消费者停止订阅或者连接断开，该队列是不会被自动删除的。另外当消费者向该队列发送`Basic.Get`请求后，`x-expires`参数就失效了，该队列不再是定时队列了。rabbitmq不保证删除定时队列的及时性。\r\n\r\n通过在创建队列请求中将`durable`参数置为true，可以让该队列成为一个永久队列，并被持久化到磁盘中去，直到`Queue.Delete`命令删除该队列。\r\n\r\n通过在创建队列时设置`x-message-ttl`可以设置队列中消息的过期时间，设置`x-max-length`可以设置队列最大消息数，当队列中的消息达到了这个数目，就无法向队列中添加消息了。如果该队列声明了`DLX`，那么过期的消息和无法添加的消息会被交给`DLX`处理。\r\n\r\n声明一个队列可使用的参数及其作用如下图所示：<div align=\"center\"><img src=\"../../resources/img/queue-argument.png\"></div>\r\n\r\nrabbitmq最强大的力量来自于exchange基于消息中的routing信息将消息路由至不同队列的灵活性。通过exchange，消息可以被路由至一个或多个队列，其他exchange，还可以是外部资源。在rabbitmq中有四种类型的exchange：\r\n- Direct exchange\r\n- Fanout exchange\r\n- Topic exchange\r\n- Headers exchange\r\n\r\nDirect exchange是rabbitmq中最简单的exchange，它可以被多个队列绑定，当消息发送至此exchange时，它会将消息的routing-key同与之绑定的队列的binding-key做比较，只有当两个字符串完全相等时，exchange才会将消息丢到队列中去。\r\n\r\nFanout exchange会将接受的消息发送到所有绑定的队列中去，因为不需要进行routing-key和binding-key的比较，所有性能会很好，但是也因为缺乏选择机制，路由至所有队列中的消息都应该被消费。\r\n\r\nTopic exchange同Direct exchange一样会基于routing-key选择性的路由消息到队列中，不同的是Topic exchange不需要完全匹配，它通过基于通配符的模式匹配完成工作。\r\n\r\nHeaders exchange的允许在消息中自描述路由逻辑，在消息头的Basic.Properties中添加headers属性，headers表随意添加key/value对，队列与exchange的绑定使用的也不再是字符串数组，而是key/value对的数组，绑定会被设置一个叫x-match的参数，值为any或者all，any表示任意匹配，all则是全匹配。Headers exchange提供强大的路由机制，但代价是也给broker带来了额外的计算负担，在比较路由之前，headers表中的属性值会先被排序。但是有一点需要注意的是只要在消息的属性中设置了headers，那么无论消息被发送至什么类型的exchange上，性能都会受到影响。\r\n\r\n一个exchange可以有多个queue绑定，那么一个消息可以被发送至多个exchange吗？答案是可以的。通过exchange-to-exchange绑定，你可以做到这一切，不同于队列绑定使用Queue.Bind method，exchange绑定使用Exchange.Bind method。这种机制非常灵活，灵活可能会使系统变得复杂。rabbitmq中的主要exchange类型如下图所示：<div align=\"center\"><img src=\"../../resources/img/exchanges.png\"></div>"}]},{"tag":"中间件","payload":[{"title":"rabbitmq与AMQP","date":"2022-05-01","tags":["消息队列","中间件","rabbitmq"],"categories":"中间件","content":"\r\n\r\nrabbitmq是一款被广泛使用的消息队列中间件，它目前被Pivotal公司所拥有。其基于`AMQM`、`AMQP`并用`erlang`语言实现，拥有诸多特性，譬如开源、强大商业支持、跨语言、跨平台、轻量级、扩展性强、可定制、安全支持等。它可以通过分布式部署满足高可用的需求，其吞吐量亦十分可观，能够达到万/s的级别，当然吞吐量的高的代价是比较吃cpu，我们可以根据自身系统在可用性和性能两方面做权衡。另外rabbitmq还支持异地多活和异地多活多主架构。\r\nrabbitmq强悍的力量很大程度上是因为其基于`AMQP`，`AMQP`不仅定义了网络层协议而且对服务端的服务和行为也做了定义，即`AMQ model`。`AMQ model`就消息路由行为定义了三个抽象组件：`Exchange,Queue,Binding`。\r\n- Exchange：将消息路由给队列的组件\r\n- Queue：存在于内存或者磁盘中的存储消息的数据结构\r\n- Binding：Exchange将消息分发给Queue的规则\r\n\r\n将一个message发送到broker后，broker的行为如下图所示：<div align=\"center\"><img src=\"../../resources/img/rabbitmq-message-send.jpg\"></div>\r\n\r\n实际使用时，每种Exchange类型处理routing-key的行为会有所差异，有的不做任何处理，有些则需要进行复杂的模式匹配提取，header exchange甚至根本就不管routing-key是啥。rabbitmq在设计中扩展了AMQ model，exchange不仅接受queue的绑定，而且接受其他exchange的绑定，这种特性为消息的路由模式提供了相当的灵活性。\r\n\r\nrabbitmq客户端库的实现都会隐藏掉基于AMQP进行通信的复杂性，这或许对用户来说是一件好事，用户的绝大多数精力可以用在应用层上，不必关心实际上的复杂性。但我们还是应当熟悉AMQP协议，只有这样，我们才不会在应用性能没有达到预期或者是出现错误时束手无策。\r\n\r\nrabbitmq利用`RPC`模式实现AMQP的通信，但是具体实现又同一般的RPC模式有所不同。一般来说，进行RPC通信的双方，客户端发送指令给服务端，服务端处理后返回响应，这里服务端是不会发指令给客户端的，但是rabbitmq的RPC实现中，服务端会。<div align=\"center\"><img src=\"../../resources/img/rabbitmq-conversation.jpg\" height=600px></div>\r\n\r\nrabbitmq客户端与服务端之间建立通信首先需要经过三次握手。首先客户端会发送包含Protocol Header的Greeting给服务端，接着服务端发送Connection.Start给客户端，最后客户端发送Connection.StartOk给服务端，之后一个连接就建立了。在客户端与服务端之间进行有实际意义的交流之前，还得在连接中打开channel，在channel中进行AMQP帧的传输。channel是双工的，并且可以在一个连接中有多个，有点像HTTP2。\r\n\r\nAMQP的命令由类和方法组成，像Connection.Start中，Connection是对象，Start是方法。当命令被发送到客户端或者服务端时，执行命令所需的参数被封装到帧中进行传输。底层的AMQP帧大致上长这样。<div align=\"center\"><img src=\"../../resources/img/amqp-frame.jpg\" ></div>\r\n\r\n帧的头部由帧类型，channe编码，payload大小组成。有五种帧的类型如下所示：\r\n- protocol header frame：只会在在连接到rabbitmq时用到\r\n- method frame：携带RPC请求或者响应\r\n- content header frame：包含消息的大小和属性\r\n- body frame：消息内容\r\n- heartbeat frame：心跳检测确认通信双方存活\r\n\r\n在channel中的数据总是以`method frame`，`content header frame`，多个`body frame`的顺序流动。method frame被特殊编码以压缩大小，典型的method frame头两个字段包含类型和方法，之后的一个字段是exchange name，再然后是routing-key，最后可能会有一个mandatory字段以让rabbitmq在没有满足消息发布需求时给客户端进行反馈。content header frame的payload主体由Basic.Properties表组成，通过它可以很方便的实现消息的定制化。content header frame也会被特殊编码。body frame则不会被特殊编码，它可以装载各种格式的图片，json/xml格式数据或者是文档等。\r\n\r\n在AMQ model中，`exchange`和`queue`都是一等公民。创建一个exchange对应的method是Exchange.Declare,如果创建成功，rabbitmq会返回Exchange.DeclareOk,否则会返回Channel.Close。类似的，创建一个queue对应的method是Queue.Declare,如果创建成功，rabbitmq会返回Queue.DeclareOk,否则会返回Channel.Close。将一个queue绑定到exchange的method是Queue.Bind,绑定成功，rabbitmq会返回Queue.BindOk。以上的method在AMQP中都是同步命令，在AMQP中也有一些命令通过异步的方式来接受和发送消息。\r\n\r\n当我们通过Basic.Publish发布消息到rabbitmq中时，可以将消息存储到内存或者是磁盘中去，并且只会储存一份，丢到队列中的实际是实例的一份引用，不同队列的实例引用之间互不影响。当我们把消息丢到队列中去之后，剩下的就是消费了，客户端发送Basic.Consume请求消费，然后rabbitmq响应Basic.ConsumeOk表示可以开始消费，若客户端想要终止消费过程，可以发送Basic.Cancel,这是一个异步命令，所以客户端此时还是会收到rabbitmq发来的消息。\r\n\r\n受限于精力，能力和时间成本，rabbitmq的AMQP实现的了解暂时先到此为止。如果想进一步了解，可以参考[rabbitmq的官方文档](https://www.rabbitmq.com/protocol.html)。\r\n\r\n附上Basic.Properties的属性表：<div align=\"center\"><img src=\"../../resources/img/Basic-properties.png\"></div>\r\n"},{"title":"rabbitmq中的队列和exchange","date":"2022-05-02","tags":["rabbitmq","中间件","消息队列"],"categories":"中间件","content":"\r\n\r\n队列毫无疑问在消息队列中占据着核心地位，rabbitmq提供了诸多设置让我们能够自如地定义队列。这些设置有很多，挑一些常用的列举在下方：\r\n- 自动删除\r\n- 限制唯一消费者消费\r\n- 自动过期队列\r\n- 限制消息的数量\r\n\r\n非常重要的是，一旦我们创建了一个队列，队列的设置就无法被更改了，改变队列的设置只能通过删除然后重新创建的方式。\r\n\r\n通过在`Queue.Declare`请求中加入`auto_delete`标志可以创建临时队列，所谓临时队列就是一旦消费者拿走队列的全部消息、断开连接，队列就会被删除。值得留意的是，临时队列可以被任意数量的消费者消费，只有当不再有消费者监听该队列了，这个队列才会被删除。\r\n\r\n在队列声明请求中加入`exclusive`标志可以限制消费者的数量为一，声明一个排他队列，排他队列也会自动删除，但它的行为和临时队列有所不同，排他队列在连接断开后被删除，临时队列则与是否有订阅者有关。\r\n\r\n通过在队列声明请求中加入`x-expires`参数可以声明一个定时队列，参数单位为毫秒，定时队列会在过期时间到后被自动删除，需要注意的是只要定时队列上由消费者，那么除非消费者停止订阅或者连接断开，该队列是不会被自动删除的。另外当消费者向该队列发送`Basic.Get`请求后，`x-expires`参数就失效了，该队列不再是定时队列了。rabbitmq不保证删除定时队列的及时性。\r\n\r\n通过在创建队列请求中将`durable`参数置为true，可以让该队列成为一个永久队列，并被持久化到磁盘中去，直到`Queue.Delete`命令删除该队列。\r\n\r\n通过在创建队列时设置`x-message-ttl`可以设置队列中消息的过期时间，设置`x-max-length`可以设置队列最大消息数，当队列中的消息达到了这个数目，就无法向队列中添加消息了。如果该队列声明了`DLX`，那么过期的消息和无法添加的消息会被交给`DLX`处理。\r\n\r\n声明一个队列可使用的参数及其作用如下图所示：<div align=\"center\"><img src=\"../../resources/img/queue-argument.png\"></div>\r\n\r\nrabbitmq最强大的力量来自于exchange基于消息中的routing信息将消息路由至不同队列的灵活性。通过exchange，消息可以被路由至一个或多个队列，其他exchange，还可以是外部资源。在rabbitmq中有四种类型的exchange：\r\n- Direct exchange\r\n- Fanout exchange\r\n- Topic exchange\r\n- Headers exchange\r\n\r\nDirect exchange是rabbitmq中最简单的exchange，它可以被多个队列绑定，当消息发送至此exchange时，它会将消息的routing-key同与之绑定的队列的binding-key做比较，只有当两个字符串完全相等时，exchange才会将消息丢到队列中去。\r\n\r\nFanout exchange会将接受的消息发送到所有绑定的队列中去，因为不需要进行routing-key和binding-key的比较，所有性能会很好，但是也因为缺乏选择机制，路由至所有队列中的消息都应该被消费。\r\n\r\nTopic exchange同Direct exchange一样会基于routing-key选择性的路由消息到队列中，不同的是Topic exchange不需要完全匹配，它通过基于通配符的模式匹配完成工作。\r\n\r\nHeaders exchange的允许在消息中自描述路由逻辑，在消息头的Basic.Properties中添加headers属性，headers表随意添加key/value对，队列与exchange的绑定使用的也不再是字符串数组，而是key/value对的数组，绑定会被设置一个叫x-match的参数，值为any或者all，any表示任意匹配，all则是全匹配。Headers exchange提供强大的路由机制，但代价是也给broker带来了额外的计算负担，在比较路由之前，headers表中的属性值会先被排序。但是有一点需要注意的是只要在消息的属性中设置了headers，那么无论消息被发送至什么类型的exchange上，性能都会受到影响。\r\n\r\n一个exchange可以有多个queue绑定，那么一个消息可以被发送至多个exchange吗？答案是可以的。通过exchange-to-exchange绑定，你可以做到这一切，不同于队列绑定使用Queue.Bind method，exchange绑定使用Exchange.Bind method。这种机制非常灵活，灵活可能会使系统变得复杂。rabbitmq中的主要exchange类型如下图所示：<div align=\"center\"><img src=\"../../resources/img/exchanges.png\"></div>"}]},{"tag":"rabbitmq","payload":[{"title":"rabbitmq与AMQP","date":"2022-05-01","tags":["消息队列","中间件","rabbitmq"],"categories":"中间件","content":"\r\n\r\nrabbitmq是一款被广泛使用的消息队列中间件，它目前被Pivotal公司所拥有。其基于`AMQM`、`AMQP`并用`erlang`语言实现，拥有诸多特性，譬如开源、强大商业支持、跨语言、跨平台、轻量级、扩展性强、可定制、安全支持等。它可以通过分布式部署满足高可用的需求，其吞吐量亦十分可观，能够达到万/s的级别，当然吞吐量的高的代价是比较吃cpu，我们可以根据自身系统在可用性和性能两方面做权衡。另外rabbitmq还支持异地多活和异地多活多主架构。\r\nrabbitmq强悍的力量很大程度上是因为其基于`AMQP`，`AMQP`不仅定义了网络层协议而且对服务端的服务和行为也做了定义，即`AMQ model`。`AMQ model`就消息路由行为定义了三个抽象组件：`Exchange,Queue,Binding`。\r\n- Exchange：将消息路由给队列的组件\r\n- Queue：存在于内存或者磁盘中的存储消息的数据结构\r\n- Binding：Exchange将消息分发给Queue的规则\r\n\r\n将一个message发送到broker后，broker的行为如下图所示：<div align=\"center\"><img src=\"../../resources/img/rabbitmq-message-send.jpg\"></div>\r\n\r\n实际使用时，每种Exchange类型处理routing-key的行为会有所差异，有的不做任何处理，有些则需要进行复杂的模式匹配提取，header exchange甚至根本就不管routing-key是啥。rabbitmq在设计中扩展了AMQ model，exchange不仅接受queue的绑定，而且接受其他exchange的绑定，这种特性为消息的路由模式提供了相当的灵活性。\r\n\r\nrabbitmq客户端库的实现都会隐藏掉基于AMQP进行通信的复杂性，这或许对用户来说是一件好事，用户的绝大多数精力可以用在应用层上，不必关心实际上的复杂性。但我们还是应当熟悉AMQP协议，只有这样，我们才不会在应用性能没有达到预期或者是出现错误时束手无策。\r\n\r\nrabbitmq利用`RPC`模式实现AMQP的通信，但是具体实现又同一般的RPC模式有所不同。一般来说，进行RPC通信的双方，客户端发送指令给服务端，服务端处理后返回响应，这里服务端是不会发指令给客户端的，但是rabbitmq的RPC实现中，服务端会。<div align=\"center\"><img src=\"../../resources/img/rabbitmq-conversation.jpg\" height=600px></div>\r\n\r\nrabbitmq客户端与服务端之间建立通信首先需要经过三次握手。首先客户端会发送包含Protocol Header的Greeting给服务端，接着服务端发送Connection.Start给客户端，最后客户端发送Connection.StartOk给服务端，之后一个连接就建立了。在客户端与服务端之间进行有实际意义的交流之前，还得在连接中打开channel，在channel中进行AMQP帧的传输。channel是双工的，并且可以在一个连接中有多个，有点像HTTP2。\r\n\r\nAMQP的命令由类和方法组成，像Connection.Start中，Connection是对象，Start是方法。当命令被发送到客户端或者服务端时，执行命令所需的参数被封装到帧中进行传输。底层的AMQP帧大致上长这样。<div align=\"center\"><img src=\"../../resources/img/amqp-frame.jpg\" ></div>\r\n\r\n帧的头部由帧类型，channe编码，payload大小组成。有五种帧的类型如下所示：\r\n- protocol header frame：只会在在连接到rabbitmq时用到\r\n- method frame：携带RPC请求或者响应\r\n- content header frame：包含消息的大小和属性\r\n- body frame：消息内容\r\n- heartbeat frame：心跳检测确认通信双方存活\r\n\r\n在channel中的数据总是以`method frame`，`content header frame`，多个`body frame`的顺序流动。method frame被特殊编码以压缩大小，典型的method frame头两个字段包含类型和方法，之后的一个字段是exchange name，再然后是routing-key，最后可能会有一个mandatory字段以让rabbitmq在没有满足消息发布需求时给客户端进行反馈。content header frame的payload主体由Basic.Properties表组成，通过它可以很方便的实现消息的定制化。content header frame也会被特殊编码。body frame则不会被特殊编码，它可以装载各种格式的图片，json/xml格式数据或者是文档等。\r\n\r\n在AMQ model中，`exchange`和`queue`都是一等公民。创建一个exchange对应的method是Exchange.Declare,如果创建成功，rabbitmq会返回Exchange.DeclareOk,否则会返回Channel.Close。类似的，创建一个queue对应的method是Queue.Declare,如果创建成功，rabbitmq会返回Queue.DeclareOk,否则会返回Channel.Close。将一个queue绑定到exchange的method是Queue.Bind,绑定成功，rabbitmq会返回Queue.BindOk。以上的method在AMQP中都是同步命令，在AMQP中也有一些命令通过异步的方式来接受和发送消息。\r\n\r\n当我们通过Basic.Publish发布消息到rabbitmq中时，可以将消息存储到内存或者是磁盘中去，并且只会储存一份，丢到队列中的实际是实例的一份引用，不同队列的实例引用之间互不影响。当我们把消息丢到队列中去之后，剩下的就是消费了，客户端发送Basic.Consume请求消费，然后rabbitmq响应Basic.ConsumeOk表示可以开始消费，若客户端想要终止消费过程，可以发送Basic.Cancel,这是一个异步命令，所以客户端此时还是会收到rabbitmq发来的消息。\r\n\r\n受限于精力，能力和时间成本，rabbitmq的AMQP实现的了解暂时先到此为止。如果想进一步了解，可以参考[rabbitmq的官方文档](https://www.rabbitmq.com/protocol.html)。\r\n\r\n附上Basic.Properties的属性表：<div align=\"center\"><img src=\"../../resources/img/Basic-properties.png\"></div>\r\n"},{"title":"rabbitmq中的消息发布与消费","date":"2022-05-02","tags":["rabbitmq"],"categories":"中间件","content":"\r\n>多一分则肥，少一分则瘦\r\n\r\n消息中间件消息的发布需要在高性能与可靠性之间做权衡，rabbitmq依靠AMQP的事务规范，可选的持久化机制，以及自身的传输确认机制为我们构建不同等级的可靠系统提供了可能性。<div align=\"center\"><img src=\"../../resources/img/performance-with-guarantee.png\"></div>\r\n\r\nNotification on failure -- 当我们在Basic.Publish的method frame中添加mandatory标志时，如果消息没有被正确的路由，那么rabbitmq broker就会通过Basic.Return的RPC回传消息给publisher。在我们的代码中要注册回调函数处理这种路由失败的情况。Publisher confirms -- publisher发送Confirm.Select,rabbitmq broker回复Confirm.SelectOk，之后这条传递消息的channel就成了一个confirm channel，publisher每发送一条消息给服务器，如果消息都入队等待被消费并且被持久化到磁盘中，或者是消息在所有应该路由到的队列中都被消费者消费完毕了，服务端就会回复Basic.Ack，否则就会回复Basic.Nak。服务端异步回复confirm消息，在我们的代码中需要注册回调函数处理来自服务端的回复。Alternate exchanges -- 当我们声明一个exchange，可以给它绑定一个备用exchange，当发送给给此exchange的消息无法被路由时，此备选exchange就会接管工作，将消息路由到死信队列中去，值得注意的是，一旦同时设置mandatory标志和备选队列，那么mandatory就失效了。Transactions -- AMQP规范中定义了事务来保证批处理的原子性。publisher发送TX.Select,服务端回传TX.SelectOk，事务就开始了，可以在事务中发送一条或者多条消息，消息发送完毕publisher发送TX.Commit，然后在收到服务端的TX.CommitOk后，事务就完成了。这里需要注意的是当事务执行过程中，发生错误了，那么服务端就会发送Basic.Return,publisher如果想终止事务，可以发送TX.Rollback，然后等待服务端回传TX.RollbackOk。另外，rabbitmq在实现AMQP事务规范时只有当命令只影响一条队列时，才保证其原子性，当有多条队列收到影响时，原子性就会被打破。事务机制比较影响性能。HA queues -- HA queue需要在集群环境中使用，在定义队列时，将队列声明为高可用队列，模式若设为all，则集群中的所有结点都会同步此队列的状态。若模式为nodes，则可自定义同步节点。一旦消费者在任意节点消费了此队列中的消息，所有节点中的该条消息就会立刻被删除。HA queues拥有一个主节点，其他的都是副节点，如果主节点挂了，其他的某个副节点就会成为新的主节点。如果挂了的节点恢复了，或者集群中加入了新的节点，那么它们会接受新发送来的消息，并且在队列中的旧消息都消费完毕了才会加入同步集。HA queues with transactions -- 这种方式会引入相当的响应延迟，慎重使用。Persisted messages -- 持久化选项由Basic.Properties中的delivery-mode控制，默认为1，表示不持久化，如果想要持久化，则应该设为2，另外装此消息的队列也应该被设置为持久化队列。\r\n\r\n上面一段讲了向rabbitmq发布消息的问题，这一段我们看看怎么从rabbitmq获取消息。有两种方法可以从rabbitmq获取消息，`Basic.Get` & `Basic.Consume`。Basic.Get使用一种拉的模式从broker中获取消息，consumer想要获取一个消息都必须发送一个新的Basic.Get RPC请求，broker会根据queue中是否有代办消息回复`Basic.GetOk` or `Basic.GetEmpty`，消费端需要根据回复进行相应的处理。Basic.Get的这种同步方式对性能有明显的影响，更重要的是，由于consume是消费端主动发起的，所以broker也无法优化整个传输过程。与`Basic.Get`相反的是，`Basic.Consume`以一种推的方式从broker中获取消息，发送Basic.Consume RPC请求到broker后，rabbitmq就会在broker中注册你的应用，然后直到你发送`Basic.Cancel`之前,broker都以一种异步的方式将队列中的消息发送给消费者。当然从broker获取到消息之后，消费端也需要向broker发送`Basic.Ack`让它知道消息已经被正常消费了。同publish一样，消费消息也需要在吞吐量和可靠性之间做权衡。<div align=\"center\"><img src=\"../../resources/img/consume-with-guarantee.png\"></div>\r\n\r\nno-ack -- 当向rabbitmq发送Basic.Consume注册我们的应用进行消费时，在请求中携带no-ack的标志时，broker就会知道消费端不会ack，应该尽可能快速地将消息发送给消费端。Consuming with acknowledgement and Qos > 1 -- 通过向broker发送Basic.Qos请求，我们可以设置一条channel的服务质量，broker会在这条channel上连续发送预设数量的message后，等待消费端的回复，消费端可以选择依旧每条消息都回复，也可以通过在Basic.Ack中设置multiple标志而不必每条消息都回复，broker会将没有收到回复的消息写回到队列中。当然设置multiple标志的方式会有重复消费的风险。transaction -- 事务方式可以规避重复消费的风险，代价是吞吐量不及QoS的方式。\r\n\r\n当消费端在接收消息或者处理消息的过程中发生异常情况时，rabbitmq提供两种方式将消息踢还给broker：`Basic.Reject` & `Basic.Nak`。发送Basic.Reject给服务端时，若在请求中携带requeue标志，则broker会将消息重新入队，否则broker只是简单的将消息丢弃。Basic.Nak的行为与Basic.Reject类似，不同的是其类似Basic.Ack可以在一次回复中携带多个拒绝信息，它也不是AMQP原生支持的命令。除了这两条命令，rabbitmq还提供叫做死信exchange(DLX)的扩展，DLX同队列进行绑定，一个队列中被拒绝且没有重新入队的消息或者过期的消息会被交给DLX。"},{"title":"rabbitmq中的队列和exchange","date":"2022-05-02","tags":["rabbitmq","中间件","消息队列"],"categories":"中间件","content":"\r\n\r\n队列毫无疑问在消息队列中占据着核心地位，rabbitmq提供了诸多设置让我们能够自如地定义队列。这些设置有很多，挑一些常用的列举在下方：\r\n- 自动删除\r\n- 限制唯一消费者消费\r\n- 自动过期队列\r\n- 限制消息的数量\r\n\r\n非常重要的是，一旦我们创建了一个队列，队列的设置就无法被更改了，改变队列的设置只能通过删除然后重新创建的方式。\r\n\r\n通过在`Queue.Declare`请求中加入`auto_delete`标志可以创建临时队列，所谓临时队列就是一旦消费者拿走队列的全部消息、断开连接，队列就会被删除。值得留意的是，临时队列可以被任意数量的消费者消费，只有当不再有消费者监听该队列了，这个队列才会被删除。\r\n\r\n在队列声明请求中加入`exclusive`标志可以限制消费者的数量为一，声明一个排他队列，排他队列也会自动删除，但它的行为和临时队列有所不同，排他队列在连接断开后被删除，临时队列则与是否有订阅者有关。\r\n\r\n通过在队列声明请求中加入`x-expires`参数可以声明一个定时队列，参数单位为毫秒，定时队列会在过期时间到后被自动删除，需要注意的是只要定时队列上由消费者，那么除非消费者停止订阅或者连接断开，该队列是不会被自动删除的。另外当消费者向该队列发送`Basic.Get`请求后，`x-expires`参数就失效了，该队列不再是定时队列了。rabbitmq不保证删除定时队列的及时性。\r\n\r\n通过在创建队列请求中将`durable`参数置为true，可以让该队列成为一个永久队列，并被持久化到磁盘中去，直到`Queue.Delete`命令删除该队列。\r\n\r\n通过在创建队列时设置`x-message-ttl`可以设置队列中消息的过期时间，设置`x-max-length`可以设置队列最大消息数，当队列中的消息达到了这个数目，就无法向队列中添加消息了。如果该队列声明了`DLX`，那么过期的消息和无法添加的消息会被交给`DLX`处理。\r\n\r\n声明一个队列可使用的参数及其作用如下图所示：<div align=\"center\"><img src=\"../../resources/img/queue-argument.png\"></div>\r\n\r\nrabbitmq最强大的力量来自于exchange基于消息中的routing信息将消息路由至不同队列的灵活性。通过exchange，消息可以被路由至一个或多个队列，其他exchange，还可以是外部资源。在rabbitmq中有四种类型的exchange：\r\n- Direct exchange\r\n- Fanout exchange\r\n- Topic exchange\r\n- Headers exchange\r\n\r\nDirect exchange是rabbitmq中最简单的exchange，它可以被多个队列绑定，当消息发送至此exchange时，它会将消息的routing-key同与之绑定的队列的binding-key做比较，只有当两个字符串完全相等时，exchange才会将消息丢到队列中去。\r\n\r\nFanout exchange会将接受的消息发送到所有绑定的队列中去，因为不需要进行routing-key和binding-key的比较，所有性能会很好，但是也因为缺乏选择机制，路由至所有队列中的消息都应该被消费。\r\n\r\nTopic exchange同Direct exchange一样会基于routing-key选择性的路由消息到队列中，不同的是Topic exchange不需要完全匹配，它通过基于通配符的模式匹配完成工作。\r\n\r\nHeaders exchange的允许在消息中自描述路由逻辑，在消息头的Basic.Properties中添加headers属性，headers表随意添加key/value对，队列与exchange的绑定使用的也不再是字符串数组，而是key/value对的数组，绑定会被设置一个叫x-match的参数，值为any或者all，any表示任意匹配，all则是全匹配。Headers exchange提供强大的路由机制，但代价是也给broker带来了额外的计算负担，在比较路由之前，headers表中的属性值会先被排序。但是有一点需要注意的是只要在消息的属性中设置了headers，那么无论消息被发送至什么类型的exchange上，性能都会受到影响。\r\n\r\n一个exchange可以有多个queue绑定，那么一个消息可以被发送至多个exchange吗？答案是可以的。通过exchange-to-exchange绑定，你可以做到这一切，不同于队列绑定使用Queue.Bind method，exchange绑定使用Exchange.Bind method。这种机制非常灵活，灵活可能会使系统变得复杂。rabbitmq中的主要exchange类型如下图所示：<div align=\"center\"><img src=\"../../resources/img/exchanges.png\"></div>"}]}];
